{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd78a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bands in seq_last3: ['y5', 'y6', 'y7']\n",
      "Bands in corrected stack: ['y5', 'y6', 'y7', 'ABA6_allowed', 'y6c']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6935fbf3a63b41039ee780ed58cd1c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[0, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], position='topright', transp…"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ee\n",
    "import geemap\n",
    "\n",
    "# -------------------------------\n",
    "# 0) INITIALIZE EE\n",
    "# -------------------------------\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='raman-461708')\n",
    "\n",
    "# -------------------------------\n",
    "# 1) PARAMETERS\n",
    "# -------------------------------\n",
    "aez         = 1\n",
    "start_year  = 2017      # first LULC year (2017-07-01_2018-06-30)\n",
    "total_years = 7         # you now have 7 yearly maps\n",
    "project     = 'raman-461708'\n",
    "\n",
    "roi_boundary = ee.FeatureCollection(\"users/mtpictd/agro_eco_regions\") \\\n",
    "    .filter(ee.Filter.eq(\"ae_regcode\", aez)).geometry()\n",
    "\n",
    "# -------------------------------\n",
    "# 2) CLASS GROUPING\n",
    "# -------------------------------\n",
    "# Original → grouped mapping\n",
    "ORIG  = [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "GROUP = [0, 1, 2, 2, 2, 6, 7, 8, 8,  8,  8,  12, 13]\n",
    "BAND  = 'predicted_label'\n",
    "\n",
    "def group_classes(img, band=BAND):\n",
    "    \"\"\"Map fine LULC classes to grouped classes (Water + Crop merged).\"\"\"\n",
    "    return img.select([band]).remap(ORIG, GROUP).rename('predicted_label').toInt()\n",
    "\n",
    "# -------------------------------\n",
    "# 3) LOAD: y5 FROM CORRECTED, y6 & y7 FROM ORIGINAL\n",
    "# -------------------------------\n",
    "def load_y5_corrected_y6_y7_original(aez, start_year, total_years, roi_boundary, project='raman-461708'):\n",
    "    \"\"\"\n",
    "    Assumes:\n",
    "      - Years: 1..total_years starting at start_year\n",
    "      - You want last 3 years: year5, year6, year7\n",
    "      - Year5 is already temporally corrected and stored as:\n",
    "          projects/{project}/assets/AEZ_{aez}_{Y5-07-01_Y6-06-30}_temporal_corrected\n",
    "      - Year6 & Year7 are still original LULC_v4_PanIndia_* assets.\n",
    "    \"\"\"\n",
    "    # Last 3 conceptual years in the 7-year sequence\n",
    "    y5 = start_year + (total_years - 3)  # e.g., 2017 + 4 = 2021\n",
    "    y6 = y5 + 1                           # 2022\n",
    "    y7 = y6 + 1                           # 2023\n",
    "\n",
    "    # Date tags\n",
    "    date5 = f\"{y5}-07-01_{y5+1}-06-30\"\n",
    "    date6 = f\"{y6}-07-01_{y6+1}-06-30\"\n",
    "    date7 = f\"{y7}-07-01_{y7+1}-06-30\"\n",
    "\n",
    "    # ---- Year 5: corrected AEZ asset ----\n",
    "    corr5_id = f\"projects/{project}/assets/AEZ_{aez}_{date5}_temporal_corrected\"\n",
    "    corr5 = ee.Image(corr5_id).clip(roi_boundary)\n",
    "\n",
    "    # corrected asset likely has band name 'y5f' (from your export).\n",
    "    # Make it look like original by renaming to 'predicted_label'\n",
    "    corr5_band = ee.String(corr5.bandNames().get(0))\n",
    "    corr5_pl   = corr5.select([corr5_band], ['predicted_label'])\n",
    "\n",
    "    # ---- Year 6 & 7: original pan-India assets ----\n",
    "    base = f\"projects/{project}/assets/LULC_v4_PanIndia_\"\n",
    "    img6 = ee.Image(f\"{base}{date6}\").clip(roi_boundary)\n",
    "    img7 = ee.Image(f\"{base}{date7}\").clip(roi_boundary)\n",
    "\n",
    "    return corr5_pl, img6, img7, (y5, y6, y7)\n",
    "\n",
    "corr5_pl, img6_orig, img7_orig, (y5, y6, y7) = load_y5_corrected_y6_y7_original(\n",
    "    aez=aez,\n",
    "    start_year=start_year,\n",
    "    total_years=total_years,\n",
    "    roi_boundary=roi_boundary,\n",
    "    project=project\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 4) GROUPED (y5, y6, y7)\n",
    "# -------------------------------\n",
    "# corr5_pl is already 'predicted_label' in original codebook; group it.\n",
    "y5_grp = group_classes(corr5_pl, band='predicted_label')\n",
    "\n",
    "# For y6 & y7, bands are already 'predicted_label' in the original LULC assets.\n",
    "y6_grp = group_classes(img6_orig, band='predicted_label')\n",
    "y7_grp = group_classes(img7_orig, band='predicted_label')\n",
    "\n",
    "# Stack as grouped y5, y6, y7\n",
    "seq_last3 = ee.Image.cat([\n",
    "    y5_grp.rename('y5'),\n",
    "    y6_grp.rename('y6'),\n",
    "    y7_grp.rename('y7')\n",
    "])\n",
    "\n",
    "print(\"Bands in seq_last3:\", seq_last3.bandNames().getInfo())\n",
    "\n",
    "# -------------------------------\n",
    "# 5) ADMISSIBILITY MATRIX & allow_flip(A,B)\n",
    "# -------------------------------\n",
    "# Grouped classes (excluding 0)\n",
    "# Order: [Built-up, Water, Tree, Barren, Crop, Scrub, Plantation]\n",
    "MAT_CLASSES = [1, 2, 6, 7, 8, 12, 13]\n",
    "\n",
    "# A \\ B (rows = target A, cols = current B): 1=allowed, 0=not allowed\n",
    "#            Bu Wa Tr Ba Cr Sc Pl\n",
    "ALLOW_TABLE = [\n",
    "    # A=Built-up\n",
    "               0, 0, 0, 1, 1, 1, 1,\n",
    "    # A=Water\n",
    "               0, 0, 1, 0, 0, 0, 0,\n",
    "    # A=Tree/Forest\n",
    "               1, 1, 0, 1, 1, 1, 1,\n",
    "    # A=Barren\n",
    "               1, 0, 1, 0, 1, 1, 1,\n",
    "    # A=Crop\n",
    "               0, 0, 1, 1, 0, 1, 0,\n",
    "    # A=Scrub\n",
    "               0, 0, 1, 1, 1, 0, 1,\n",
    "    # A=Plantation\n",
    "               1, 0, 1, 1, 0, 1, 0\n",
    "]\n",
    "\n",
    "ALLOW_TABLE_ARR = ee.Array(ALLOW_TABLE).reshape([7, 7])\n",
    "ALLOW_TABLE_IMG = ee.Image.constant(ALLOW_TABLE_ARR)\n",
    "\n",
    "def _class_to_index(x):\n",
    "    \"\"\"Map grouped class image -> index 0..6 (for MAT_CLASSES), else -1.\"\"\"\n",
    "    return ee.Image(x).remap(MAT_CLASSES, list(range(7)), -1).toInt()\n",
    "\n",
    "def allow_flip(A, B):\n",
    "    \"\"\"\n",
    "    Returns an image (0/1) indicating where flipping B -> A is allowed by the matrix.\n",
    "    A, B are grouped-class images.\n",
    "    \"\"\"\n",
    "    a = _class_to_index(A)\n",
    "    b = _class_to_index(B)\n",
    "    valid = a.gte(0).And(b.gte(0))\n",
    "    val = ALLOW_TABLE_IMG.arrayGet([a, b]).toInt()\n",
    "    return val.updateMask(valid).unmask(0).rename('allowFlip')\n",
    "\n",
    "# -------------------------------\n",
    "# 6) ABA FLIPS CENTERED AT YEAR 6\n",
    "# -------------------------------\n",
    "def detect_ABA_flips_year6(seq3):\n",
    "    \"\"\"\n",
    "    seq3: image with bands y5, y6, y7 (grouped labels).\n",
    "    Detects ABA patterns centered at year 6: (A, B, A) with B != A\n",
    "    and flipping B->A allowed by the admissibility matrix.\n",
    "\n",
    "    Returns:\n",
    "      - aba_mask: 1 where year 6 is an admissible ABA anomaly.\n",
    "      - y6c: corrected year-6 band with B flipped to A where aba_mask==1.\n",
    "    \"\"\"\n",
    "    y5 = seq3.select('y5')  # A (prev year, already temporally corrected)\n",
    "    y6 = seq3.select('y6')  # B (current / 6th year)\n",
    "    y7 = seq3.select('y7')  # A (next year / new 7th year)\n",
    "\n",
    "    # Raw ABA at center year 6: y5 == y7, y6 != y5\n",
    "    raw_ABA = y5.eq(y7).And(y6.neq(y5))\n",
    "\n",
    "    # Matrix constraint: only keep where B->A is allowed (A = y5, B = y6)\n",
    "    adm = allow_flip(y5, y6).eq(1)\n",
    "\n",
    "    aba_mask = raw_ABA.And(adm).rename('ABA6_allowed')  # 1 = valid anomaly at year 6\n",
    "\n",
    "    # Corrected y6: flip B -> A where allowed ABA\n",
    "    y6c = y6.where(aba_mask, y5).rename('y6c')\n",
    "\n",
    "    return aba_mask, y6c\n",
    "\n",
    "aba_mask, y6c = detect_ABA_flips_year6(seq_last3)\n",
    "seq_last3_corrected = seq_last3.addBands([aba_mask, y6c])\n",
    "\n",
    "print(\"Bands in corrected stack:\", seq_last3_corrected.bandNames().getInfo())\n",
    "\n",
    "# -------------------------------\n",
    "# 7) OPTIONAL VISUALIZATION\n",
    "# -------------------------------\n",
    "pallete_lulc = [\n",
    "  '000000','ff0000','74ccf4','1ca3ec','0f5e9c',\n",
    "  'f1c232','38761d','A9A9A9','BAD93E','f59d22',\n",
    "  'FF9371','b3561d','a9a9a9','84994F'\n",
    "]\n",
    "vis_params_lulc = {'min': 0, 'max': 13, 'palette': pallete_lulc}\n",
    "\n",
    "mask_vis = {\n",
    "    'min': 0,\n",
    "    'max': 1,\n",
    "    'palette': ['000000', 'ff00ff']  # 0=black, 1=magenta\n",
    "}\n",
    "\n",
    "Map = geemap.Map()\n",
    "url = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}'\n",
    "Map.layout.height = '800px'\n",
    "Map.add_tile_layer(url, name=\"Google Map\", attribution=\"Google\")\n",
    "Map.addLayer(seq_last3.select('y5'), vis_params_lulc, 'y5 grouped (before ABA correction)')\n",
    "Map.addLayer(seq_last3.select('y6'), vis_params_lulc, 'y6 grouped (before ABA correction)')\n",
    "Map.addLayer(seq_last3.select('y7'), vis_params_lulc, 'y7 grouped (before ABA correction)')\n",
    "Map.addLayer(seq_last3_corrected.select('y6c'), vis_params_lulc, 'y6 grouped (after ABA correction)')\n",
    "Map.addLayer(aba_mask, mask_vis, 'ABA flips on year 6 (allowed)')\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00401c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "chastainBandNames = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']\n",
    "\n",
    "# Regression model parameters from Table-4. MSI TOA reflectance as a function of OLI TOA reflectance.\n",
    "msiOLISlopes = [1.0946,1.0043,1.0524,0.8954,1.0049,1.0002]\n",
    "msiOLIIntercepts = [-0.0107,0.0026,-0.0015,0.0033,0.0065,0.0046]\n",
    "\n",
    "# Regression model parameters from Table-5. MSI TOA reflectance as a function of ETM+ TOA reflectance.\n",
    "msiETMSlopes = [1.10601,0.99091,1.05681,1.0045,1.03611,1.04011]\n",
    "msiETMIntercepts = [-0.0139,0.00411,-0.0024,-0.0076,0.00411,0.00861]\n",
    "\n",
    "# Regression model parameters from Table-6. OLI TOA reflectance as a function of ETM+ TOA reflectance.\n",
    "oliETMSlopes =[1.03501,1.00921,1.01991,1.14061,1.04351,1.05271];\n",
    "oliETMIntercepts = [-0.0055,-0.0008,-0.0021,-0.0163,-0.0045,0.00261]\n",
    "\n",
    "# Construct dictionary to handle all pairwise combos\n",
    "chastainCoeffDict = { 'MSI_OLI':[msiOLISlopes,msiOLIIntercepts,1], # check what the third item corresponds to\n",
    "                    'MSI_ETM':[msiETMSlopes,msiETMIntercepts,1],\n",
    "                    'OLI_ETM':[oliETMSlopes,oliETMIntercepts,1],\n",
    "                    'OLI_MSI':[msiOLISlopes,msiOLIIntercepts,0],\n",
    "                    'ETM_MSI':[msiETMSlopes,msiETMIntercepts,0],\n",
    "                    'ETM_OLI':[oliETMSlopes,oliETMIntercepts,0]\n",
    "                    }\n",
    "\n",
    "'''\n",
    "Function to mask cloudy pixels in Landsat-7\n",
    "'''\n",
    "def maskL7cloud(image):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "    return image.updateMask(mask).select(['B1', 'B2', 'B3' , 'B4' , 'B5' , 'B7']).rename('BLUE', 'GREEN', 'RED' , 'NIR' , 'SWIR1' , 'SWIR2')\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask cloudy pixels in Landsat-8\n",
    "'''\n",
    "def maskL8cloud(image):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "    return image.updateMask(mask).select(['B2', 'B3', 'B4' , 'B5' , 'B6' , 'B7']).rename('BLUE', 'GREEN', 'RED' , 'NIR' , 'SWIR1' , 'SWIR2')\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask clouds using the quality band of Sentinel-2 TOA\n",
    "'''\n",
    "def maskS2cloudTOA(image):\n",
    "    qa = image.select('QA60')\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10\n",
    "    cirrusBitMask = 1 << 11\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0));\n",
    "    return image.updateMask(mask).select(['B2', 'B3', 'B4', 'B8',  'B11', 'B12']).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "\n",
    "'''\n",
    "Get Landsat and Sentinel image collections\n",
    "'''\n",
    "def Get_L7_L8_S2_ImageCollections(inputStartDate, inputEndDate, roi_boundary):\n",
    "    # ------ Landsat 7 TOA\n",
    "    L7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_TOA') \\\n",
    "            .filterDate(inputStartDate, inputEndDate) \\\n",
    "            .filterBounds(roi_boundary) \\\n",
    "            .map(maskL7cloud)\n",
    "    # print('\\n Original Landsat 7 TOA dataset: \\n',L7.limit(1).getInfo())\n",
    "    # print('Number of images in Landsat 7 TOA dataset: \\t',L7.size().getInfo())\n",
    "\n",
    "    # ------ Landsat 8 TOA\n",
    "    L8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA') \\\n",
    "            .filterDate(inputStartDate, inputEndDate) \\\n",
    "            .filterBounds(roi_boundary) \\\n",
    "            .map(maskL8cloud)\n",
    "    # print('\\n Original Landsat 8 TOA dataset: \\n', L8.limit(1).getInfo())\n",
    "    # print('Number of images in Landsat 8 TOA dataset: \\t',L8.size().getInfo())\n",
    "\n",
    "    # ------ Sentinel-2 TOA\n",
    "    S2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
    "            .filterDate(inputStartDate, inputEndDate) \\\n",
    "            .filterBounds(roi_boundary)  \\\n",
    "            .map(maskS2cloudTOA)\n",
    "    # print('\\n Original Sentinel-2 TOA dataset: \\n',S2.limit(1).getInfo())\n",
    "    # print('Number of images in Sentinel 2 TOA dataset: \\t',S2.size().getInfo())\n",
    "\n",
    "    return L7, L8, S2\n",
    "\n",
    "\n",
    "'''\n",
    "Function to apply model in one direction\n",
    "'''\n",
    "def dir0Regression(img,slopes,intercepts):\n",
    "    return img.select(chastainBandNames).multiply(slopes).add(intercepts)\n",
    "\n",
    "\n",
    "'''\n",
    "Applying the model in the opposite direction\n",
    "'''\n",
    "def dir1Regression(img,slopes,intercepts):\n",
    "    return img.select(chastainBandNames).subtract(intercepts).divide(slopes)\n",
    "\n",
    "\n",
    "'''\n",
    "Function to correct one sensor to another\n",
    "'''\n",
    "def harmonizationChastain(img, fromSensor,toSensor):\n",
    "    # Get the model for the given from and to sensor\n",
    "    comboKey = fromSensor.upper() + '_' + toSensor.upper()\n",
    "    coeffList = chastainCoeffDict[comboKey]\n",
    "    slopes = coeffList[0]\n",
    "    intercepts = coeffList[1]\n",
    "    direction = ee.Number(coeffList[2])\n",
    "\n",
    "    # Apply the model in the respective direction\n",
    "    out = ee.Algorithms.If(direction.eq(0),dir0Regression(img,slopes,intercepts),dir1Regression(img,slopes,intercepts))\n",
    "    return ee.Image(out).copyProperties(img).copyProperties(img,['system:time_start'])\n",
    "\n",
    "\n",
    "'''\n",
    "Calibrate Landsat-8 (OLI) and Sentinel-2 (MSI) to Landsat-7 (ETM+)\n",
    "'''\n",
    "def Harmonize_L7_L8_S2(L7, L8, S2):\n",
    "    # harmonization\n",
    "    harmonized_L8 = L8.map( lambda img: harmonizationChastain(img, 'OLI','ETM') )\n",
    "    harmonized_S2 = S2.map( lambda img: harmonizationChastain(img, 'MSI','ETM') )\n",
    "\n",
    "    # Merge harmonized landsat-8 and sentinel-2 to landsat-7 image collection\n",
    "    harmonized_LandsatSentinel_ic = ee.ImageCollection(L7.merge(harmonized_L8).merge(harmonized_S2))\n",
    "    # print(harmonized_LandsatSentinel_ic.size().getInfo())\n",
    "    return harmonized_LandsatSentinel_ic\n",
    "\n",
    "\n",
    "'''\n",
    "Add NDVI band to harmonized image collection\n",
    "'''\n",
    "def addNDVI(image):\n",
    "    return image.addBands(image.normalizedDifference(['NIR', 'RED']).rename('NDVI')).float()\n",
    "\n",
    "\n",
    "'''\n",
    "Function definitions to get NDVI values at each 16-day composites\n",
    "'''\n",
    "def Get_NDVI_image_datewise(harmonized_LS_ic, roi_boundary):\n",
    "    def get_NDVI_datewise(date):\n",
    "        empty_band_image = ee.Image(0).float().rename(['NDVI']).updateMask(ee.Image(0).clip(roi_boundary))\n",
    "        return harmonized_LS_ic.select(['NDVI']) \\\n",
    "                                .filterDate(ee.Date(date), ee.Date(date).advance(16, 'day')) \\\n",
    "                                .merge(empty_band_image)\\\n",
    "                                .median() \\\n",
    "                                .set('system:time_start',ee.Date(date).millis())\n",
    "    return get_NDVI_datewise\n",
    "\n",
    "def Get_LS_16Day_NDVI_TimeSeries(inputStartDate, inputEndDate, harmonized_LS_ic, roi_boundary):\n",
    "    startDate = datetime.strptime(inputStartDate,\"%Y-%m-%d\")\n",
    "    endDate = datetime.strptime(inputEndDate,\"%Y-%m-%d\")\n",
    "\n",
    "    date_list = pd.date_range(start=startDate, end=endDate, freq='16D').tolist()\n",
    "    date_list = ee.List( [datetime.strftime(curr_date,\"%Y-%m-%d\") for curr_date in date_list] )\n",
    "\n",
    "    LSC =  ee.ImageCollection.fromImages(date_list.map(Get_NDVI_image_datewise(harmonized_LS_ic, roi_boundary)))\n",
    "\n",
    "    return LSC\n",
    "\n",
    "\n",
    "'''\n",
    "Pair available LSC and modis values for each time stamp.\n",
    "'''\n",
    "def pairLSModis(lsRenameBands):\n",
    "    def pair(feature):\n",
    "        date = ee.Date( feature.get('system:time_start') )\n",
    "        startDateT = date.advance(-8,'day')\n",
    "        endDateT = date.advance(8,'day')\n",
    "\n",
    "        # ------ MODIS VI ( We can add EVI to the band list later )\n",
    "        modis = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
    "                .filterDate(startDateT, endDateT) \\\n",
    "                .select(['NDVI','SummaryQA']) \\\n",
    "                .filterBounds(roi_boundary) \\\n",
    "                .median() \\\n",
    "                .rename(['NDVI_modis', 'SummaryQA_modis'])\n",
    "\n",
    "        return feature.rename(lsRenameBands).addBands(modis)\n",
    "    return pair\n",
    "\n",
    "\n",
    "'''\n",
    "Function to get Pearson Correlation Coffecient to perform GapFilling\n",
    "'''\n",
    "def get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, bandList):\n",
    "    corr = LSC_modis_paired_ic.filterBounds(roi_boundary) \\\n",
    "                                .select(bandList).toArray() \\\n",
    "                                .arrayReduce( reducer = ee.Reducer.pearsonsCorrelation(), axes=[0], fieldAxis=1 ) \\\n",
    "                                .arrayProject([1]).arrayFlatten([['c', 'p']])\n",
    "    return corr\n",
    "\n",
    "\n",
    "'''Use print(...) to write to this console.\n",
    "Fill gaps in LSC timeseries using modis data\n",
    "'''\n",
    "def gapfillLSM(LSC_modis_regression_model, LSC_bandName, modis_bandName):\n",
    "    def peformGapfilling(image):\n",
    "        offset = LSC_modis_regression_model.select('offset')\n",
    "        scale = LSC_modis_regression_model.select('scale')\n",
    "        nodata = -1\n",
    "\n",
    "        lsc_image = image.select(LSC_bandName)\n",
    "        modisfit = image.select(modis_bandName).multiply(scale).add(offset)\n",
    "\n",
    "        mask = lsc_image.mask()#update mask needs an input (no default input from the API document)\n",
    "        gapfill = lsc_image.unmask(nodata)\n",
    "        gapfill = gapfill.where(mask.Not(), modisfit)\n",
    "\n",
    "        '''\n",
    "        in SummaryQA,\n",
    "        0: Good data, use with confidence\n",
    "        1: Marginal data, useful but look at detailed QA for more information\n",
    "        2: Pixel covered with snow/ice\n",
    "        3: Pixel is cloudy\n",
    "        '''\n",
    "        qc_m = image.select('SummaryQA_modis').unmask(3)  # missing value is grouped as cloud\n",
    "        w_m  = modisfit.mask().rename('w_m').where(qc_m.eq(0), 0.8)  # default is 0.8\n",
    "        w_m = w_m.where(qc_m.eq(1), 0.5)   # Marginal\n",
    "        w_m = w_m.where(qc_m.gte(2), 0.2) # snow/ice or cloudy\n",
    "\n",
    "        # make sure these modis values are read where there is missing data from LandSat, Sentinel\n",
    "        w_l = gapfill.mask() # default is 1\n",
    "        w_l = w_l.where(mask.Not(), w_m)\n",
    "\n",
    "        return gapfill.addBands(w_l).rename(['gapfilled_'+LSC_bandName,'SummaryQA']) #have NDVI from modis and a summary of clarity for each\n",
    "\n",
    "    return peformGapfilling\n",
    "\n",
    "\n",
    "'''\n",
    "Function to combine LSC with Modis data\n",
    "'''\n",
    "def Combine_LS_Modis(LSC):\n",
    "    lsRenameBands = ee.Image(LSC.first()).bandNames().map( lambda band: ee.String(band).cat('_lsc') )\n",
    "    LSC_modis_paired_ic = LSC.map( pairLSModis(lsRenameBands) )\n",
    "\n",
    "    # Output contains scale, offset i.e. two bands\n",
    "    LSC_modis_regression_model_NDVI = LSC_modis_paired_ic.select(['NDVI_modis', 'NDVI_lsc']) \\\n",
    "                                                            .reduce(ee.Reducer.linearFit())\n",
    "\n",
    "    corr_NDVI = get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, ['NDVI_modis', 'NDVI_lsc'])\n",
    "    LSMC_NDVI = LSC_modis_paired_ic.map(gapfillLSM(LSC_modis_regression_model_NDVI, 'NDVI_lsc', 'NDVI_modis'))\n",
    "\n",
    "    return LSMC_NDVI\n",
    "\n",
    "\n",
    "'''\n",
    "Mask out low quality pixels\n",
    "'''\n",
    "def mask_low_QA(lsmc_image):\n",
    "    low_qa = lsmc_image.select('SummaryQA').neq(0.2)\n",
    "    return lsmc_image.updateMask(low_qa).copyProperties(lsmc_image, ['system:time_start'])\n",
    "\n",
    "\n",
    "'''\n",
    "Add image timestamp to each image in time series\n",
    "'''\n",
    "def add_timestamp(image):\n",
    "    timeImage = image.metadata('system:time_start').rename('timestamp')\n",
    "    timeImageMasked = timeImage.updateMask(image.mask().select(0))\n",
    "    return image.addBands(timeImageMasked)\n",
    "\n",
    "\n",
    "'''\n",
    "Perform linear interpolation on missing values\n",
    "'''\n",
    "def performInterpolation(image):\n",
    "    image = ee.Image(image)\n",
    "    beforeImages = ee.List(image.get('before'))\n",
    "    beforeMosaic = ee.ImageCollection.fromImages(beforeImages).mosaic()\n",
    "    afterImages = ee.List(image.get('after'))\n",
    "    afterMosaic = ee.ImageCollection.fromImages(afterImages).mosaic()\n",
    "\n",
    "    # Interpolation formula\n",
    "    # y = y1 + (y2-y1)*((t – t1) / (t2 – t1))\n",
    "    # y = interpolated image\n",
    "    # y1 = before image\n",
    "    # y2 = after image\n",
    "    # t = interpolation timestamp\n",
    "    # t1 = before image timestamp\n",
    "    # t2 = after image timestamp\n",
    "\n",
    "    t1 = beforeMosaic.select('timestamp').rename('t1')\n",
    "    t2 = afterMosaic.select('timestamp').rename('t2')\n",
    "    t = image.metadata('system:time_start').rename('t')\n",
    "    timeImage = ee.Image.cat([t1, t2, t])\n",
    "    timeRatio = timeImage.expression('(t - t1) / (t2 - t1)', {\n",
    "                    't': timeImage.select('t'),\n",
    "                    't1': timeImage.select('t1'),\n",
    "                    't2': timeImage.select('t2'),\n",
    "                })\n",
    "\n",
    "    interpolated = beforeMosaic.add((afterMosaic.subtract(beforeMosaic).multiply(timeRatio)))\n",
    "    result = image.unmask(interpolated)\n",
    "    fill_value = ee.ImageCollection([beforeMosaic, afterMosaic]).mosaic()\n",
    "    result = result.unmask(fill_value)\n",
    "\n",
    "    return result.copyProperties(image, ['system:time_start'])\n",
    "\n",
    "\n",
    "def interpolate_timeseries(S1_TS):\n",
    "    lsmc_masked = S1_TS.map(mask_low_QA)\n",
    "    filtered = lsmc_masked.map(add_timestamp)\n",
    "\n",
    "    # Time window in which we are willing to look forward and backward for unmasked pixel in time series\n",
    "    timeWindow = 120\n",
    "\n",
    "    # Define a maxDifference filter to find all images within the specified days. Convert days to milliseconds.\n",
    "    millis = ee.Number(timeWindow).multiply(1000*60*60*24)\n",
    "    # Filter says that pick only those timestamps which lie between the 2 timestamps not more than millis difference apart\n",
    "    maxDiffFilter = ee.Filter.maxDifference(\n",
    "                                difference = millis,\n",
    "                                leftField = 'system:time_start',\n",
    "                                rightField = 'system:time_start',\n",
    "                                )\n",
    "\n",
    "    # Filter to find all images after a given image. Compare the image's timstamp against other images.\n",
    "    # Images ahead of target image should have higher timestamp.\n",
    "    lessEqFilter = ee.Filter.lessThanOrEquals(\n",
    "                                leftField = 'system:time_start',\n",
    "                                rightField = 'system:time_start'\n",
    "                            )\n",
    "\n",
    "    # Similarly define this filter to find all images before a given image\n",
    "    greaterEqFilter = ee.Filter.greaterThanOrEquals(\n",
    "                                leftField = 'system:time_start',\n",
    "                                rightField = 'system:time_start'\n",
    "                            )\n",
    "\n",
    "    # Apply first join to find all images that are after the target image but within the timeWindow\n",
    "    filter1 = ee.Filter.And( maxDiffFilter, lessEqFilter )\n",
    "    join1 = ee.Join.saveAll(\n",
    "                    matchesKey = 'after',\n",
    "                    ordering = 'system:time_start',\n",
    "                    ascending = False\n",
    "            )\n",
    "    join1Result = join1.apply(\n",
    "                    primary = filtered,\n",
    "                    secondary = filtered,\n",
    "                    condition = filter1\n",
    "                    )\n",
    "\n",
    "    # Apply first join to find all images that are after the target image but within the timeWindow\n",
    "    filter2 = ee.Filter.And( maxDiffFilter, greaterEqFilter )\n",
    "    join2 = ee.Join.saveAll(\n",
    "                    matchesKey = 'before',\n",
    "                    ordering = 'system:time_start',\n",
    "                    ascending = True\n",
    "            )\n",
    "    join2Result = join2.apply(\n",
    "                    primary = join1Result,\n",
    "                    secondary = join1Result,\n",
    "                    condition = filter2\n",
    "                    )\n",
    "\n",
    "    interpolated_S1_TS = ee.ImageCollection(join2Result.map(performInterpolation))\n",
    "\n",
    "    return interpolated_S1_TS\n",
    "\n",
    "\n",
    "'''\n",
    "Function Definition to get Padded NDVI LSMC timeseries image for a given ROI\n",
    "'''\n",
    "def Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary):\n",
    "    L7, L8, S2 = Get_L7_L8_S2_ImageCollections(startDate, endDate, roi_boundary)\n",
    "\n",
    "    harmonized_LS_ic = Harmonize_L7_L8_S2(L7, L8, S2)\n",
    "    harmonized_LS_ic = harmonized_LS_ic.map(addNDVI)\n",
    "    LSC = Get_LS_16Day_NDVI_TimeSeries(startDate, endDate, harmonized_LS_ic, roi_boundary)\n",
    "    LSMC_NDVI = Combine_LS_Modis(LSC)\n",
    "    Interpolated_LSMC_NDVI = interpolate_timeseries(LSMC_NDVI)\n",
    "    final_LSMC_NDVI_TS = Interpolated_LSMC_NDVI.select(['gapfilled_NDVI_lsc']).toBands()\n",
    "    final_LSMC_NDVI_TS = final_LSMC_NDVI_TS.clip(roi_boundary)\n",
    "\n",
    "    input_bands = final_LSMC_NDVI_TS.bandNames()\n",
    "    return final_LSMC_NDVI_TS, input_bands\n",
    "\n",
    "\n",
    "'''\n",
    "Function definition to compute euclidean distance to each cluster centroid\n",
    "features ---> clusters\n",
    "flattened ---> time series image clipped to target area\n",
    "input_bands ---> band names for time series image\n",
    "studyarea ---> geometry of region of interest\n",
    "'''\n",
    "# Function to get distances as required from each pixel to each cluster centroid\n",
    "def Get_Euclidean_Distance(cluster_centroids, roi_timeseries_img, input_bands, roi_boundary):\n",
    "\n",
    "    def wrapper(curr_centroid):\n",
    "        temp_img = ee.Image()\n",
    "        curr_centroid = ee.Feature(curr_centroid).setGeometry(roi_boundary)\n",
    "        temp_fc = ee.FeatureCollection( [curr_centroid] )\n",
    "        class_img = temp_fc.select(['class']).reduceToImage(['class'], ee.Reducer.first()).rename(['class'])\n",
    "        def create_img(band_name):\n",
    "            return temp_fc.select([band_name]).reduceToImage([band_name], ee.Reducer.first()).rename([band_name])\n",
    "\n",
    "        temp_img = input_bands.map(create_img)\n",
    "        empty = ee.Image()\n",
    "        temp_img = ee.Image( temp_img.iterate( lambda img, prev: ee.Image(prev).addBands(img) , empty))\n",
    "\n",
    "        temp_img = temp_img.select(temp_img.bandNames().remove('constant'))\n",
    "        distance = roi_timeseries_img.spectralDistance(temp_img, 'sed')\n",
    "        confidence = ee.Image(1.0).divide(distance).rename(['confidence'])\n",
    "        distance = distance.addBands(confidence)\n",
    "        return distance.addBands(class_img.rename(['class'])).set('class', curr_centroid.get('class'))\n",
    "\n",
    "    return cluster_centroids.map(wrapper)\n",
    "\n",
    "\n",
    "'''\n",
    "Function definition to get final prediction image from distance images\n",
    "'''\n",
    "def Get_final_prediction_image(distance_imgs_list):\n",
    "    # Denominator is an image that is sum of all confidences to each cluster\n",
    "    sum_of_distances = ee.ImageCollection( distance_imgs_list ).select(['confidence']).sum().unmask()\n",
    "    distance_imgs_ic = ee.ImageCollection( distance_imgs_list ).select(['distance','class'])\n",
    "\n",
    "    # array is an image where distance band is an array of distances to each cluster centroid and class band is an array of classes associated with each cluster\n",
    "    array_img = ee.ImageCollection(distance_imgs_ic).toArray()\n",
    "\n",
    "    axes = {'image': 0, 'band':1}\n",
    "    sort = array_img.arraySlice(axes['band'], 0, 1)\n",
    "    sorted = array_img.arraySort(sort)\n",
    "\n",
    "    # take the first image only\n",
    "    values = sorted.arraySlice(axes['image'], 0, 1)\n",
    "    # convert back to an image\n",
    "    min = values.arrayProject([axes['band']]).arrayFlatten([['distance', 'class']])\n",
    "    # Extract the hard classification\n",
    "    predicted_class_img = min.select(1)\n",
    "    predicted_class_img = predicted_class_img.rename(['predicted_label'])\n",
    "\n",
    "    return predicted_class_img\n",
    "\n",
    "## My Helper Functions\n",
    "def change_clusters(cluster_centroids):\n",
    "    size = cluster_centroids.size().getInfo()\n",
    "    features = []\n",
    "    for i in range(size):\n",
    "        features.append(ee.Feature(cluster_centroids.toList(size).get(i)).set(\"class\", 13+i))\n",
    "    return ee.FeatureCollection(features)\n",
    "\n",
    "\n",
    "def get_cropping_frequency(roi_boundary, startDate, endDate):\n",
    "    cluster_centroids = ee.FeatureCollection('projects/ee-indiasat/assets/L3_LULC_Clusters/Final_Level3_PanIndia_Clusters')\n",
    "    ignore_clusters = [12] # remove invalid clusters\n",
    "    cluster_centroids = cluster_centroids.filter(ee.Filter.Not( ee.Filter.inList('class', ignore_clusters)))\n",
    "    \n",
    "    final_LSMC_NDVI_TS, input_bands =  Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary)\n",
    "    distance_imgs_list = Get_Euclidean_Distance(cluster_centroids, final_LSMC_NDVI_TS, input_bands, roi_boundary)\n",
    "    final_classified_img = Get_final_prediction_image(distance_imgs_list)\n",
    "    ### adding Cluster values after 12\n",
    "    #cluster_centroids = change_clusters(cluster_centroids)\n",
    "    distance_imgs_list = Get_Euclidean_Distance(cluster_centroids, final_LSMC_NDVI_TS, input_bands, roi_boundary)\n",
    "    final_cluster_classified_img = Get_final_prediction_image(distance_imgs_list)\n",
    "    final_cluster_classified_img = final_cluster_classified_img.rename(['predicted_cluster'])\n",
    "    final_classified_img = final_classified_img.addBands(final_cluster_classified_img)\n",
    "    return final_classified_img, final_LSMC_NDVI_TS\n",
    "\n",
    "def get_six_year_cropping_frequency_rasters(roi_boundary, start_year, num_years=6):\n",
    "    \"\"\"\n",
    "    Uses your existing get_cropping_frequency(roi_boundary, startDate, endDate)\n",
    "    and produces a list of 6 yearly cropping-frequency images.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Does NOT rename or modify your existing functions/variables.\n",
    "    - Each output image is clipped to roi_boundary (as your pipeline already does inside Get_Padded_NDVI_TS_Image).\n",
    "    - Output list order: [Y1, Y2, ..., Y6] where\n",
    "        Y1 = start_year-07-01 to start_year+1-06-30\n",
    "        ...\n",
    "        Y6 = start_year+5-07-01 to start_year+6-06-30\n",
    "\n",
    "    Returns:\n",
    "      crop_freq_imgs: Python list of ee.Image (each has band 'predicted_label' and 'predicted_cluster')\n",
    "      date_ranges:    Python list of (startDate, endDate) strings for bookkeeping\n",
    "    \"\"\"\n",
    "    crop_freq_imgs = []\n",
    "    date_ranges = []\n",
    "\n",
    "    for i in range(num_years):\n",
    "        y1 = start_year + i\n",
    "        y2 = y1 + 1\n",
    "\n",
    "        currStartDate = f\"{y1}-07-01\"\n",
    "        currEndDate   = f\"{y2}-06-30\"\n",
    "\n",
    "        # Your function returns:\n",
    "        #   final_classified_img: bands ['predicted_label', 'predicted_cluster']\n",
    "        #   final_LSMC_NDVI_TS:   NDVI time-series (not needed here)\n",
    "        cropping_frequency_img, _ = get_cropping_frequency(roi_boundary, currStartDate, currEndDate)\n",
    "\n",
    "        # Keep as-is (same variable names, same band names)\n",
    "        crop_freq_imgs.append(cropping_frequency_img.select(['predicted_label',]))\n",
    "        date_ranges.append((currStartDate, currEndDate))\n",
    "\n",
    "    return crop_freq_imgs, date_ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877721b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------- MERGED CLASS CONSTANTS & HELPERS (if not already defined) ---------\n",
    "ORIG  = [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "GROUP = [0, 1, 2, 2, 2, 6, 7, 8, 8,  8,  8,  12, 13]\n",
    "\n",
    "WATER_SET = ee.List([2, 3, 4])          # original water subclasses\n",
    "CROP_SET  = ee.List([8, 9, 10, 11])     # original crop subclasses\n",
    "\n",
    "def _is_in_list(img, vals):\n",
    "    # vals is ee.List of ints\n",
    "    return ee.Image(img).remap(vals, ee.List.repeat(1, vals.size()), 0).eq(1)\n",
    "\n",
    "def _group_from_orig(orig_img):\n",
    "    # orig_img: ee.Image single band predicted_label\n",
    "    return orig_img.remap(ORIG, GROUP).toInt()\n",
    "\n",
    "def _safe_water_source(orig_img):\n",
    "    \"\"\"\n",
    "    Ensure output is a valid water subclass. If orig_img isn't water (2/3/4), fall back to 2.\n",
    "    \"\"\"\n",
    "    isw = _is_in_list(orig_img, WATER_SET)\n",
    "    return ee.Image(orig_img).where(isw.Not(), 2).toInt()\n",
    "\n",
    "\n",
    "def reinstate_merged_classes_year6(\n",
    "    original6_img,          # ee.Image, original year-6 LULC (fine classes), band 'predicted_label'\n",
    "    grouped_y6c,            # ee.Image, grouped corrected year-6 band (y6c, values in {0,1,2,6,7,8,12,13})\n",
    "    original5_img,          # ee.Image, corrected year-5 LULC (fine classes), band 'predicted_label'\n",
    "    crop_intensity6_img=None  # ee.Image for crop frequency/intensity, band 'predicted_label'\n",
    "):\n",
    "    \"\"\"\n",
    "    Reinstates water subclasses (2,3,4) and crop subclasses (8,9,10,11) for the\n",
    "    corrected year-6 grouped labels.\n",
    "\n",
    "    Logic:\n",
    "      - Non-merged classes (1,6,7,12,13) are written directly from grouped_y6c.\n",
    "      - If grouped_y6c == Water(2):\n",
    "            * If original6 already water (2/3/4), keep it.\n",
    "            * Else, copy water subclass from year-5 (original5_img).\n",
    "              If year-5 isn't water, fall back to generic 2.\n",
    "      - If grouped_y6c == Crop(8):\n",
    "            * If original6 already crop (8/9/10/11), keep it.\n",
    "            * Else, use crop_intensity6_img (recomputed cropping frequency for year 6).\n",
    "    \"\"\"\n",
    "\n",
    "    # Fine labels for year 6 and year 5\n",
    "    orig6 = ee.Image(original6_img).select('predicted_label').toInt()\n",
    "    orig5 = ee.Image(original5_img).select('predicted_label').toInt()\n",
    "\n",
    "    # Grouped originals and grouped corrected\n",
    "    orig_grp6 = _group_from_orig(orig6)\n",
    "    corr_grp6 = ee.Image(grouped_y6c).toInt()\n",
    "\n",
    "    # Start with original year-6 labels\n",
    "    final6 = orig6\n",
    "\n",
    "    # Flags for corrected water/crop in grouped space\n",
    "    isWaterCorr = corr_grp6.eq(2)\n",
    "    isCropCorr  = corr_grp6.eq(8)\n",
    "\n",
    "    # ------------- (A) Non-merged classes -------------\n",
    "    # Non-merged: {Built-up(1), Tree(6), Barren(7), Scrub(12), Plantation(13)}\n",
    "    nonMerged = isWaterCorr.Or(isCropCorr).Not()\n",
    "    final6 = final6.where(\n",
    "        nonMerged.And(corr_grp6.neq(orig_grp6)),\n",
    "        corr_grp6\n",
    "    )\n",
    "\n",
    "    # ------------- (B) Crop re-introduction -------------\n",
    "    # Here we use your recomputed cropping frequency for year 6\n",
    "    if crop_intensity6_img is not None:\n",
    "        crop_pred6 = ee.Image(crop_intensity6_img).select('predicted_label').toInt()\n",
    "    else:\n",
    "        crop_pred6 = ee.Image(8).toInt()  # fallback\n",
    "\n",
    "    orig_is_crop = _is_in_list(orig6, CROP_SET)\n",
    "    crop_fill = orig6.where(orig_is_crop.Not(), crop_pred6).toInt()\n",
    "    final6 = final6.where(isCropCorr, crop_fill)\n",
    "\n",
    "    # ------------- (C) Water re-introduction -------------\n",
    "    orig_is_water = _is_in_list(orig6, WATER_SET)\n",
    "\n",
    "    # For singlet ABA at year 6, use year 5 as the temporal reference\n",
    "    prev1  = orig5\n",
    "    prev1w = _safe_water_source(prev1)\n",
    "\n",
    "    water_source = prev1w\n",
    "    water_fill = orig6.where(orig_is_water.Not(), water_source).toInt()\n",
    "    final6 = final6.where(isWaterCorr, water_fill)\n",
    "\n",
    "    return final6.rename('y6f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d619074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6935fbf3a63b41039ee780ed58cd1c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=912.0, center=[0, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], position='top…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- Year indices for your 6-year window -----\n",
    "y1 = start_year          # e.g., 2017\n",
    "y6 = start_year + 5      # sixth year\n",
    "y7 = y6 + 1              # next year (for date window)\n",
    "\n",
    "start6 = f\"{y6}-07-01\"\n",
    "end6   = f\"{y7}-06-30\"\n",
    "\n",
    "# 1. Recompute cropping frequency for year 6 (as you do for earlier years)\n",
    "crop_freq6_img, _ = get_cropping_frequency(\n",
    "    roi_boundary=roi_boundary,\n",
    "    startDate=start6,\n",
    "    endDate=end6\n",
    ")\n",
    "# crop_freq6_img has band 'predicted_label' (cluster-based cropping frequency class)\n",
    "\n",
    "# 2. Reinstate merged classes for year 6, using:\n",
    "#    - img6_orig: original fine LULC for year 6\n",
    "#    - corr5_pl:  corrected fine LULC for year 5\n",
    "#    - seq_last3_corrected: image with band 'y6c' (grouped corrected year 6)\n",
    "final_y6 = reinstate_merged_classes_year6(\n",
    "    original6_img=img6_orig,\n",
    "    grouped_y6c=seq_last3_corrected.select('y6c'),\n",
    "    original5_img=corr5_pl,\n",
    "    crop_intensity6_img=crop_freq6_img   # this is your recomputed cropping intensity for year 6\n",
    ")\n",
    "\n",
    "# (Optional) visualize\n",
    "pallete_lulc = [\n",
    "  '000000','ff0000','74ccf4','1ca3ec','0f5e9c',\n",
    "  'f1c232','38761d','A9A9A9','BAD93E','f59d22',\n",
    "  'FF9371','b3561d','a9a9a9','84994F'\n",
    "]\n",
    "vis_params_lulc = {'min': 0, 'max': 13, 'palette': pallete_lulc}\n",
    "\n",
    "Map.addLayer(final_y6, vis_params_lulc, 'year 6 final (un-grouped with new crop freq)')\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a356ada9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started export: projects/raman-461708/assets/AEZ_1_2022-07-01_2023-06-30_temporal_corrected\n"
     ]
    }
   ],
   "source": [
    "# --- PARAMETERS ---\n",
    "project    = 'raman-461708'\n",
    "scale      = 10\n",
    "maxPixels  = 1e13\n",
    "\n",
    "# You already have:\n",
    "#   aez\n",
    "#   start_year\n",
    "#   roi_boundary\n",
    "#   final_y6  (image with band 'y6f')\n",
    "\n",
    "# Compute the year-span for the 6th year\n",
    "y6 = start_year + 5      # sixth year start\n",
    "y7 = y6 + 1              # sixth year end\n",
    "\n",
    "date_tag = f\"{y6}-07-01_{y7}-06-30\"\n",
    "\n",
    "# EXACT naming convention you provided\n",
    "asset_id = f\"projects/{project}/assets/AEZ_{aez}_{date_tag}_temporal_corrected\"\n",
    "\n",
    "# Task description\n",
    "desc = f\"AEZ_{aez}_{y6}_{y7}_temporal_corrected\"\n",
    "\n",
    "# Start export\n",
    "task = ee.batch.Export.image.toAsset(\n",
    "    image     = final_y6.clip(roi_boundary),  # should contain band 'y6f'\n",
    "    description = desc,\n",
    "    assetId   = asset_id,\n",
    "    region    = roi_boundary,\n",
    "    scale     = scale,\n",
    "    maxPixels = maxPixels\n",
    ")\n",
    "\n",
    "task.start()\n",
    "print(f\"Started export: {asset_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ffc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
