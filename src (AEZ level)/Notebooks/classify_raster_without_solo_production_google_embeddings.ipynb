{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBg2jArDvSv3"
   },
   "source": [
    "## Authenticate to Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GXSXdKfivbFF"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "ee.Authenticate() #Uncomment this whenever needed, once done usually not needed for 1-2 days\n",
    "ee.Initialize(project='raman-461708')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the two AEZ_7_boundaries assets\n",
    "aez_boundaries_0 = ee.FeatureCollection('projects/raman-461708/assets/AEZ_7_boundaries_0')\n",
    "aez_boundaries_1 = ee.FeatureCollection('projects/raman-461708/assets/AEZ_7_boundaries_1')\n",
    "\n",
    "# Merge the two feature collections into one\n",
    "merged_aez_boundaries = aez_boundaries_0.merge(aez_boundaries_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"AEZ_7/status.csv\")\n",
    "\n",
    "# Function to create a tile (rectangle polygon) from diagonal points\n",
    "def create_tile_from_points(points):\n",
    "    # points is a string representation of a tuple, e.g. \"((lat1, lon1), (lat2, lon2))\"\n",
    "    if isinstance(points, str):\n",
    "        points_tuple = ast.literal_eval(points)\n",
    "    else:\n",
    "        points_tuple = points\n",
    "    (lon1, lat1), (lon2, lat2) = points_tuple\n",
    "    # Get min/max for lat/lon to define the rectangle\n",
    "    min_lat, max_lat = min(lat1, lat2), max(lat1, lat2)\n",
    "    min_lon, max_lon = min(lon1, lon2), max(lon1, lon2)\n",
    "    # Return the four corners in order (clockwise or counterclockwise)\n",
    "    return [\n",
    "        (min_lat, min_lon),\n",
    "        (min_lat, max_lon),\n",
    "        (max_lat, max_lon),\n",
    "        (max_lat, min_lon),\n",
    "        (min_lat, min_lon)  # close the polygon\n",
    "    ]\n",
    "\n",
    "# Create a new column 'tile' with the rectangle polygon for each row\n",
    "df['tile'] = df['points'].apply(create_tile_from_points)\n",
    "tiles = df['tile'].tolist()\n",
    "\n",
    "# Function to create a single tile encompassing four smaller tiles\n",
    "#def create_group_tile(group):\n",
    "#    all_points = [point for points in group['tile'] for point in points]\n",
    "#    lons = [lon for lat, lon in all_points]\n",
    "#    lats = [lat for lat, lon in all_points]\n",
    "#    min_lat, max_lat = min(lats), max(lats)\n",
    "#    min_lon, max_lon = min(lons), max(lons)\n",
    "#    return [\n",
    "#        (min_lat, min_lon),\n",
    "#        (min_lat, max_lon),\n",
    "#        (max_lat, max_lon),\n",
    "#        (max_lat, min_lon),\n",
    "#        (min_lat, min_lon)  # close the polygon\n",
    "#    ]\n",
    "\n",
    "# Create a new column 'tile' with the rectangle polygon for each row\n",
    "#df['tile'] = df['points'].apply(create_tile_from_points)\n",
    "\n",
    "# Group every four rows and create a single tile encompassing them\n",
    "#grouped_tiles = []\n",
    "#for i in range(0, len(df), 4):\n",
    "#    group_df = df.iloc[i:i+4]\n",
    "#    grouped_tile = create_group_tile(group_df)\n",
    "#    grouped_tiles.append(grouped_tile)\n",
    "\n",
    "#tiles = grouped_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_2 started\n",
      "Task tile_2 status: READY\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 203\u001b[39m\n\u001b[32m    197\u001b[39m     \u001b[38;5;66;03m#all_filtered_samples_df = fc_to_df(all_filtered_samples)\u001b[39;00m\n\u001b[32m    198\u001b[39m     \u001b[38;5;66;03m#all_filtered_samples_df.to_csv('output_'+str(index)+'.csv', index=False)\u001b[39;00m\n\u001b[32m    199\u001b[39m     \u001b[38;5;66;03m#print(\"Done tile no \", index)\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tiles)):\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     process_tile(tiles[i], i)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 196\u001b[39m, in \u001b[36mprocess_tile\u001b[39m\u001b[34m(tile, index)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mCOMPLETED\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mFAILED\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCANCELLED\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m time.sleep(\u001b[32m30\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# Function to chunk a list into sublists of size p\n",
    "#def chunk_list(lst, p):\n",
    "#    return [lst[i:i + p] for i in range(0, len(lst), p)]\n",
    "\n",
    "# Define the number of tiles per group\n",
    "#p = 1\n",
    "\n",
    "# Chunk the tiles into groups\n",
    "#tile_groups = chunk_list(tiles, p)\n",
    "\n",
    "def fc_to_df(fc):\n",
    "    # Get the data from the FeatureCollection\n",
    "    features = fc.getInfo()['features']\n",
    "    \n",
    "    # Extract properties and geometry\n",
    "    data = [feature['properties'] for feature in features]\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def process_tile(tile, index):\n",
    "    tile = ee.FeatureCollection(ee.Geometry.Polygon(tile))\n",
    "    \n",
    "    #aez_region = ee.FeatureCollection(\"users/mtpictd/agro_eco_regions\").filter(ee.Filter.eq(\"ae_regcode\", 7)).filter(tile)\n",
    "    g_embs = ee.ImageCollection(\"GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL\").filterDate('2024-01-01', '2025-01-01').filterBounds(tile).mosaic()\n",
    "\n",
    "    mapping = {\n",
    "        \"farm\": 1,\n",
    "        \"plantation\": 2,\n",
    "        \"scrubland\": 3,\n",
    "        \"rest\": 0\n",
    "    }\n",
    "    reversed_mapping = {v: k for k, v in mapping.items()}\n",
    "    reversed_ee_mapping = ee.Dictionary(reversed_mapping)\n",
    "\n",
    "    easy_farm = [\n",
    "        ee.Filter.gte(\"rect\", 0.67),\n",
    "        ee.Filter.gt(\"size\", 500),\n",
    "        ee.Filter.lt(\"size\", 2000),\n",
    "        ee.Filter.lt(\"ent\", 1)\n",
    "        ]\n",
    "    easy_scrubland = [\n",
    "        ee.Filter.gte(\"size\", 60000)\n",
    "        ]\n",
    "    easy_plantation = [\n",
    "        ee.Filter.lt(\"area\", 20000),\n",
    "        ee.Filter.gt(\"area\", 1000)\n",
    "    ]\n",
    "\n",
    "    all = merged_aez_boundaries.filterBounds(tile)\n",
    "    farm = all.filter(ee.Filter.And(*easy_farm))\n",
    "    scrubland = all.filter(ee.Filter.And(easy_scrubland))\n",
    "    plantation = all.filter(ee.Filter.eq(\"class\", \"plantation\")).map(lambda x: x.set(\"area\", x.geometry().area())).filter(ee.Filter.And(easy_plantation))\n",
    "    mapping = {\n",
    "        \"farm\": 1,\n",
    "        \"plantation\": 2,\n",
    "        \"scrubland\": 3,\n",
    "        \"rest\": 0\n",
    "    }\n",
    "    reversed_mapping = {v: k for k, v in mapping.items()}\n",
    "    reversed_ee_mapping = ee.Dictionary(reversed_mapping)\n",
    "\n",
    "    easy_farm = [\n",
    "        ee.Filter.gte(\"rect\", 0.67),\n",
    "        ee.Filter.gt(\"size\", 500),\n",
    "        ee.Filter.lt(\"size\", 2000),\n",
    "        ee.Filter.lt(\"ent\", 1)\n",
    "        ]\n",
    "\n",
    "    easy_scrubland = [\n",
    "        ee.Filter.gte(\"size\", 60000)\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "    #Filter out farms which doesnot have 3 nearby farms (Removing solo farms inside scrublands)\n",
    "    farm_buffer = farm.map(lambda x: x.buffer(10))\n",
    "    farm_image = ee.Image(0)\n",
    "    farm_mask = farm_image.clip(farm_buffer).mask()\n",
    "    farm_vectors = farm_mask.toInt().reduceToVectors(\n",
    "        geometry=farm.geometry(),\n",
    "        scale=10,  # Change based on your resolution\n",
    "        geometryType='polygon',\n",
    "        labelProperty='zone',\n",
    "        reducer=ee.Reducer.countEvery(),\n",
    "        maxPixels=1e8\n",
    "    ) \n",
    "    farm_vectors = farm_vectors.filter(ee.Filter.eq('zone', 1)).map(lambda x: x.set(\"count\", farm.filterBounds(x.geometry()).size())).filter(ee.Filter.gt('count', 3))\n",
    "\n",
    "    #farm_vectors = get_feature_collection(\"projects/ee-raman/assets/\" + block + \"_farm_clusters\")\n",
    "    farm = farm.filterBounds(farm_vectors)\n",
    "    lulc_v3 = ee.Image(\"projects/corestack-datasets/assets/datasets/LULC_v3_river_basin/pan_india_lulc_v3_2023_2024\").clip(tile.geometry())\n",
    "    classes_of_interest = [8, 9, 10, 11]\n",
    "    masked_lulc = lulc_v3.remap(classes_of_interest, [1]*len(classes_of_interest))  # 1 where class is of interest, 0 elsewhere\n",
    "\n",
    "    # Step 2: Function to compute % area of interest inside each feature\n",
    "    def filter_by_lulc(feature):\n",
    "        geom = feature.geometry()\n",
    "        scale = 30  # Set resolution appropriate to your LULC data\n",
    "\n",
    "        # Area of interest within polygon (masked_lulc == 1)\n",
    "        interest_area_img = ee.Image.pixelArea().updateMask(masked_lulc)\n",
    "        interest_area = interest_area_img.reduceRegion(\n",
    "            reducer=ee.Reducer.sum(),\n",
    "            geometry=geom,\n",
    "            scale=scale,\n",
    "            maxPixels=1e8\n",
    "        ).get('area')\n",
    "\n",
    "        # Total area of the polygon\n",
    "        total_area = ee.Image.pixelArea().reduceRegion(\n",
    "            reducer=ee.Reducer.sum(),\n",
    "            geometry=geom,\n",
    "            scale=scale,\n",
    "            maxPixels=1e8\n",
    "        ).get('area')\n",
    "\n",
    "        # Compute % and add it as a property\n",
    "        percent_interest = ee.Number(interest_area).divide(ee.Number(total_area)).multiply(100)\n",
    "        return feature.set('percent_interest', percent_interest)\n",
    "\n",
    "    # Step 3: Apply to FeatureCollection\n",
    "    scrubland = scrubland.map(filter_by_lulc)\n",
    "\n",
    "    # Step 4: Filter features with > 50% area of interest\n",
    "    def strictly_inside_roi(feature):\n",
    "        return feature.set('inside', all.union().geometry().contains(feature.geometry()))\n",
    "\n",
    "    scrubland = scrubland.filter(ee.Filter.lt('percent_interest', 50)).map(strictly_inside_roi)\n",
    "    scrubland = scrubland.filter(ee.Filter.eq('inside', True))\n",
    "\n",
    "    label_image = ee.Image(0).rename(\"label\")\n",
    "    farm_mask = label_image.clip(farm).mask()\n",
    "    scrubland_mask = label_image.clip(scrubland).mask()\n",
    "    plantation_mask = label_image.clip(plantation).mask()\n",
    "\n",
    "    label_image = label_image.where(farm_mask, mapping[\"farm\"]).where(scrubland_mask, mapping[\"scrubland\"]).where(plantation_mask, mapping[\"plantation\"])\n",
    "    \n",
    "    # Classes to sample (exclude background = 0)\n",
    "    class_values = [(1, 150), (2, 150), (3, 150)]\n",
    "\n",
    "    # Create masks for all classes and combine them into a single mask\n",
    "    combined_mask = ee.Image(0).rename('class')\n",
    "    for class_val, points in class_values:\n",
    "        combined_mask = combined_mask.where(label_image.eq(class_val), class_val)\n",
    "\n",
    "    # Add the combined mask to the image\n",
    "    masked_ts = g_embs.addBands(combined_mask.rename('class'))\n",
    "\n",
    "    # Prepare class values and points for stratified sampling\n",
    "    class_band = 'class'\n",
    "    class_values_list = [class_val for class_val, _ in class_values]\n",
    "    class_points_list = [points for _, points in class_values]\n",
    "\n",
    "    # Sample uniformly from the masked image using a single call to stratifiedSample\n",
    "    all_samples = masked_ts.stratifiedSample(\n",
    "        numPoints=sum(class_points_list),  # Total number of points needed\n",
    "        classBand=class_band,\n",
    "        classValues=class_values_list,\n",
    "        classPoints=class_points_list,\n",
    "        scale=10,  # Adjust the scale as needed\n",
    "        region=tile.geometry(),\n",
    "        seed=42,\n",
    "        dropNulls=True,\n",
    "        geometries=False\n",
    "    )\n",
    "\n",
    "    # Filter samples to ensure each class has the correct number of points\n",
    "    def filter_samples(samples, class_val, points):\n",
    "        return samples.filter(ee.Filter.eq('class', class_val)).limit(points)\n",
    "\n",
    "    filtered_samples_list = [\n",
    "        filter_samples(all_samples, class_val, points)\n",
    "        for class_val, points in class_values\n",
    "    ]\n",
    "\n",
    "    # Merge all filtered samples into a single FeatureCollection\n",
    "    all_filtered_samples = ee.FeatureCollection(filtered_samples_list).flatten()\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=all_filtered_samples,\n",
    "        description=\"tile_\" + str(index),\n",
    "        fileFormat='CSV',\n",
    "        folder='Scrubland_Field_Delineation',\n",
    "        fileNamePrefix='tile_' + str(index),\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"tile_\" + str(index) + \" started\")\n",
    "    while True:\n",
    "        status = task.status()['state']\n",
    "        print(f\"Task tile_{index} status: {status}\")\n",
    "        if status in ['COMPLETED', 'FAILED', 'CANCELLED']:\n",
    "            break\n",
    "        time.sleep(30) \n",
    "    #all_filtered_samples_df = fc_to_df(all_filtered_samples)\n",
    "    #all_filtered_samples_df.to_csv('output_'+str(index)+'.csv', index=False)\n",
    "    #print(\"Done tile no \", index)\n",
    "    \n",
    "\n",
    "for i in range(2, len(tiles)):\n",
    "    process_tile(tiles[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to the following link in your browser:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=903213563690-dc8onmle8ebf0d8qj557hl6ot54snj8q.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n",
      "Downloading tile_105.csv\n",
      "Downloading tile_104.csv\n",
      "Downloading tile_103.csv\n",
      "Downloading tile_102.csv\n",
      "Downloading tile_101.csv\n",
      "Downloading tile_100.csv\n",
      "Downloading tile_99.csv\n",
      "Downloading tile_98.csv\n",
      "Downloading tile_97.csv\n",
      "Downloading tile_96.csv\n",
      "Downloading tile_95.csv\n",
      "Downloading tile_94.csv\n",
      "Downloading tile_93.csv\n",
      "Downloading tile_92.csv\n",
      "Downloading tile_91.csv\n",
      "Downloading tile_90.csv\n",
      "Downloading tile_89.csv\n",
      "Downloading tile_88.csv\n",
      "Downloading tile_87.csv\n",
      "Downloading tile_86.csv\n",
      "Downloading tile_85.csv\n",
      "Downloading tile_84.csv\n",
      "Downloading tile_83.csv\n",
      "Downloading tile_82.csv\n",
      "Downloading tile_81.csv\n",
      "Downloading tile_80.csv\n",
      "Downloading tile_79.csv\n",
      "Downloading tile_78.csv\n",
      "Downloading tile_77.csv\n",
      "Downloading tile_76.csv\n",
      "Downloading tile_75.csv\n",
      "Downloading tile_74.csv\n",
      "Downloading tile_73.csv\n",
      "Downloading tile_72.csv\n",
      "Downloading tile_71.csv\n",
      "Downloading tile_70.csv\n",
      "Downloading tile_69.csv\n",
      "Downloading tile_68.csv\n",
      "Downloading tile_67.csv\n",
      "Downloading tile_66.csv\n",
      "Downloading tile_65.csv\n",
      "Downloading tile_64.csv\n",
      "Downloading tile_63.csv\n",
      "Downloading tile_62.csv\n",
      "Downloading tile_61.csv\n",
      "Downloading tile_60.csv\n",
      "Downloading tile_59.csv\n",
      "Downloading tile_58.csv\n",
      "Downloading tile_57.csv\n",
      "Downloading tile_56.csv\n",
      "Downloading tile_55.csv\n",
      "Downloading tile_54.csv\n",
      "Downloading tile_53.csv\n",
      "Downloading tile_52.csv\n",
      "Downloading tile_51.csv\n",
      "Downloading tile_50.csv\n",
      "Downloading tile_49.csv\n",
      "Downloading tile_48.csv\n",
      "Downloading tile_47.csv\n",
      "Downloading tile_46.csv\n",
      "Downloading tile_45.csv\n",
      "Downloading tile_44.csv\n",
      "Downloading tile_43.csv\n",
      "Downloading tile_42.csv\n",
      "Downloading tile_41.csv\n",
      "Downloading tile_40.csv\n",
      "Downloading tile_39.csv\n",
      "Downloading tile_38.csv\n",
      "Downloading tile_37.csv\n",
      "Downloading tile_36.csv\n",
      "Downloading tile_35.csv\n",
      "Downloading tile_34.csv\n",
      "Downloading tile_33.csv\n",
      "Downloading tile_32.csv\n",
      "Downloading tile_31.csv\n",
      "Downloading tile_30.csv\n",
      "Downloading tile_29.csv\n",
      "Downloading tile_28.csv\n",
      "Downloading tile_27.csv\n",
      "Downloading tile_26.csv\n",
      "Downloading tile_25.csv\n",
      "Downloading tile_24.csv\n",
      "Downloading tile_23.csv\n",
      "Downloading tile_22.csv\n",
      "Downloading tile_21.csv\n",
      "Downloading tile_20.csv\n",
      "Downloading tile_19.csv\n",
      "Downloading tile_18.csv\n",
      "Downloading tile_17.csv\n",
      "Downloading tile_16.csv\n",
      "Downloading tile_15.csv\n",
      "Downloading tile_14.csv\n",
      "Downloading tile_13.csv\n",
      "Downloading tile_12.csv\n",
      "Downloading tile_11.csv\n",
      "Downloading tile_10.csv\n",
      "Downloading tile_9.csv\n",
      "Downloading tile_8.csv\n",
      "Downloading tile_7.csv\n",
      "Downloading tile_6.csv\n",
      "Downloading tile_5.csv\n",
      "Downloading tile_4.csv\n",
      "Downloading tile_3.csv\n",
      "Downloading tile_2.csv\n",
      "Downloading tile_1.csv\n",
      "Downloading tile_0.csv\n"
     ]
    }
   ],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "\n",
    "# Authenticate and create the PyDrive client\n",
    "gauth = GoogleAuth()\n",
    "gauth.CommandLineAuth()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Folder name in Google Drive\n",
    "folder_name = 'Scrubland_Field_Delineation'\n",
    "local_folder = 'Scrubland_Field_Delineation'\n",
    "os.makedirs(local_folder, exist_ok=True)\n",
    "\n",
    "# Get folder ID\n",
    "file_list = drive.ListFile({'q': \"mimeType='application/vnd.google-apps.folder' and trashed=false\"}).GetList()\n",
    "folder_id = None\n",
    "for file in file_list:\n",
    "    if file['title'] == folder_name:\n",
    "        folder_id = file['id']\n",
    "        break\n",
    "\n",
    "if folder_id is None:\n",
    "    print(\"Folder not found!\")\n",
    "else:\n",
    "    # List all CSV files in the folder\n",
    "    query = f\"'{folder_id}' in parents and trashed=false and mimeType='text/csv'\"\n",
    "    file_list = drive.ListFile({'q': query}).GetList()\n",
    "    for file in file_list:\n",
    "        print(f\"Downloading {file['title']}\")\n",
    "        file.GetContentFile(os.path.join(local_folder, file['title']))\n",
    "        \n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "csv_files = glob.glob('Scrubland_Field_Delineation/tile_*.csv')\n",
    "df_list = [pd.read_csv(f) for f in csv_files]\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "combined_df.to_csv('Scrubland_Field_Delineation/combined_samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system:index</th>\n",
       "      <th>A00</th>\n",
       "      <th>A01</th>\n",
       "      <th>A02</th>\n",
       "      <th>A03</th>\n",
       "      <th>A04</th>\n",
       "      <th>A05</th>\n",
       "      <th>A06</th>\n",
       "      <th>A07</th>\n",
       "      <th>A08</th>\n",
       "      <th>...</th>\n",
       "      <th>A56</th>\n",
       "      <th>A57</th>\n",
       "      <th>A58</th>\n",
       "      <th>A59</th>\n",
       "      <th>A60</th>\n",
       "      <th>A61</th>\n",
       "      <th>A62</th>\n",
       "      <th>A63</th>\n",
       "      <th>class</th>\n",
       "      <th>.geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_450</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>-0.044844</td>\n",
       "      <td>0.214133</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.029773</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.051734</td>\n",
       "      <td>-0.088827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079723</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>-0.172795</td>\n",
       "      <td>-0.051734</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.147697</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"type\":\"MultiPoint\",\"coordinates\":[]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_451</td>\n",
       "      <td>-0.001538</td>\n",
       "      <td>-0.075356</td>\n",
       "      <td>0.206936</td>\n",
       "      <td>-0.048228</td>\n",
       "      <td>-0.059116</td>\n",
       "      <td>0.066990</td>\n",
       "      <td>-0.066990</td>\n",
       "      <td>0.032541</td>\n",
       "      <td>-0.075356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035433</td>\n",
       "      <td>-0.066990</td>\n",
       "      <td>-0.153787</td>\n",
       "      <td>-0.079723</td>\n",
       "      <td>-0.044844</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.084214</td>\n",
       "      <td>0.119093</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"type\":\"MultiPoint\",\"coordinates\":[]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_452</td>\n",
       "      <td>0.019931</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>0.172795</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>-0.035433</td>\n",
       "      <td>0.098424</td>\n",
       "      <td>-0.044844</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>-0.079723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059116</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>-0.124567</td>\n",
       "      <td>-0.088827</td>\n",
       "      <td>-0.075356</td>\n",
       "      <td>-0.027128</td>\n",
       "      <td>0.141730</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"type\":\"MultiPoint\",\"coordinates\":[]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_453</td>\n",
       "      <td>-0.024606</td>\n",
       "      <td>-0.051734</td>\n",
       "      <td>0.192910</td>\n",
       "      <td>0.038447</td>\n",
       "      <td>-0.055363</td>\n",
       "      <td>0.051734</td>\n",
       "      <td>0.071111</td>\n",
       "      <td>0.032541</td>\n",
       "      <td>-0.071111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>-0.017778</td>\n",
       "      <td>-0.221453</td>\n",
       "      <td>-0.103406</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>-0.075356</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>0.093564</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"type\":\"MultiPoint\",\"coordinates\":[]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_454</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>-0.093564</td>\n",
       "      <td>0.172795</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>-0.035433</td>\n",
       "      <td>0.032541</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>0.038447</td>\n",
       "      <td>-0.108512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>-0.221453</td>\n",
       "      <td>-0.071111</td>\n",
       "      <td>0.038447</td>\n",
       "      <td>-0.048228</td>\n",
       "      <td>0.084214</td>\n",
       "      <td>0.108512</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"type\":\"MultiPoint\",\"coordinates\":[]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8902</th>\n",
       "      <td>2_895</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>-0.055363</td>\n",
       "      <td>0.147697</td>\n",
       "      <td>0.098424</td>\n",
       "      <td>-0.055363</td>\n",
       "      <td>-0.007443</td>\n",
       "      <td>-0.079723</td>\n",
       "      <td>0.153787</td>\n",
       "      <td>-0.147697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055363</td>\n",
       "      <td>-0.044844</td>\n",
       "      <td>-0.079723</td>\n",
       "      <td>-0.084214</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>-0.088827</td>\n",
       "      <td>0.084214</td>\n",
       "      <td>0.059116</td>\n",
       "      <td>3</td>\n",
       "      <td>{\"type\":\"MultiPoint\",\"coordinates\":[]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8903</th>\n",
       "      <td>2_896</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>-0.032541</td>\n",
       "      <td>0.153787</td>\n",
       "      <td>0.035433</td>\n",
       "      <td>-0.035433</td>\n",
       "      <td>-0.062991</td>\n",
       "      <td>-0.019931</td>\n",
       "      <td>0.166336</td>\n",
       "      <td>-0.084214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051734</td>\n",
       "      <td>-0.035433</td>\n",
       "      <td>-0.098424</td>\n",
       "      <td>-0.113741</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>-0.088827</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>0.108512</td>\n",
       "      <td>3</td>\n",
       "      <td>{\"type\":\"MultiPoint\",\"coordinates\":[]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>2_897</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>-0.071111</td>\n",
       "      <td>0.135886</td>\n",
       "      <td>0.108512</td>\n",
       "      <td>-0.027128</td>\n",
       "      <td>0.084214</td>\n",
       "      <td>-0.006151</td>\n",
       "      <td>0.079723</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088827</td>\n",
       "      <td>0.051734</td>\n",
       "      <td>-0.013841</td>\n",
       "      <td>-0.038447</td>\n",
       "      <td>-0.041584</td>\n",
       "      <td>-0.098424</td>\n",
       "      <td>0.119093</td>\n",
       "      <td>0.221453</td>\n",
       "      <td>3</td>\n",
       "      <td>{\"type\":\"MultiPoint\",\"coordinates\":[]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8905</th>\n",
       "      <td>2_898</td>\n",
       "      <td>-0.002215</td>\n",
       "      <td>-0.041584</td>\n",
       "      <td>0.124567</td>\n",
       "      <td>0.029773</td>\n",
       "      <td>-0.062991</td>\n",
       "      <td>-0.062991</td>\n",
       "      <td>-0.032541</td>\n",
       "      <td>0.147697</td>\n",
       "      <td>-0.108512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071111</td>\n",
       "      <td>-0.066990</td>\n",
       "      <td>-0.071111</td>\n",
       "      <td>-0.098424</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>-0.119093</td>\n",
       "      <td>0.079723</td>\n",
       "      <td>0.124567</td>\n",
       "      <td>3</td>\n",
       "      <td>{\"type\":\"MultiPoint\",\"coordinates\":[]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8906</th>\n",
       "      <td>2_899</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>-0.041584</td>\n",
       "      <td>0.124567</td>\n",
       "      <td>0.051734</td>\n",
       "      <td>-0.062991</td>\n",
       "      <td>-0.051734</td>\n",
       "      <td>-0.048228</td>\n",
       "      <td>0.186082</td>\n",
       "      <td>-0.079723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029773</td>\n",
       "      <td>-0.032541</td>\n",
       "      <td>-0.059116</td>\n",
       "      <td>-0.098424</td>\n",
       "      <td>0.048228</td>\n",
       "      <td>-0.093564</td>\n",
       "      <td>0.051734</td>\n",
       "      <td>0.108512</td>\n",
       "      <td>3</td>\n",
       "      <td>{\"type\":\"MultiPoint\",\"coordinates\":[]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8907 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     system:index       A00       A01       A02       A03       A04       A05  \\\n",
       "0           0_450  0.022207 -0.044844  0.214133  0.007443 -0.015748  0.029773   \n",
       "1           0_451 -0.001538 -0.075356  0.206936 -0.048228 -0.059116  0.066990   \n",
       "2           0_452  0.019931  0.007443  0.172795  0.044844 -0.035433  0.098424   \n",
       "3           0_453 -0.024606 -0.051734  0.192910  0.038447 -0.055363  0.051734   \n",
       "4           0_454  0.010396 -0.093564  0.172795  0.055363 -0.035433  0.032541   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "8902        2_895  0.015748 -0.055363  0.147697  0.098424 -0.055363 -0.007443   \n",
       "8903        2_896  0.055363 -0.032541  0.153787  0.035433 -0.035433 -0.062991   \n",
       "8904        2_897  0.015748 -0.071111  0.135886  0.108512 -0.027128  0.084214   \n",
       "8905        2_898 -0.002215 -0.041584  0.124567  0.029773 -0.062991 -0.062991   \n",
       "8906        2_899  0.012057 -0.041584  0.124567  0.051734 -0.062991 -0.051734   \n",
       "\n",
       "           A06       A07       A08  ...       A56       A57       A58  \\\n",
       "0     0.015748  0.051734 -0.088827  ... -0.079723  0.010396 -0.172795   \n",
       "1    -0.066990  0.032541 -0.075356  ... -0.035433 -0.066990 -0.153787   \n",
       "2    -0.044844  0.006151 -0.079723  ... -0.059116  0.022207 -0.124567   \n",
       "3     0.071111  0.032541 -0.071111  ...  0.017778 -0.017778 -0.221453   \n",
       "4     0.044844  0.038447 -0.108512  ...  0.010396  0.000984 -0.221453   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "8902 -0.079723  0.153787 -0.147697  ... -0.055363 -0.044844 -0.079723   \n",
       "8903 -0.019931  0.166336 -0.084214  ... -0.051734 -0.035433 -0.098424   \n",
       "8904 -0.006151  0.079723  0.006151  ... -0.088827  0.051734 -0.013841   \n",
       "8905 -0.032541  0.147697 -0.108512  ... -0.071111 -0.066990 -0.071111   \n",
       "8906 -0.048228  0.186082 -0.079723  ... -0.029773 -0.032541 -0.059116   \n",
       "\n",
       "           A59       A60       A61       A62       A63  class  \\\n",
       "0    -0.051734  0.007443 -0.015748  0.027128  0.147697      1   \n",
       "1    -0.079723 -0.044844 -0.015748  0.084214  0.119093      1   \n",
       "2    -0.088827 -0.075356 -0.027128  0.141730  0.093564      1   \n",
       "3    -0.103406  0.013841 -0.075356  0.093564  0.093564      1   \n",
       "4    -0.071111  0.038447 -0.048228  0.084214  0.108512      1   \n",
       "...        ...       ...       ...       ...       ...    ...   \n",
       "8902 -0.084214  0.010396 -0.088827  0.084214  0.059116      3   \n",
       "8903 -0.113741  0.027128 -0.088827  0.055363  0.108512      3   \n",
       "8904 -0.038447 -0.041584 -0.098424  0.119093  0.221453      3   \n",
       "8905 -0.098424 -0.004983 -0.119093  0.079723  0.124567      3   \n",
       "8906 -0.098424  0.048228 -0.093564  0.051734  0.108512      3   \n",
       "\n",
       "                                        .geo  \n",
       "0     {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n",
       "1     {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n",
       "2     {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n",
       "3     {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n",
       "4     {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n",
       "...                                      ...  \n",
       "8902  {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n",
       "8903  {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n",
       "8904  {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n",
       "8905  {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n",
       "8906  {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n",
       "\n",
       "[8907 rows x 67 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aez = ee.FeatureCollection(\"projects/raman-461708/assets/AEZ_7_boundaries_0\")\n",
    "all_samples = ee.FeatureCollection('projects/raman-461708/assets/combined_samples')\n",
    "classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "    features=all_samples,\n",
    "    classProperty='class',\n",
    "    inputProperties=ts_data.bandNames()\n",
    ")\n",
    "classified = ts_data.classify(classifier)\n",
    "\n",
    "classifier_dynamic = ee.Classifier.smileRandomForest(50).train(\n",
    "    features=samples_without_plantaiton,\n",
    "    classProperty='class',\n",
    "    inputProperties=ts_data.bandNames()\n",
    ")\n",
    "\n",
    "task = ee.batch.Export.classifier.toAsset(classifier_dynamic, \"Saving dynamic classifier for \" + directory, \"projects/ee-raman/assets/\" + directory + \"_classifier\")\n",
    "task.start()\n",
    "classified_ = ts_data.classify(classifier_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3624753053.py, line 137)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 137\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmasked_ts.\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tile = ee.FeatureCollection(ee.Geometry.Polygon(tiles[2]))\n",
    "index = 2\n",
    "\n",
    "#aez_region = ee.FeatureCollection(\"users/mtpictd/agro_eco_regions\").filter(ee.Filter.eq(\"ae_regcode\", 7)).filter(tile)\n",
    "g_embs = ee.ImageCollection(\"GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL\").filterDate('2024-01-01', '2025-01-01').filterBounds(tile).mosaic()\n",
    "\n",
    "mapping = {\n",
    "    \"farm\": 1,\n",
    "    \"plantation\": 2,\n",
    "    \"scrubland\": 3,\n",
    "    \"rest\": 0\n",
    "}\n",
    "reversed_mapping = {v: k for k, v in mapping.items()}\n",
    "reversed_ee_mapping = ee.Dictionary(reversed_mapping)\n",
    "\n",
    "easy_farm = [\n",
    "    ee.Filter.gte(\"rect\", 0.67),\n",
    "    ee.Filter.gt(\"size\", 500),\n",
    "    ee.Filter.lt(\"size\", 2000),\n",
    "    ee.Filter.lt(\"ent\", 1)\n",
    "    ]\n",
    "easy_scrubland = [\n",
    "    ee.Filter.gte(\"size\", 60000)\n",
    "    ]\n",
    "easy_plantation = [\n",
    "    ee.Filter.lt(\"area\", 20000),\n",
    "    ee.Filter.gt(\"area\", 1000)\n",
    "]\n",
    "\n",
    "all = merged_aez_boundaries.filterBounds(tile)\n",
    "farm = all.filter(ee.Filter.And(*easy_farm))\n",
    "scrubland = all.filter(ee.Filter.And(easy_scrubland))\n",
    "plantation = all.filter(ee.Filter.eq(\"class\", \"plantation\")).map(lambda x: x.set(\"area\", x.geometry().area())).filter(ee.Filter.And(easy_plantation))\n",
    "\n",
    "mapping = {\n",
    "    \"farm\": 1,\n",
    "    \"plantation\": 2,\n",
    "    \"scrubland\": 3,\n",
    "    \"rest\": 0\n",
    "}\n",
    "reversed_mapping = {v: k for k, v in mapping.items()}\n",
    "reversed_ee_mapping = ee.Dictionary(reversed_mapping)\n",
    "\n",
    "easy_farm = [\n",
    "    ee.Filter.gte(\"rect\", 0.67),\n",
    "    ee.Filter.gt(\"size\", 500),\n",
    "    ee.Filter.lt(\"size\", 2000),\n",
    "    ee.Filter.lt(\"ent\", 1)\n",
    "    ]\n",
    "\n",
    "easy_scrubland = [\n",
    "    ee.Filter.gte(\"size\", 60000)\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "#Filter out farms which doesnot have 3 nearby farms (Removing solo farms inside scrublands)\n",
    "farm_buffer = farm.map(lambda x: x.buffer(10))\n",
    "farm_image = ee.Image(0)\n",
    "farm_mask = farm_image.clip(farm_buffer).mask()\n",
    "farm_vectors = farm_mask.toInt().reduceToVectors(\n",
    "    geometry=farm.geometry(),\n",
    "    scale=10,  # Change based on your resolution\n",
    "    geometryType='polygon',\n",
    "    labelProperty='zone',\n",
    "    reducer=ee.Reducer.countEvery(),\n",
    "    maxPixels=1e8\n",
    ") \n",
    "farm_vectors = farm_vectors.filter(ee.Filter.eq('zone', 1)).map(lambda x: x.set(\"count\", farm.filterBounds(x.geometry()).size())).filter(ee.Filter.gt('count', 3))\n",
    "\n",
    "#farm_vectors = get_feature_collection(\"projects/ee-raman/assets/\" + block + \"_farm_clusters\")\n",
    "farm = farm.filterBounds(farm_vectors)\n",
    "lulc_v3 = ee.Image(\"projects/corestack-datasets/assets/datasets/LULC_v3_river_basin/pan_india_lulc_v3_2023_2024\").clip(tile.geometry())\n",
    "classes_of_interest = [8, 9, 10, 11]\n",
    "masked_lulc = lulc_v3.remap(classes_of_interest, [1]*len(classes_of_interest))  # 1 where class is of interest, 0 elsewhere\n",
    "\n",
    "# Step 2: Function to compute % area of interest inside each feature\n",
    "def filter_by_lulc(feature):\n",
    "    geom = feature.geometry()\n",
    "    scale = 30  # Set resolution appropriate to your LULC data\n",
    "\n",
    "    # Area of interest within polygon (masked_lulc == 1)\n",
    "    interest_area_img = ee.Image.pixelArea().updateMask(masked_lulc)\n",
    "    interest_area = interest_area_img.reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=geom,\n",
    "        scale=scale,\n",
    "        maxPixels=1e8\n",
    "    ).get('area')\n",
    "\n",
    "    # Total area of the polygon\n",
    "    total_area = ee.Image.pixelArea().reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=geom,\n",
    "        scale=scale,\n",
    "        maxPixels=1e8\n",
    "    ).get('area')\n",
    "\n",
    "    # Compute % and add it as a property\n",
    "    percent_interest = ee.Number(interest_area).divide(ee.Number(total_area)).multiply(100)\n",
    "    return feature.set('percent_interest', percent_interest)\n",
    "\n",
    "# Step 3: Apply to FeatureCollection\n",
    "scrubland = scrubland.map(filter_by_lulc)\n",
    "\n",
    "# Step 4: Filter features with > 50% area of interest\n",
    "def strictly_inside_roi(feature):\n",
    "    return feature.set('inside', all.union().geometry().contains(feature.geometry()))\n",
    "\n",
    "scrubland = scrubland.filter(ee.Filter.lt('percent_interest', 50)).map(strictly_inside_roi)\n",
    "scrubland = scrubland.filter(ee.Filter.eq('inside', True))\n",
    "\n",
    "label_image = ee.Image(0).rename(\"label\")\n",
    "farm_mask = label_image.clip(farm).mask()\n",
    "scrubland_mask = label_image.clip(scrubland).mask()\n",
    "plantation_mask = label_image.clip(plantation).mask()\n",
    "\n",
    "label_image = label_image.where(farm_mask, mapping[\"farm\"]).where(scrubland_mask, mapping[\"scrubland\"]).where(plantation_mask, mapping[\"plantation\"])\n",
    "\n",
    "# Classes to sample (exclude background = 0)\n",
    "class_values = [(1, 150), (2, 150), (3, 150)]\n",
    "\n",
    "# Create masks for all classes and combine them into a single mask\n",
    "combined_mask = ee.Image(0).rename('class')\n",
    "for class_val, points in class_values:\n",
    "    combined_mask = combined_mask.where(label_image.eq(class_val), class_val)\n",
    "\n",
    "# Add the combined mask to the image\n",
    "masked_ts = g_embs.addBands(combined_mask.rename('class'))\n",
    "\n",
    "# Prepare class values and points for stratified sampling\n",
    "class_band = 'class'\n",
    "class_values_list = [class_val for class_val, _ in class_values]\n",
    "class_points_list = [points for _, points in class_values]\n",
    "\n",
    "\n",
    "masked_ts.\n",
    "# Merge all filtered samples into a single FeatureCollection\n",
    "#all_filtered_samples = ee.FeatureCollection(filtered_samples_list).flatten()\n",
    "#all_filtered_samples_df = fc_to_df(all_filtered_samples)\n",
    "#all_filtered_samples_df.to_csv('output_'+str(index)+'.csv', index=False)\n",
    "#print(\"Done tile no \", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples collected: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Classes to sample (exclude background = 0)\n",
    "class_values = [(1,1), (2,1), (3,1)]\n",
    "\n",
    "# Empty list to store samples\n",
    "samples_list = []\n",
    "\n",
    "for class_val, points in class_values:\n",
    "    # Create a mask for the class\n",
    "    class_mask = label_image.eq(class_val)\n",
    "    \n",
    "    # Mask the ts_image to only include pixels of this class\n",
    "    masked_ts = g_embs.updateMask(class_mask)\n",
    "    \n",
    "    # Sample uniformly from the masked image\n",
    "    class_samples = masked_ts.addBands(label_image.rename('class')) \\\n",
    "        .stratifiedSample(\n",
    "            numPoints=points,  # adjust as needed\n",
    "            classBand='class',\n",
    "            classValues=[class_val],\n",
    "            classPoints=[points],  # adjust per class\n",
    "            scale=10,\n",
    "            region=tile.geometry(),\n",
    "            seed=42,\n",
    "            geometries=True\n",
    "        )\n",
    "    \n",
    "    samples_list.append(class_samples)\n",
    "\n",
    "all_samples = samples_list[0].merge(samples_list[1]).merge(samples_list[2])\n",
    "print(f\"Total samples collected: {all_samples.size().getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes to sample (exclude background = 0)\n",
    "class_values = [(1, 2000), (2, 2000), (3, 2000)]\n",
    "\n",
    "# Empty list to store samples\n",
    "samples_list = []\n",
    "\n",
    "# Create masks for all classes at once\n",
    "class_masks = {class_val: label_image.eq(class_val) for class_val, _ in class_values}\n",
    "\n",
    "# Process each class in parallel\n",
    "import concurrent.futures\n",
    "\n",
    "def sample_class(class_val, points):\n",
    "    # Mask the ts_image to only include pixels of this class\n",
    "    masked_ts = g_embs.updateMask(class_masks[class_val])\n",
    "    \n",
    "    # Sample uniformly from the masked image\n",
    "    class_samples = masked_ts.addBands(label_image.rename('class')) \\\n",
    "        .stratifiedSample(\n",
    "            numPoints=points,  # adjust as needed\n",
    "            classBand='class',\n",
    "            classValues=[class_val],\n",
    "            classPoints=[points],  # adjust per class\n",
    "            scale=10,\n",
    "            region=tile.geometry(),\n",
    "            seed=42,\n",
    "            geometries=True\n",
    "        )\n",
    "    return class_samples\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    samples_list = list(executor.map(lambda cv: sample_class(cv[0], cv[1]), class_values))\n",
    "\n",
    "# Merge all samples into a single FeatureCollection\n",
    "all_samples = ee.FeatureCollection(samples_list).flatten()\n",
    "\n",
    "#print(f\"Total samples collected: {all_samples.size().getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes to sample (exclude background = 0)\n",
    "class_values = [(1, 2000), (2, 2000), (3, 2000)]\n",
    "\n",
    "# Create masks for all classes and combine them into a single mask\n",
    "combined_mask = ee.Image(0).rename('class')\n",
    "for class_val, points in class_values:\n",
    "    combined_mask = combined_mask.where(label_image.eq(class_val), class_val)\n",
    "\n",
    "# Add the combined mask to the image\n",
    "masked_ts = g_embs.addBands(combined_mask.rename('class'))\n",
    "\n",
    "# Prepare class values and points for stratified sampling\n",
    "class_band = 'class'\n",
    "class_values_list = [class_val for class_val, _ in class_values]\n",
    "class_points_list = [points for _, points in class_values]\n",
    "\n",
    "# Sample uniformly from the masked image using a single call to stratifiedSample\n",
    "all_samples = masked_ts.stratifiedSample(\n",
    "    numPoints=sum(class_points_list),  # Total number of points needed\n",
    "    classBand=class_band,\n",
    "    classValues=class_values_list,\n",
    "    classPoints=class_points_list,\n",
    "    scale=10,  # Adjust the scale as needed\n",
    "    region=tile.geometry(),\n",
    "    seed=42,\n",
    "    geometries=True\n",
    ")\n",
    "\n",
    "# Filter samples to ensure each class has the correct number of points\n",
    "def filter_samples(samples, class_val, points):\n",
    "    return samples.filter(ee.Filter.eq('class', class_val)).limit(points)\n",
    "\n",
    "filtered_samples_list = [\n",
    "    filter_samples(all_samples, class_val, points)\n",
    "    for class_val, points in class_values\n",
    "]\n",
    "\n",
    "# Merge all filtered samples into a single FeatureCollection\n",
    "all_filtered_samples = ee.FeatureCollection(filtered_samples_list).flatten()\n",
    "\n",
    "#print(f\"Total samples collected: {all_filtered_samples.size().getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'FeatureCollection',\n",
       " 'columns': {'A00': 'Float',\n",
       "  'A01': 'Float',\n",
       "  'A02': 'Float',\n",
       "  'A03': 'Float',\n",
       "  'A04': 'Float',\n",
       "  'A05': 'Float',\n",
       "  'A06': 'Float',\n",
       "  'A07': 'Float',\n",
       "  'A08': 'Float',\n",
       "  'A09': 'Float',\n",
       "  'A10': 'Float',\n",
       "  'A11': 'Float',\n",
       "  'A12': 'Float',\n",
       "  'A13': 'Float',\n",
       "  'A14': 'Float',\n",
       "  'A15': 'Float',\n",
       "  'A16': 'Float',\n",
       "  'A17': 'Float',\n",
       "  'A18': 'Float',\n",
       "  'A19': 'Float',\n",
       "  'A20': 'Float',\n",
       "  'A21': 'Float',\n",
       "  'A22': 'Float',\n",
       "  'A23': 'Float',\n",
       "  'A24': 'Float',\n",
       "  'A25': 'Float',\n",
       "  'A26': 'Float',\n",
       "  'A27': 'Float',\n",
       "  'A28': 'Float',\n",
       "  'A29': 'Float',\n",
       "  'A30': 'Float',\n",
       "  'A31': 'Float',\n",
       "  'A32': 'Float',\n",
       "  'A33': 'Float',\n",
       "  'A34': 'Float',\n",
       "  'A35': 'Float',\n",
       "  'A36': 'Float',\n",
       "  'A37': 'Float',\n",
       "  'A38': 'Float',\n",
       "  'A39': 'Float',\n",
       "  'A40': 'Float',\n",
       "  'A41': 'Float',\n",
       "  'A42': 'Float',\n",
       "  'A43': 'Float',\n",
       "  'A44': 'Float',\n",
       "  'A45': 'Float',\n",
       "  'A46': 'Float',\n",
       "  'A47': 'Float',\n",
       "  'A48': 'Float',\n",
       "  'A49': 'Float',\n",
       "  'A50': 'Float',\n",
       "  'A51': 'Float',\n",
       "  'A52': 'Float',\n",
       "  'A53': 'Float',\n",
       "  'A54': 'Float',\n",
       "  'A55': 'Float',\n",
       "  'A56': 'Float',\n",
       "  'A57': 'Float',\n",
       "  'A58': 'Float',\n",
       "  'A59': 'Float',\n",
       "  'A60': 'Float',\n",
       "  'A61': 'Float',\n",
       "  'A62': 'Float',\n",
       "  'A63': 'Float',\n",
       "  'class': 'Byte<0, 3>'},\n",
       " 'features': [{'type': 'Feature',\n",
       "   'geometry': {'geodesic': False,\n",
       "    'type': 'Point',\n",
       "    'coordinates': [78.83637391315024, 18.97057725427185]},\n",
       "   'id': '0_6000',\n",
       "   'properties': {'A00': -0.017777777777777778,\n",
       "    'A01': -0.0271280276816609,\n",
       "    'A02': 0.21413302575932336,\n",
       "    'A03': 0.024605920799692427,\n",
       "    'A04': -0.01574778931180315,\n",
       "    'A05': 0.03844675124951941,\n",
       "    'A06': -0.06698961937716265,\n",
       "    'A07': 0.05173394848135333,\n",
       "    'A08': -0.10340638216070744,\n",
       "    'A09': 0.03254133025759323,\n",
       "    'A10': 0.1085121107266436,\n",
       "    'A11': 0.08882737408688965,\n",
       "    'A12': -0.39369473279507883,\n",
       "    'A13': 0.19986159169550174,\n",
       "    'A14': -0.019930795847750864,\n",
       "    'A15': 0.2069357939254133,\n",
       "    'A16': -0.05173394848135333,\n",
       "    'A17': -0.06698961937716265,\n",
       "    'A18': -0.16633602460592078,\n",
       "    'A19': -0.1929104190695886,\n",
       "    'A20': -0.2069357939254133,\n",
       "    'A21': 0.22145328719723184,\n",
       "    'A22': 0.08882737408688965,\n",
       "    'A23': 0.16633602460592078,\n",
       "    'A24': -0.007443291041906958,\n",
       "    'A25': 0.11374086889657825,\n",
       "    'A26': 0.05536332179930796,\n",
       "    'A27': 0.041584006151480196,\n",
       "    'A28': -0.03844675124951941,\n",
       "    'A29': 0.09842368319876971,\n",
       "    'A30': 0.03543252595155709,\n",
       "    'A31': 0.04822760476739715,\n",
       "    'A32': -0.09356401384083046,\n",
       "    'A33': 0.05173394848135333,\n",
       "    'A34': 0.186082276047674,\n",
       "    'A35': -0.004982698961937716,\n",
       "    'A36': -0.16633602460592078,\n",
       "    'A37': 0.14769703960015382,\n",
       "    'A38': 0.17279507881584008,\n",
       "    'A39': -0.007443291041906958,\n",
       "    'A40': 0.0005536332179930795,\n",
       "    'A41': -0.010396001537870049,\n",
       "    'A42': -0.17937716262975778,\n",
       "    'A43': 0.17937716262975778,\n",
       "    'A44': -0.029773164167627833,\n",
       "    'A45': -0.012056901191849288,\n",
       "    'A46': 0.04822760476739715,\n",
       "    'A47': -0.007443291041906958,\n",
       "    'A48': -0.2761399461745483,\n",
       "    'A49': 0.09356401384083046,\n",
       "    'A50': -0.0271280276816609,\n",
       "    'A51': 0.11909265667051133,\n",
       "    'A52': -0.09356401384083046,\n",
       "    'A53': -0.14769703960015382,\n",
       "    'A54': 0.2288965782391388,\n",
       "    'A55': 0.008858131487889272,\n",
       "    'A56': -0.07111111111111111,\n",
       "    'A57': -0.0271280276816609,\n",
       "    'A58': -0.15378700499807765,\n",
       "    'A59': -0.08421376393694734,\n",
       "    'A60': -0.06698961937716265,\n",
       "    'A61': -0.041584006151480196,\n",
       "    'A62': 0.08421376393694734,\n",
       "    'A63': 0.13588619761630144,\n",
       "    'class': 1}}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_filtered_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "    features=all_samples,\n",
    "    classProperty='class',\n",
    "    inputProperties=g_embs.bandNames()\n",
    ")\n",
    "classified = g_embs.classify(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ee.batch.Export.classifier.toAsset(classifier, \"Saving dynamic classifier\", \"projects/raman-461708/assets/aez_7_classifier\")\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m all_samples.limit(\u001b[32m1\u001b[39m).getInfo()\n",
      "\u001b[31mNameError\u001b[39m: name 'all_samples' is not defined"
     ]
    }
   ],
   "source": [
    "all_samples.limit(1).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "raman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
