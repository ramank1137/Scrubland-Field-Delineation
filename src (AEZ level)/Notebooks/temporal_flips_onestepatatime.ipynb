{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40bfef37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e1c687b0fc4a87b9f40fd650963182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[0, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], position='topright', transp…"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ee\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='raman-461708')\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 1. LOADING\n",
    "# -------------------------------\n",
    "\n",
    "def load_aez_temporal_images(aez, start_year, num_years,roi_boundary, project='raman-461708'):\n",
    "    base = f\"projects/{project}/assets/LULC_v4_PanIndia_\"\n",
    "    images = []\n",
    "    for i in range(num_years):\n",
    "        y1 = start_year + i\n",
    "        y2 = y1 + 1\n",
    "        asset = f\"{base}{y1}-07-01_{y2}-06-30\"\n",
    "        img = ee.Image(asset)\n",
    "        images.append(img.clip(roi_boundary))\n",
    "    return images\n",
    "\n",
    "aez = 19\n",
    "start_year = 2017\n",
    "num_years = 6\n",
    "project = 'raman-461708'\n",
    "\n",
    "roi_boundary = ee.FeatureCollection(\"users/mtpictd/agro_eco_regions\") \\\n",
    "    .filter(ee.Filter.eq(\"ae_regcode\", aez)).geometry()\n",
    "#roi = ee.FeatureCollection(\"users/mtpictd/agro_eco_regions\")\n",
    "\n",
    "# 1. Load\n",
    "images = load_aez_temporal_images(aez, start_year, num_years, roi_boundary, project)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Grouping (as you requested)\n",
    "# -----------------------------\n",
    "ORIG =  [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "GROUP = [0, 1, 2, 2, 2, 6, 7, 8, 8,  8,  8,  12, 13]\n",
    "\n",
    "BAND = 'predicted_label'\n",
    "\n",
    "def group_classes(img, band=BAND):\n",
    "    g = img.select([band]).remap(ORIG, GROUP).rename('predicted_label')\n",
    "    return g\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0.5) ADMISSIBILITY MATRIX (apply to detection)\n",
    "# ============================================================\n",
    "# grouped classes used in the matrix (exclude background 0)\n",
    "# Order: [Built-up, Water, Tree, Barren, Crop, Scrub, Plantation]\n",
    "MAT_CLASSES = [1, 2, 6, 7, 8, 12, 13]\n",
    "\n",
    "# A \\ B (rows = target A, cols = current B): 1=allowed, 0=not allowed\n",
    "#            Bu Wa Tr Ba Cr Sc Pl\n",
    "ALLOW_TABLE = [\n",
    "    # A=Built-up\n",
    "               0, 0, 0, 1, 1, 1, 1,\n",
    "    # A=Water\n",
    "               0, 0, 1, 0, 0, 0, 0,\n",
    "    # A=Tree/Forest\n",
    "               1, 1, 0, 1, 1, 1, 1,\n",
    "    # A=Barren\n",
    "               1, 0, 1, 0, 1, 1, 1,\n",
    "    # A=Crop\n",
    "               0, 0, 1, 1, 0, 1, 0,\n",
    "    # A=Scrub\n",
    "               0, 0, 1, 1, 1, 0, 1,\n",
    "    # A=Plantation\n",
    "               1, 0, 1, 1, 0, 1, 0\n",
    "]\n",
    "\n",
    "# Make a 7x7 ee.Array first, then a constant image from it\n",
    "ALLOW_TABLE_ARR = ee.Array(ALLOW_TABLE).reshape([7, 7])\n",
    "ALLOW_TABLE_IMG = ee.Image.constant(ALLOW_TABLE_ARR)\n",
    "\n",
    "\n",
    "def _class_to_index(x):\n",
    "    # map grouped class -> 0..6 index, else -1\n",
    "    return ee.Image(x).remap(MAT_CLASSES, list(range(7)), -1).toInt()\n",
    "\n",
    "def allow_flip(A, B):\n",
    "    \"\"\"\n",
    "    Returns 1 where flipping B -> A is allowed by matrix, else 0.\n",
    "    A and B are grouped class images.\n",
    "    \"\"\"\n",
    "    a = _class_to_index(A)\n",
    "    b = _class_to_index(B)\n",
    "    valid = a.gte(0).And(b.gte(0))\n",
    "    val = ALLOW_TABLE_IMG.arrayGet([a, b]).toInt()\n",
    "    return val.updateMask(valid).unmask(0).rename('allowFlip')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1) Stack 6 yearly layers into one 6-band image: y1..y6\n",
    "# ----------------------------------------------------------\n",
    "def stack_6_years(year_imgs):\n",
    "    if len(year_imgs) != 6:\n",
    "        raise ValueError(\"Provide exactly 6 yearly images.\")\n",
    "\n",
    "    bands = []\n",
    "    for i, im in enumerate(year_imgs, start=1):\n",
    "        bands.append(im.select(['predicted_label']).rename(f'y{i}'))\n",
    "    return ee.Image.cat(bands)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2) Helpers\n",
    "# ----------------------------------------------------------\n",
    "def _count_ones_nbit(mask, nbits):\n",
    "    bits = [mask.rightShift(k).bitwiseAnd(1) for k in range(nbits)]\n",
    "    return ee.Image.cat(bits).reduce(ee.Reducer.sum()).rename('singletCount').toInt()\n",
    "\n",
    "def _has_adjacent_ones(mask):\n",
    "    return mask.bitwiseAnd(mask.leftShift(1)).neq(0).rename('hasAdj11')\n",
    "\n",
    "def _has_run_k(mask, nbits, k):\n",
    "    base = (1 << k) - 1\n",
    "    cond = ee.Image(0)\n",
    "    for start in range(0, nbits - k + 1):\n",
    "        pat = ee.Image(base << start).toInt()\n",
    "        cond = cond.Or(mask.bitwiseAnd(pat).eq(pat))\n",
    "    return cond\n",
    "\n",
    "def _max_run_length(mask, nbits):\n",
    "    any1 = mask.neq(0)\n",
    "    maxRun = ee.Image(0).where(any1, 1)\n",
    "    for k in range(2, nbits + 1):\n",
    "        maxRun = maxRun.where(_has_run_k(mask, nbits, k), k)\n",
    "    return maxRun.rename('singletMaxRun').toInt()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3) Singlet categories WITH MATRIX constraint\n",
    "#    Only count an ABA center if flipping mid->left is allowed.\n",
    "# ----------------------------------------------------------\n",
    "def singlet_category_6yr(seq6):\n",
    "    y = [seq6.select(f'y{i}') for i in range(1, 7)]  # y1..y6\n",
    "\n",
    "    centers = []\n",
    "    for idx in range(1, 5):  # centers y2..y5\n",
    "        left  = y[idx - 1]\n",
    "        mid   = y[idx]\n",
    "        right = y[idx + 1]\n",
    "\n",
    "        raw = left.eq(right).And(mid.neq(left))  # ABA local condition\n",
    "\n",
    "        # matrix constraint: only keep this center if flip mid -> left is allowed\n",
    "        adm = allow_flip(left, mid).eq(1)\n",
    "\n",
    "        s = raw.And(adm).rename(f's{idx+1}').toUint8()  # s2..s5 (admissible)\n",
    "        centers.append(s)\n",
    "\n",
    "    # Pack s2..s5 into 4-bit mask (s2 MSB bit3, s5 LSB bit0)\n",
    "    mask = ee.Image(0).toInt()\n",
    "    for j, s in enumerate(centers):  # j=0..3 => s2..s5\n",
    "        mask = mask.bitwiseOr(s.toInt().leftShift(3 - j))\n",
    "    singletSeqMask = mask.rename('singletSeqMask')\n",
    "\n",
    "    singletCount = _count_ones_nbit(singletSeqMask, 4).rename('singletCount')\n",
    "    anySinglet = singletSeqMask.neq(0)\n",
    "\n",
    "    adj11 = _has_adjacent_ones(singletSeqMask)\n",
    "    maxRun = _max_run_length(singletSeqMask, 4).rename('singletMaxRun')\n",
    "\n",
    "    bits_in_adj = singletSeqMask.bitwiseAnd(singletSeqMask.leftShift(1))\n",
    "    bits_in_adj_covered = bits_in_adj.bitwiseOr(bits_in_adj.rightShift(1))\n",
    "    isolatedMask = singletSeqMask.bitwiseAnd(bits_in_adj_covered.bitwiseNot()).rename('isolatedSingletMask')\n",
    "\n",
    "    hasIsolated = isolatedMask.neq(0)\n",
    "    isMax2 = maxRun.eq(2)\n",
    "\n",
    "    composite = anySinglet.And(isMax2).And(adj11).And(hasIsolated)\n",
    "    disjointSingles = anySinglet.And(adj11.Not())\n",
    "\n",
    "    cat = ee.Image(0).toInt() \\\n",
    "        .where(disjointSingles, 1) \\\n",
    "        .where(isMax2.And(disjointSingles.Not()).And(composite.Not()), 2) \\\n",
    "        .where(maxRun.eq(3), 3) \\\n",
    "        .where(maxRun.eq(4), 4) \\\n",
    "        .where(composite, 6) \\\n",
    "        .where(anySinglet.Not(), 0) \\\n",
    "        .rename('singletCategory')\n",
    "\n",
    "    return ee.Image.cat([\n",
    "        cat,\n",
    "        singletSeqMask,\n",
    "        singletCount,\n",
    "        adj11,\n",
    "        maxRun,\n",
    "        isolatedMask.toInt(),\n",
    "        ee.Image.cat(centers)  # s2..s5 (admissible)\n",
    "    ])\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4) Doublet patterns WITH MATRIX constraint\n",
    "#    Keep doublet only if BOTH X->A and Y->A are allowed.\n",
    "# ----------------------------------------------------------\n",
    "def detect_doublet_6yr(seq6):\n",
    "    y1 = seq6.select('y1')\n",
    "    y2 = seq6.select('y2')\n",
    "    y3 = seq6.select('y3')\n",
    "    y4 = seq6.select('y4')\n",
    "    y5 = seq6.select('y5')\n",
    "    y6 = seq6.select('y6')\n",
    "\n",
    "    def xy_constraints(A, X, Y):\n",
    "        return X.neq(Y).And(X.neq(A)).And(Y.neq(A))\n",
    "\n",
    "    # (1) A X Y A A *\n",
    "    A = y1\n",
    "    X = y2\n",
    "    Y = y3\n",
    "    p1_raw = y4.eq(A).And(y5.eq(A)).And(xy_constraints(A, X, Y))\n",
    "    p1 = p1_raw.And(allow_flip(A, X).eq(1)).And(allow_flip(A, Y).eq(1))\n",
    "\n",
    "    # (2) A A X Y A A\n",
    "    A = y1\n",
    "    X = y3\n",
    "    Y = y4\n",
    "    p2_raw = y2.eq(A).And(y5.eq(A)).And(y6.eq(A)).And(xy_constraints(A, X, Y))\n",
    "    p2 = p2_raw.And(allow_flip(A, X).eq(1)).And(allow_flip(A, Y).eq(1))\n",
    "\n",
    "    # (3) * A A X Y A\n",
    "    A = y2\n",
    "    X = y4\n",
    "    Y = y5\n",
    "    p3_raw = y3.eq(A).And(y6.eq(A)).And(xy_constraints(A, X, Y))\n",
    "    p3 = p3_raw.And(allow_flip(A, X).eq(1)).And(allow_flip(A, Y).eq(1))\n",
    "\n",
    "    pat = ee.Image(0).toInt() \\\n",
    "        .where(p1, 1) \\\n",
    "        .where(p2, 2) \\\n",
    "        .where(p3, 3) \\\n",
    "        .rename('doubletPattern')\n",
    "\n",
    "    anyDoublet = p1.Or(p2).Or(p3).rename('hasDoublet')\n",
    "    return pat.addBands(anyDoublet)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5) Main wrapper\n",
    "# ----------------------------------------------------------\n",
    "def classify_temporal_flip_categories_6yr(year_imgs, roi):\n",
    "    grouped = [group_classes(im, band=BAND) for im in year_imgs]\n",
    "    seq6 = stack_6_years(grouped)\n",
    "\n",
    "    roi_mask = ee.Image.constant(1).clip(roi).selfMask()\n",
    "\n",
    "    sing = singlet_category_6yr(seq6).updateMask(roi_mask)\n",
    "    dbl  = detect_doublet_6yr(seq6).updateMask(roi_mask)\n",
    "\n",
    "    return seq6.addBands(sing).addBands(dbl)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Visualization\n",
    "# -----------------------------\n",
    "singlet_vis = {\n",
    "    'min': 0,\n",
    "    'max': 6,\n",
    "    'palette': [\n",
    "        '000000',  # 0 - No flips\n",
    "        '2ecc71',  # 1 - Disjoint singles\n",
    "        'f1c40f',  # 2 - Run=2\n",
    "        'e67e22',  # 3 - Run=3\n",
    "        'e74c3c',  # 4 - Run=4\n",
    "        '8e44ad',  # 5 - Run=5 (won't happen in 6yr)\n",
    "        '34495e'   # 6 - Composite\n",
    "    ]\n",
    "}\n",
    "\n",
    "doublet_vis_6yr = {\n",
    "    'min': 0,\n",
    "    'max': 3,\n",
    "    'palette': [\n",
    "        '000000',  # 0 none\n",
    "        '00bcd4',  # 1 pattern: A X Y A A *\n",
    "        'ff9800',  # 2 pattern: A A X Y A A\n",
    "        'e91e63'   # 3 pattern: * A A X Y A\n",
    "    ]\n",
    "}\n",
    "\n",
    "pallete_lulc = [\n",
    "  '000000','ff0000','74ccf4','1ca3ec','0f5e9c',\n",
    "  'f1c232','38761d','A9A9A9','BAD93E','f59d22',\n",
    "  'FF9371','b3561d','a9a9a9','84994F'\n",
    "]\n",
    "\n",
    "vis_params_lulc = {'min': 0, 'max': 13, 'palette': pallete_lulc}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Run\n",
    "# -----------------------------\n",
    "out = classify_temporal_flip_categories_6yr(images, roi_boundary)\n",
    "\n",
    "import geemap\n",
    "Map = geemap.Map()\n",
    "url = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}'\n",
    "Map.layout.height = '1000px'\n",
    "Map.add_tile_layer(url, name=\"Google Map\", attribution=\"Google\")\n",
    "\n",
    "Map.addLayer(out.select('singletCategory'), singlet_vis, 'singletCategory (matrix-filtered)')\n",
    "Map.addLayer(out.select('doubletPattern'), doublet_vis_6yr, 'doubletPattern (matrix-filtered)')\n",
    "Map.addLayer(out.select('y1'), vis_params_lulc, 'y1')\n",
    "Map.addLayer(out.select('y2'), vis_params_lulc, 'y2')\n",
    "Map.addLayer(out.select('y3'), vis_params_lulc, 'y3')\n",
    "Map.addLayer(out.select('y4'), vis_params_lulc, 'y4')\n",
    "Map.addLayer(out.select('y5'), vis_params_lulc, 'y5')\n",
    "Map.addLayer(out.select('y6'), vis_params_lulc, 'y6')\n",
    "\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec620a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6) APPLY TEMPORAL CORRECTIONS (6-year) USING YOUR RULES\n",
    "# ============================================================\n",
    "\n",
    "def _eq(img, val):\n",
    "    return img.eq(val)\n",
    "\n",
    "def _count_eq_6(y_list, val_img):\n",
    "    # count over y1..y6 how many equal val_img (pixel-wise)\n",
    "    c = ee.Image(0)\n",
    "    for yi in y_list:\n",
    "        c = c.add(yi.eq(val_img))\n",
    "    return c.toInt()\n",
    "\n",
    "def _apply_where_band(seq6, band_name, cond, new_val):\n",
    "    \"\"\"Return seq6 with one band updated where cond is true.\"\"\"\n",
    "    b = seq6.select(band_name)\n",
    "    b2 = b.where(cond, new_val).rename(band_name)\n",
    "    others = seq6.select(seq6.bandNames().remove(band_name))\n",
    "    return ee.Image.cat([others, b2]).select(seq6.bandNames())\n",
    "\n",
    "def _apply_flip_to_A(seq6, cond, A):\n",
    "    \"\"\"Flip pixels under cond to class A for all 6 years where values != A.\"\"\"\n",
    "    out = seq6\n",
    "    for i in range(1, 7):\n",
    "        bi = f'y{i}'\n",
    "        yi = out.select(bi)\n",
    "        out = _apply_where_band(out, bi, cond.And(yi.neq(A)), A)\n",
    "    return out\n",
    "\n",
    "def _apply_flip_B_to_A_in_mask(seq6, cond, A, B, years):\n",
    "    \"\"\"\n",
    "    In given list of years (e.g., [1,2,3,4]), flip B -> A where cond holds.\n",
    "    Does NOT touch A values; does NOT touch other classes outside {A,B}.\n",
    "    \"\"\"\n",
    "    out = seq6\n",
    "    for t in years:\n",
    "        bi = f'y{t}'\n",
    "        yi = out.select(bi)\n",
    "        out = _apply_where_band(out, bi, cond.And(yi.eq(B)), A)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _unpack_centers_from_mask_4bit(mask4):\n",
    "    \"\"\"\n",
    "    mask4 corresponds to [s2 s3 s4 s5] in bits [3 2 1 0]\n",
    "    Return images s2..s5 (0/1).\n",
    "    \"\"\"\n",
    "    s2 = mask4.rightShift(3).bitwiseAnd(1).rename('s2')\n",
    "    s3 = mask4.rightShift(2).bitwiseAnd(1).rename('s3')\n",
    "    s4 = mask4.rightShift(1).bitwiseAnd(1).rename('s4')\n",
    "    s5 = mask4.rightShift(0).bitwiseAnd(1).rename('s5')\n",
    "    return s2, s3, s4, s5\n",
    "\n",
    "\n",
    "def correct_singlets_6yr(seq6, sing):\n",
    "    \"\"\"\n",
    "    Apply your singlet correction rules by singletCategory, using global evidence.\n",
    "    Expects 'sing' output from singlet_category_6yr(seq6) (already matrix filtered).\n",
    "    \"\"\"\n",
    "    y = [seq6.select(f'y{i}') for i in range(1, 7)]\n",
    "    cat = sing.select('singletCategory')\n",
    "    mask4 = sing.select('singletSeqMask').toInt()           # 4-bit s2..s5\n",
    "    iso4  = sing.select('isolatedSingletMask').toInt()      # subset of mask4 (same bit layout)\n",
    "    s2, s3, s4, s5 = _unpack_centers_from_mask_4bit(mask4)\n",
    "    i2, i3, i4, i5 = _unpack_centers_from_mask_4bit(iso4)\n",
    "\n",
    "    out = seq6\n",
    "\n",
    "    # -------------------------\n",
    "    # CASE 1: disjoint singles\n",
    "    # Flip each isolated center year to its surrounding A (left==right)\n",
    "    # centers are y2..y5 (s2..s5)\n",
    "    # -------------------------\n",
    "    case1 = cat.eq(1)\n",
    "\n",
    "    # For each center t, set y[t] = y[t-1] (which equals y[t+1] by ABA)\n",
    "    # Only apply where the center is active AND case1\n",
    "    out = _apply_where_band(out, 'y2', case1.And(s2.eq(1)), out.select('y1'))\n",
    "    out = _apply_where_band(out, 'y3', case1.And(s3.eq(1)), out.select('y2'))  # note: uses updated y2 in out\n",
    "    out = _apply_where_band(out, 'y4', case1.And(s4.eq(1)), out.select('y3'))\n",
    "    out = _apply_where_band(out, 'y5', case1.And(s5.eq(1)), out.select('y4'))\n",
    "\n",
    "    # -------------------------\n",
    "    # CASE 3: run length 3 (ABABA*)\n",
    "    # Winner is A in that segment; flip Bs -> A inside the 5-year segment.\n",
    "    # Possible placements of 3 consecutive centers:\n",
    "    #  - (s2,s3,s4)=1  => segment years 1..5 (A=y1, B=y2)\n",
    "    #  - (s3,s4,s5)=1  => segment years 2..6 (A=y2, B=y3)\n",
    "    # -------------------------\n",
    "    case3 = cat.eq(3)\n",
    "    run3_123 = case3.And(s2.eq(1)).And(s3.eq(1)).And(s4.eq(1))   # centers 2,3,4\n",
    "    run3_234 = case3.And(s3.eq(1)).And(s4.eq(1)).And(s5.eq(1))   # centers 3,4,5\n",
    "\n",
    "    # placement 1: years 1..5, A=y1, B=y2\n",
    "    A = out.select('y1')\n",
    "    B = out.select('y2')\n",
    "    out = _apply_flip_B_to_A_in_mask(out, run3_123, A, B, years=[1,2,3,4,5])\n",
    "\n",
    "    # placement 2: years 2..6, A=y2, B=y3\n",
    "    A = out.select('y2')\n",
    "    B = out.select('y3')\n",
    "    out = _apply_flip_B_to_A_in_mask(out, run3_234, A, B, years=[2,3,4,5,6])\n",
    "\n",
    "    # -------------------------\n",
    "    # CASE 4: run length 4 (ABABAB)\n",
    "    # Tie -> choose A and flip all B -> A across years 1..6 (A=y1, B=y2)\n",
    "    # This only happens when all s2..s5 are 1.\n",
    "    # -------------------------\n",
    "    case4 = cat.eq(4)\n",
    "    run4 = case4.And(s2.eq(1)).And(s3.eq(1)).And(s4.eq(1)).And(s5.eq(1))\n",
    "    A = out.select('y1')\n",
    "    B = out.select('y2')\n",
    "    out = _apply_flip_B_to_A_in_mask(out, run4, A, B, years=[1,2,3,4,5,6])\n",
    "\n",
    "    # -------------------------\n",
    "    # CASE 2: run length 2 (ABAB**)\n",
    "    # Use full-sequence majority between A and B; tie -> choose A.\n",
    "    #\n",
    "    # Possible placements:\n",
    "    #  - (s2,s3)=1 => ABAB in years 1..4, A=y1, B=y2\n",
    "    #  - (s3,s4)=1 => ABAB in years 2..5, A=y2, B=y3\n",
    "    #  - (s4,s5)=1 => ABAB in years 3..6, A=y3, B=y4\n",
    "    # -------------------------\n",
    "    case2 = cat.eq(2)\n",
    "    run2_12 = case2.And(s2.eq(1)).And(s3.eq(1)).And(s4.eq(0)).And(s5.eq(0))\n",
    "    run2_23 = case2.And(s3.eq(1)).And(s4.eq(1)).And(s2.eq(0)).And(s5.eq(0))\n",
    "    run2_34 = case2.And(s4.eq(1)).And(s5.eq(1)).And(s2.eq(0)).And(s3.eq(0))\n",
    "\n",
    "    def _resolve_run2(out_img, cond, A_band, B_band):\n",
    "        A = out_img.select(A_band)\n",
    "        B = out_img.select(B_band)\n",
    "\n",
    "        # global counts across 6 years\n",
    "        ylist = [out_img.select(f'y{i}') for i in range(1, 7)]\n",
    "        cA = _count_eq_6(ylist, A)\n",
    "        cB = _count_eq_6(ylist, B)\n",
    "\n",
    "        A_wins = cA.gt(cB)\n",
    "        B_wins = cB.gt(cA)\n",
    "        tie    = cA.eq(cB)\n",
    "\n",
    "        # if strict majority: flip the minority to majority (across all 6 years)\n",
    "        out2 = out_img\n",
    "        out2 = _apply_flip_B_to_A_in_mask(out2, cond.And(A_wins), A, B, years=[1,2,3,4,5,6])\n",
    "        out2 = _apply_flip_B_to_A_in_mask(out2, cond.And(B_wins), B, A, years=[1,2,3,4,5,6])\n",
    "\n",
    "        # if tie: choose A and flip B->A\n",
    "        out2 = _apply_flip_B_to_A_in_mask(out2, cond.And(tie), A, B, years=[1,2,3,4,5,6])\n",
    "        return out2\n",
    "\n",
    "    out = _resolve_run2(out, run2_12, 'y1', 'y2')\n",
    "    out = _resolve_run2(out, run2_23, 'y2', 'y3')\n",
    "    out = _resolve_run2(out, run2_34, 'y3', 'y4')\n",
    "\n",
    "    # -------------------------\n",
    "    # CASE 6: composite\n",
    "    # Strategy: fix isolated (odd/disjoint) first, then recompute singlets and fix even (run2) next.\n",
    "    # -------------------------\n",
    "    case6 = cat.eq(6)\n",
    "\n",
    "    # Pass-1: apply isolated centers only (from isolatedSingletMask bits i2..i5)\n",
    "    tmp = out\n",
    "    tmp = _apply_where_band(tmp, 'y2', case6.And(i2.eq(1)), tmp.select('y1'))\n",
    "    tmp = _apply_where_band(tmp, 'y3', case6.And(i3.eq(1)), tmp.select('y2'))\n",
    "    tmp = _apply_where_band(tmp, 'y4', case6.And(i4.eq(1)), tmp.select('y3'))\n",
    "    tmp = _apply_where_band(tmp, 'y5', case6.And(i5.eq(1)), tmp.select('y4'))\n",
    "\n",
    "    # Recompute singlet info on updated sequence, then apply run2 logic again but only where case6\n",
    "    sing2 = singlet_category_6yr(tmp)\n",
    "    cat2  = sing2.select('singletCategory')\n",
    "    mask4b = sing2.select('singletSeqMask').toInt()\n",
    "    t2, t3, t4, t5 = _unpack_centers_from_mask_4bit(mask4b)\n",
    "\n",
    "    # Only handle the run2 part in pass-2 (category 2 equivalent) under original case6 pixels\n",
    "    case6_run2 = case6.And(cat2.eq(2))\n",
    "\n",
    "    run2b_12 = case6_run2.And(t2.eq(1)).And(t3.eq(1)).And(t4.eq(0)).And(t5.eq(0))\n",
    "    run2b_23 = case6_run2.And(t3.eq(1)).And(t4.eq(1)).And(t2.eq(0)).And(t5.eq(0))\n",
    "    run2b_34 = case6_run2.And(t4.eq(1)).And(t5.eq(1)).And(t2.eq(0)).And(t3.eq(0))\n",
    "\n",
    "    tmp = _resolve_run2(tmp, run2b_12, 'y1', 'y2')\n",
    "    tmp = _resolve_run2(tmp, run2b_23, 'y2', 'y3')\n",
    "    tmp = _resolve_run2(tmp, run2b_34, 'y3', 'y4')\n",
    "\n",
    "    # Merge composite-corrected pixels back into out\n",
    "    # (only replace where case6; otherwise keep out)\n",
    "    out = out.where(case6, tmp)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def correct_doublets_6yr(seq6, dbl):\n",
    "    \"\"\"\n",
    "    Apply doublet corrections:\n",
    "      pattern 1: A X Y A A *  (A=y1) => y2,y3 -> A\n",
    "      pattern 2: A A X Y A A  (A=y1) => y3,y4 -> A\n",
    "      pattern 3: * A A X Y A  (A=y2) => y4,y5 -> A\n",
    "    Expects 'dbl' from detect_doublet_6yr(seq6) (already matrix filtered).\n",
    "    \"\"\"\n",
    "    pat = dbl.select('doubletPattern').toInt()\n",
    "    has = dbl.select('hasDoublet').eq(1)\n",
    "\n",
    "    out = seq6\n",
    "\n",
    "    # pat==1\n",
    "    cond1 = has.And(pat.eq(1))\n",
    "    A1 = out.select('y1')\n",
    "    out = _apply_where_band(out, 'y2', cond1, A1)\n",
    "    out = _apply_where_band(out, 'y3', cond1, A1)\n",
    "\n",
    "    # pat==2\n",
    "    cond2 = has.And(pat.eq(2))\n",
    "    A2 = out.select('y1')\n",
    "    out = _apply_where_band(out, 'y3', cond2, A2)\n",
    "    out = _apply_where_band(out, 'y4', cond2, A2)\n",
    "\n",
    "    # pat==3\n",
    "    cond3 = has.And(pat.eq(3))\n",
    "    A3 = out.select('y2')\n",
    "    out = _apply_where_band(out, 'y4', cond3, A3)\n",
    "    out = _apply_where_band(out, 'y5', cond3, A3)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def apply_temporal_corrections_6yr(out_img):\n",
    "    \"\"\"\n",
    "    out_img is output of classify_temporal_flip_categories_6yr(images)\n",
    "    containing y1..y6 + singlet/doublet diagnostic bands.\n",
    "    Returns corrected sequence y1..y6 plus diagnostics.\n",
    "    \"\"\"\n",
    "    seq6 = out_img.select(['y1','y2','y3','y4','y5','y6'])\n",
    "    sing = out_img.select([\n",
    "        'singletCategory','singletSeqMask','isolatedSingletMask'\n",
    "    ])\n",
    "    dbl  = out_img.select(['doubletPattern','hasDoublet'])\n",
    "\n",
    "    # Apply singlets first (your pipeline), then doublets\n",
    "    seq_after_sing = correct_singlets_6yr(seq6, sing)\n",
    "    seq_after_both = correct_doublets_6yr(seq_after_sing, dbl)\n",
    "\n",
    "    return out_img.addBands(seq_after_both.rename(['y1c','y2c','y3c','y4c','y5c','y6c']), overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1df767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e1c687b0fc4a87b9f40fd650963182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[0, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], position='topright', transp…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected = apply_temporal_corrections_6yr(out)\n",
    "\n",
    "# visualize corrected sequence\n",
    "Map.addLayer(corrected.select('y1c'), vis_params_lulc, 'y1 corrected')\n",
    "Map.addLayer(corrected.select('y2c'), vis_params_lulc, 'y2 corrected')\n",
    "Map.addLayer(corrected.select('y3c'), vis_params_lulc, 'y3 corrected')\n",
    "Map.addLayer(corrected.select('y4c'), vis_params_lulc, 'y4 corrected')\n",
    "Map.addLayer(corrected.select('y5c'), vis_params_lulc, 'y5 corrected')\n",
    "Map.addLayer(corrected.select('y6c'), vis_params_lulc, 'y6 corrected')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9004c7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "chastainBandNames = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']\n",
    "\n",
    "# Regression model parameters from Table-4. MSI TOA reflectance as a function of OLI TOA reflectance.\n",
    "msiOLISlopes = [1.0946,1.0043,1.0524,0.8954,1.0049,1.0002]\n",
    "msiOLIIntercepts = [-0.0107,0.0026,-0.0015,0.0033,0.0065,0.0046]\n",
    "\n",
    "# Regression model parameters from Table-5. MSI TOA reflectance as a function of ETM+ TOA reflectance.\n",
    "msiETMSlopes = [1.10601,0.99091,1.05681,1.0045,1.03611,1.04011]\n",
    "msiETMIntercepts = [-0.0139,0.00411,-0.0024,-0.0076,0.00411,0.00861]\n",
    "\n",
    "# Regression model parameters from Table-6. OLI TOA reflectance as a function of ETM+ TOA reflectance.\n",
    "oliETMSlopes =[1.03501,1.00921,1.01991,1.14061,1.04351,1.05271];\n",
    "oliETMIntercepts = [-0.0055,-0.0008,-0.0021,-0.0163,-0.0045,0.00261]\n",
    "\n",
    "# Construct dictionary to handle all pairwise combos\n",
    "chastainCoeffDict = { 'MSI_OLI':[msiOLISlopes,msiOLIIntercepts,1], # check what the third item corresponds to\n",
    "                    'MSI_ETM':[msiETMSlopes,msiETMIntercepts,1],\n",
    "                    'OLI_ETM':[oliETMSlopes,oliETMIntercepts,1],\n",
    "                    'OLI_MSI':[msiOLISlopes,msiOLIIntercepts,0],\n",
    "                    'ETM_MSI':[msiETMSlopes,msiETMIntercepts,0],\n",
    "                    'ETM_OLI':[oliETMSlopes,oliETMIntercepts,0]\n",
    "                    }\n",
    "\n",
    "'''\n",
    "Function to mask cloudy pixels in Landsat-7\n",
    "'''\n",
    "def maskL7cloud(image):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "    return image.updateMask(mask).select(['B1', 'B2', 'B3' , 'B4' , 'B5' , 'B7']).rename('BLUE', 'GREEN', 'RED' , 'NIR' , 'SWIR1' , 'SWIR2')\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask cloudy pixels in Landsat-8\n",
    "'''\n",
    "def maskL8cloud(image):\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "    return image.updateMask(mask).select(['B2', 'B3', 'B4' , 'B5' , 'B6' , 'B7']).rename('BLUE', 'GREEN', 'RED' , 'NIR' , 'SWIR1' , 'SWIR2')\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask clouds using the quality band of Sentinel-2 TOA\n",
    "'''\n",
    "def maskS2cloudTOA(image):\n",
    "    qa = image.select('QA60')\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10\n",
    "    cirrusBitMask = 1 << 11\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0));\n",
    "    return image.updateMask(mask).select(['B2', 'B3', 'B4', 'B8',  'B11', 'B12']).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "\n",
    "'''\n",
    "Get Landsat and Sentinel image collections\n",
    "'''\n",
    "def Get_L7_L8_S2_ImageCollections(inputStartDate, inputEndDate, roi_boundary):\n",
    "    # ------ Landsat 7 TOA\n",
    "    L7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_TOA') \\\n",
    "            .filterDate(inputStartDate, inputEndDate) \\\n",
    "            .filterBounds(roi_boundary) \\\n",
    "            .map(maskL7cloud)\n",
    "    # print('\\n Original Landsat 7 TOA dataset: \\n',L7.limit(1).getInfo())\n",
    "    # print('Number of images in Landsat 7 TOA dataset: \\t',L7.size().getInfo())\n",
    "\n",
    "    # ------ Landsat 8 TOA\n",
    "    L8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA') \\\n",
    "            .filterDate(inputStartDate, inputEndDate) \\\n",
    "            .filterBounds(roi_boundary) \\\n",
    "            .map(maskL8cloud)\n",
    "    # print('\\n Original Landsat 8 TOA dataset: \\n', L8.limit(1).getInfo())\n",
    "    # print('Number of images in Landsat 8 TOA dataset: \\t',L8.size().getInfo())\n",
    "\n",
    "    # ------ Sentinel-2 TOA\n",
    "    S2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
    "            .filterDate(inputStartDate, inputEndDate) \\\n",
    "            .filterBounds(roi_boundary)  \\\n",
    "            .map(maskS2cloudTOA)\n",
    "    # print('\\n Original Sentinel-2 TOA dataset: \\n',S2.limit(1).getInfo())\n",
    "    # print('Number of images in Sentinel 2 TOA dataset: \\t',S2.size().getInfo())\n",
    "\n",
    "    return L7, L8, S2\n",
    "\n",
    "\n",
    "'''\n",
    "Function to apply model in one direction\n",
    "'''\n",
    "def dir0Regression(img,slopes,intercepts):\n",
    "    return img.select(chastainBandNames).multiply(slopes).add(intercepts)\n",
    "\n",
    "\n",
    "'''\n",
    "Applying the model in the opposite direction\n",
    "'''\n",
    "def dir1Regression(img,slopes,intercepts):\n",
    "    return img.select(chastainBandNames).subtract(intercepts).divide(slopes)\n",
    "\n",
    "\n",
    "'''\n",
    "Function to correct one sensor to another\n",
    "'''\n",
    "def harmonizationChastain(img, fromSensor,toSensor):\n",
    "    # Get the model for the given from and to sensor\n",
    "    comboKey = fromSensor.upper() + '_' + toSensor.upper()\n",
    "    coeffList = chastainCoeffDict[comboKey]\n",
    "    slopes = coeffList[0]\n",
    "    intercepts = coeffList[1]\n",
    "    direction = ee.Number(coeffList[2])\n",
    "\n",
    "    # Apply the model in the respective direction\n",
    "    out = ee.Algorithms.If(direction.eq(0),dir0Regression(img,slopes,intercepts),dir1Regression(img,slopes,intercepts))\n",
    "    return ee.Image(out).copyProperties(img).copyProperties(img,['system:time_start'])\n",
    "\n",
    "\n",
    "'''\n",
    "Calibrate Landsat-8 (OLI) and Sentinel-2 (MSI) to Landsat-7 (ETM+)\n",
    "'''\n",
    "def Harmonize_L7_L8_S2(L7, L8, S2):\n",
    "    # harmonization\n",
    "    harmonized_L8 = L8.map( lambda img: harmonizationChastain(img, 'OLI','ETM') )\n",
    "    harmonized_S2 = S2.map( lambda img: harmonizationChastain(img, 'MSI','ETM') )\n",
    "\n",
    "    # Merge harmonized landsat-8 and sentinel-2 to landsat-7 image collection\n",
    "    harmonized_LandsatSentinel_ic = ee.ImageCollection(L7.merge(harmonized_L8).merge(harmonized_S2))\n",
    "    # print(harmonized_LandsatSentinel_ic.size().getInfo())\n",
    "    return harmonized_LandsatSentinel_ic\n",
    "\n",
    "\n",
    "'''\n",
    "Add NDVI band to harmonized image collection\n",
    "'''\n",
    "def addNDVI(image):\n",
    "    return image.addBands(image.normalizedDifference(['NIR', 'RED']).rename('NDVI')).float()\n",
    "\n",
    "\n",
    "'''\n",
    "Function definitions to get NDVI values at each 16-day composites\n",
    "'''\n",
    "def Get_NDVI_image_datewise(harmonized_LS_ic, roi_boundary):\n",
    "    def get_NDVI_datewise(date):\n",
    "        empty_band_image = ee.Image(0).float().rename(['NDVI']).updateMask(ee.Image(0).clip(roi_boundary))\n",
    "        return harmonized_LS_ic.select(['NDVI']) \\\n",
    "                                .filterDate(ee.Date(date), ee.Date(date).advance(16, 'day')) \\\n",
    "                                .merge(empty_band_image)\\\n",
    "                                .median() \\\n",
    "                                .set('system:time_start',ee.Date(date).millis())\n",
    "    return get_NDVI_datewise\n",
    "\n",
    "def Get_LS_16Day_NDVI_TimeSeries(inputStartDate, inputEndDate, harmonized_LS_ic, roi_boundary):\n",
    "    startDate = datetime.strptime(inputStartDate,\"%Y-%m-%d\")\n",
    "    endDate = datetime.strptime(inputEndDate,\"%Y-%m-%d\")\n",
    "\n",
    "    date_list = pd.date_range(start=startDate, end=endDate, freq='16D').tolist()\n",
    "    date_list = ee.List( [datetime.strftime(curr_date,\"%Y-%m-%d\") for curr_date in date_list] )\n",
    "\n",
    "    LSC =  ee.ImageCollection.fromImages(date_list.map(Get_NDVI_image_datewise(harmonized_LS_ic, roi_boundary)))\n",
    "\n",
    "    return LSC\n",
    "\n",
    "\n",
    "'''\n",
    "Pair available LSC and modis values for each time stamp.\n",
    "'''\n",
    "def pairLSModis(lsRenameBands):\n",
    "    def pair(feature):\n",
    "        date = ee.Date( feature.get('system:time_start') )\n",
    "        startDateT = date.advance(-8,'day')\n",
    "        endDateT = date.advance(8,'day')\n",
    "\n",
    "        # ------ MODIS VI ( We can add EVI to the band list later )\n",
    "        modis = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
    "                .filterDate(startDateT, endDateT) \\\n",
    "                .select(['NDVI','SummaryQA']) \\\n",
    "                .filterBounds(roi_boundary) \\\n",
    "                .median() \\\n",
    "                .rename(['NDVI_modis', 'SummaryQA_modis'])\n",
    "\n",
    "        return feature.rename(lsRenameBands).addBands(modis)\n",
    "    return pair\n",
    "\n",
    "\n",
    "'''\n",
    "Function to get Pearson Correlation Coffecient to perform GapFilling\n",
    "'''\n",
    "def get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, bandList):\n",
    "    corr = LSC_modis_paired_ic.filterBounds(roi_boundary) \\\n",
    "                                .select(bandList).toArray() \\\n",
    "                                .arrayReduce( reducer = ee.Reducer.pearsonsCorrelation(), axes=[0], fieldAxis=1 ) \\\n",
    "                                .arrayProject([1]).arrayFlatten([['c', 'p']])\n",
    "    return corr\n",
    "\n",
    "\n",
    "'''Use print(...) to write to this console.\n",
    "Fill gaps in LSC timeseries using modis data\n",
    "'''\n",
    "def gapfillLSM(LSC_modis_regression_model, LSC_bandName, modis_bandName):\n",
    "    def peformGapfilling(image):\n",
    "        offset = LSC_modis_regression_model.select('offset')\n",
    "        scale = LSC_modis_regression_model.select('scale')\n",
    "        nodata = -1\n",
    "\n",
    "        lsc_image = image.select(LSC_bandName)\n",
    "        modisfit = image.select(modis_bandName).multiply(scale).add(offset)\n",
    "\n",
    "        mask = lsc_image.mask()#update mask needs an input (no default input from the API document)\n",
    "        gapfill = lsc_image.unmask(nodata)\n",
    "        gapfill = gapfill.where(mask.Not(), modisfit)\n",
    "\n",
    "        '''\n",
    "        in SummaryQA,\n",
    "        0: Good data, use with confidence\n",
    "        1: Marginal data, useful but look at detailed QA for more information\n",
    "        2: Pixel covered with snow/ice\n",
    "        3: Pixel is cloudy\n",
    "        '''\n",
    "        qc_m = image.select('SummaryQA_modis').unmask(3)  # missing value is grouped as cloud\n",
    "        w_m  = modisfit.mask().rename('w_m').where(qc_m.eq(0), 0.8)  # default is 0.8\n",
    "        w_m = w_m.where(qc_m.eq(1), 0.5)   # Marginal\n",
    "        w_m = w_m.where(qc_m.gte(2), 0.2) # snow/ice or cloudy\n",
    "\n",
    "        # make sure these modis values are read where there is missing data from LandSat, Sentinel\n",
    "        w_l = gapfill.mask() # default is 1\n",
    "        w_l = w_l.where(mask.Not(), w_m)\n",
    "\n",
    "        return gapfill.addBands(w_l).rename(['gapfilled_'+LSC_bandName,'SummaryQA']) #have NDVI from modis and a summary of clarity for each\n",
    "\n",
    "    return peformGapfilling\n",
    "\n",
    "\n",
    "'''\n",
    "Function to combine LSC with Modis data\n",
    "'''\n",
    "def Combine_LS_Modis(LSC):\n",
    "    lsRenameBands = ee.Image(LSC.first()).bandNames().map( lambda band: ee.String(band).cat('_lsc') )\n",
    "    LSC_modis_paired_ic = LSC.map( pairLSModis(lsRenameBands) )\n",
    "\n",
    "    # Output contains scale, offset i.e. two bands\n",
    "    LSC_modis_regression_model_NDVI = LSC_modis_paired_ic.select(['NDVI_modis', 'NDVI_lsc']) \\\n",
    "                                                            .reduce(ee.Reducer.linearFit())\n",
    "\n",
    "    corr_NDVI = get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, ['NDVI_modis', 'NDVI_lsc'])\n",
    "    LSMC_NDVI = LSC_modis_paired_ic.map(gapfillLSM(LSC_modis_regression_model_NDVI, 'NDVI_lsc', 'NDVI_modis'))\n",
    "\n",
    "    return LSMC_NDVI\n",
    "\n",
    "\n",
    "'''\n",
    "Mask out low quality pixels\n",
    "'''\n",
    "def mask_low_QA(lsmc_image):\n",
    "    low_qa = lsmc_image.select('SummaryQA').neq(0.2)\n",
    "    return lsmc_image.updateMask(low_qa).copyProperties(lsmc_image, ['system:time_start'])\n",
    "\n",
    "\n",
    "'''\n",
    "Add image timestamp to each image in time series\n",
    "'''\n",
    "def add_timestamp(image):\n",
    "    timeImage = image.metadata('system:time_start').rename('timestamp')\n",
    "    timeImageMasked = timeImage.updateMask(image.mask().select(0))\n",
    "    return image.addBands(timeImageMasked)\n",
    "\n",
    "\n",
    "'''\n",
    "Perform linear interpolation on missing values\n",
    "'''\n",
    "def performInterpolation(image):\n",
    "    image = ee.Image(image)\n",
    "    beforeImages = ee.List(image.get('before'))\n",
    "    beforeMosaic = ee.ImageCollection.fromImages(beforeImages).mosaic()\n",
    "    afterImages = ee.List(image.get('after'))\n",
    "    afterMosaic = ee.ImageCollection.fromImages(afterImages).mosaic()\n",
    "\n",
    "    # Interpolation formula\n",
    "    # y = y1 + (y2-y1)*((t – t1) / (t2 – t1))\n",
    "    # y = interpolated image\n",
    "    # y1 = before image\n",
    "    # y2 = after image\n",
    "    # t = interpolation timestamp\n",
    "    # t1 = before image timestamp\n",
    "    # t2 = after image timestamp\n",
    "\n",
    "    t1 = beforeMosaic.select('timestamp').rename('t1')\n",
    "    t2 = afterMosaic.select('timestamp').rename('t2')\n",
    "    t = image.metadata('system:time_start').rename('t')\n",
    "    timeImage = ee.Image.cat([t1, t2, t])\n",
    "    timeRatio = timeImage.expression('(t - t1) / (t2 - t1)', {\n",
    "                    't': timeImage.select('t'),\n",
    "                    't1': timeImage.select('t1'),\n",
    "                    't2': timeImage.select('t2'),\n",
    "                })\n",
    "\n",
    "    interpolated = beforeMosaic.add((afterMosaic.subtract(beforeMosaic).multiply(timeRatio)))\n",
    "    result = image.unmask(interpolated)\n",
    "    fill_value = ee.ImageCollection([beforeMosaic, afterMosaic]).mosaic()\n",
    "    result = result.unmask(fill_value)\n",
    "\n",
    "    return result.copyProperties(image, ['system:time_start'])\n",
    "\n",
    "\n",
    "def interpolate_timeseries(S1_TS):\n",
    "    lsmc_masked = S1_TS.map(mask_low_QA)\n",
    "    filtered = lsmc_masked.map(add_timestamp)\n",
    "\n",
    "    # Time window in which we are willing to look forward and backward for unmasked pixel in time series\n",
    "    timeWindow = 120\n",
    "\n",
    "    # Define a maxDifference filter to find all images within the specified days. Convert days to milliseconds.\n",
    "    millis = ee.Number(timeWindow).multiply(1000*60*60*24)\n",
    "    # Filter says that pick only those timestamps which lie between the 2 timestamps not more than millis difference apart\n",
    "    maxDiffFilter = ee.Filter.maxDifference(\n",
    "                                difference = millis,\n",
    "                                leftField = 'system:time_start',\n",
    "                                rightField = 'system:time_start',\n",
    "                                )\n",
    "\n",
    "    # Filter to find all images after a given image. Compare the image's timstamp against other images.\n",
    "    # Images ahead of target image should have higher timestamp.\n",
    "    lessEqFilter = ee.Filter.lessThanOrEquals(\n",
    "                                leftField = 'system:time_start',\n",
    "                                rightField = 'system:time_start'\n",
    "                            )\n",
    "\n",
    "    # Similarly define this filter to find all images before a given image\n",
    "    greaterEqFilter = ee.Filter.greaterThanOrEquals(\n",
    "                                leftField = 'system:time_start',\n",
    "                                rightField = 'system:time_start'\n",
    "                            )\n",
    "\n",
    "    # Apply first join to find all images that are after the target image but within the timeWindow\n",
    "    filter1 = ee.Filter.And( maxDiffFilter, lessEqFilter )\n",
    "    join1 = ee.Join.saveAll(\n",
    "                    matchesKey = 'after',\n",
    "                    ordering = 'system:time_start',\n",
    "                    ascending = False\n",
    "            )\n",
    "    join1Result = join1.apply(\n",
    "                    primary = filtered,\n",
    "                    secondary = filtered,\n",
    "                    condition = filter1\n",
    "                    )\n",
    "\n",
    "    # Apply first join to find all images that are after the target image but within the timeWindow\n",
    "    filter2 = ee.Filter.And( maxDiffFilter, greaterEqFilter )\n",
    "    join2 = ee.Join.saveAll(\n",
    "                    matchesKey = 'before',\n",
    "                    ordering = 'system:time_start',\n",
    "                    ascending = True\n",
    "            )\n",
    "    join2Result = join2.apply(\n",
    "                    primary = join1Result,\n",
    "                    secondary = join1Result,\n",
    "                    condition = filter2\n",
    "                    )\n",
    "\n",
    "    interpolated_S1_TS = ee.ImageCollection(join2Result.map(performInterpolation))\n",
    "\n",
    "    return interpolated_S1_TS\n",
    "\n",
    "\n",
    "'''\n",
    "Function Definition to get Padded NDVI LSMC timeseries image for a given ROI\n",
    "'''\n",
    "def Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary):\n",
    "    L7, L8, S2 = Get_L7_L8_S2_ImageCollections(startDate, endDate, roi_boundary)\n",
    "\n",
    "    harmonized_LS_ic = Harmonize_L7_L8_S2(L7, L8, S2)\n",
    "    harmonized_LS_ic = harmonized_LS_ic.map(addNDVI)\n",
    "    LSC = Get_LS_16Day_NDVI_TimeSeries(startDate, endDate, harmonized_LS_ic, roi_boundary)\n",
    "    LSMC_NDVI = Combine_LS_Modis(LSC)\n",
    "    Interpolated_LSMC_NDVI = interpolate_timeseries(LSMC_NDVI)\n",
    "    final_LSMC_NDVI_TS = Interpolated_LSMC_NDVI.select(['gapfilled_NDVI_lsc']).toBands()\n",
    "    final_LSMC_NDVI_TS = final_LSMC_NDVI_TS.clip(roi_boundary)\n",
    "\n",
    "    input_bands = final_LSMC_NDVI_TS.bandNames()\n",
    "    return final_LSMC_NDVI_TS, input_bands\n",
    "\n",
    "\n",
    "'''\n",
    "Function definition to compute euclidean distance to each cluster centroid\n",
    "features ---> clusters\n",
    "flattened ---> time series image clipped to target area\n",
    "input_bands ---> band names for time series image\n",
    "studyarea ---> geometry of region of interest\n",
    "'''\n",
    "# Function to get distances as required from each pixel to each cluster centroid\n",
    "def Get_Euclidean_Distance(cluster_centroids, roi_timeseries_img, input_bands, roi_boundary):\n",
    "\n",
    "    def wrapper(curr_centroid):\n",
    "        temp_img = ee.Image()\n",
    "        curr_centroid = ee.Feature(curr_centroid).setGeometry(roi_boundary)\n",
    "        temp_fc = ee.FeatureCollection( [curr_centroid] )\n",
    "        class_img = temp_fc.select(['class']).reduceToImage(['class'], ee.Reducer.first()).rename(['class'])\n",
    "        def create_img(band_name):\n",
    "            return temp_fc.select([band_name]).reduceToImage([band_name], ee.Reducer.first()).rename([band_name])\n",
    "\n",
    "        temp_img = input_bands.map(create_img)\n",
    "        empty = ee.Image()\n",
    "        temp_img = ee.Image( temp_img.iterate( lambda img, prev: ee.Image(prev).addBands(img) , empty))\n",
    "\n",
    "        temp_img = temp_img.select(temp_img.bandNames().remove('constant'))\n",
    "        distance = roi_timeseries_img.spectralDistance(temp_img, 'sed')\n",
    "        confidence = ee.Image(1.0).divide(distance).rename(['confidence'])\n",
    "        distance = distance.addBands(confidence)\n",
    "        return distance.addBands(class_img.rename(['class'])).set('class', curr_centroid.get('class'))\n",
    "\n",
    "    return cluster_centroids.map(wrapper)\n",
    "\n",
    "\n",
    "'''\n",
    "Function definition to get final prediction image from distance images\n",
    "'''\n",
    "def Get_final_prediction_image(distance_imgs_list):\n",
    "    # Denominator is an image that is sum of all confidences to each cluster\n",
    "    sum_of_distances = ee.ImageCollection( distance_imgs_list ).select(['confidence']).sum().unmask()\n",
    "    distance_imgs_ic = ee.ImageCollection( distance_imgs_list ).select(['distance','class'])\n",
    "\n",
    "    # array is an image where distance band is an array of distances to each cluster centroid and class band is an array of classes associated with each cluster\n",
    "    array_img = ee.ImageCollection(distance_imgs_ic).toArray()\n",
    "\n",
    "    axes = {'image': 0, 'band':1}\n",
    "    sort = array_img.arraySlice(axes['band'], 0, 1)\n",
    "    sorted = array_img.arraySort(sort)\n",
    "\n",
    "    # take the first image only\n",
    "    values = sorted.arraySlice(axes['image'], 0, 1)\n",
    "    # convert back to an image\n",
    "    min = values.arrayProject([axes['band']]).arrayFlatten([['distance', 'class']])\n",
    "    # Extract the hard classification\n",
    "    predicted_class_img = min.select(1)\n",
    "    predicted_class_img = predicted_class_img.rename(['predicted_label'])\n",
    "\n",
    "    return predicted_class_img\n",
    "\n",
    "## My Helper Functions\n",
    "def change_clusters(cluster_centroids):\n",
    "    size = cluster_centroids.size().getInfo()\n",
    "    features = []\n",
    "    for i in range(size):\n",
    "        features.append(ee.Feature(cluster_centroids.toList(size).get(i)).set(\"class\", 13+i))\n",
    "    return ee.FeatureCollection(features)\n",
    "\n",
    "\n",
    "def get_cropping_frequency(roi_boundary, startDate, endDate):\n",
    "    cluster_centroids = ee.FeatureCollection('projects/ee-indiasat/assets/L3_LULC_Clusters/Final_Level3_PanIndia_Clusters')\n",
    "    ignore_clusters = [12] # remove invalid clusters\n",
    "    cluster_centroids = cluster_centroids.filter(ee.Filter.Not( ee.Filter.inList('class', ignore_clusters)))\n",
    "    \n",
    "    final_LSMC_NDVI_TS, input_bands =  Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary)\n",
    "    distance_imgs_list = Get_Euclidean_Distance(cluster_centroids, final_LSMC_NDVI_TS, input_bands, roi_boundary)\n",
    "    final_classified_img = Get_final_prediction_image(distance_imgs_list)\n",
    "    ### adding Cluster values after 12\n",
    "    #cluster_centroids = change_clusters(cluster_centroids)\n",
    "    distance_imgs_list = Get_Euclidean_Distance(cluster_centroids, final_LSMC_NDVI_TS, input_bands, roi_boundary)\n",
    "    final_cluster_classified_img = Get_final_prediction_image(distance_imgs_list)\n",
    "    final_cluster_classified_img = final_cluster_classified_img.rename(['predicted_cluster'])\n",
    "    final_classified_img = final_classified_img.addBands(final_cluster_classified_img)\n",
    "    return final_classified_img, final_LSMC_NDVI_TS\n",
    "\n",
    "def get_six_year_cropping_frequency_rasters(roi_boundary, start_year, num_years=6):\n",
    "    \"\"\"\n",
    "    Uses your existing get_cropping_frequency(roi_boundary, startDate, endDate)\n",
    "    and produces a list of 6 yearly cropping-frequency images.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Does NOT rename or modify your existing functions/variables.\n",
    "    - Each output image is clipped to roi_boundary (as your pipeline already does inside Get_Padded_NDVI_TS_Image).\n",
    "    - Output list order: [Y1, Y2, ..., Y6] where\n",
    "        Y1 = start_year-07-01 to start_year+1-06-30\n",
    "        ...\n",
    "        Y6 = start_year+5-07-01 to start_year+6-06-30\n",
    "\n",
    "    Returns:\n",
    "      crop_freq_imgs: Python list of ee.Image (each has band 'predicted_label' and 'predicted_cluster')\n",
    "      date_ranges:    Python list of (startDate, endDate) strings for bookkeeping\n",
    "    \"\"\"\n",
    "    crop_freq_imgs = []\n",
    "    date_ranges = []\n",
    "\n",
    "    for i in range(num_years):\n",
    "        y1 = start_year + i\n",
    "        y2 = y1 + 1\n",
    "\n",
    "        currStartDate = f\"{y1}-07-01\"\n",
    "        currEndDate   = f\"{y2}-06-30\"\n",
    "\n",
    "        # Your function returns:\n",
    "        #   final_classified_img: bands ['predicted_label', 'predicted_cluster']\n",
    "        #   final_LSMC_NDVI_TS:   NDVI time-series (not needed here)\n",
    "        cropping_frequency_img, _ = get_cropping_frequency(roi_boundary, currStartDate, currEndDate)\n",
    "\n",
    "        # Keep as-is (same variable names, same band names)\n",
    "        crop_freq_imgs.append(cropping_frequency_img.select(['predicted_label',]))\n",
    "        date_ranges.append((currStartDate, currEndDate))\n",
    "\n",
    "    return crop_freq_imgs, date_ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c00644a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7) RE-INTRODUCE MERGED CLASSES (WATER + CROP) INTO FINAL MAPS\n",
    "# ============================================================\n",
    "\n",
    "# Original classes and grouped mapping (same as you used)\n",
    "ORIG =  [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "GROUP = [0, 1, 2, 2, 2, 6, 7, 8, 8,  8,  8,  12, 13]\n",
    "\n",
    "BAND = 'predicted_label'\n",
    "\n",
    "WATER_SET = ee.List([2, 3, 4])          # original water subclasses\n",
    "CROP_SET  = ee.List([8, 9, 10, 11])     # original crop subclasses\n",
    "\n",
    "def _is_in_list(img, vals):\n",
    "    # vals is ee.List of ints\n",
    "    return ee.Image(img).remap(vals, ee.List.repeat(1, vals.size()), 0).eq(1)\n",
    "\n",
    "def _group_from_orig(orig_img):\n",
    "    # orig_img: ee.Image single band predicted_label\n",
    "    return orig_img.remap(ORIG, GROUP).toInt()\n",
    "\n",
    "def _safe_water_source(orig_img):\n",
    "    \"\"\"\n",
    "    Ensure output is a valid water subclass. If orig_img isn't water (2/3/4), fall back to 2.\n",
    "    \"\"\"\n",
    "    isw = _is_in_list(orig_img, WATER_SET)\n",
    "    return ee.Image(orig_img).where(isw.Not(), 2).toInt()\n",
    "\n",
    "def reinstate_merged_classes_6yr(original_year_imgs, corrected_img, crop_intensity_imgs=None, band=BAND):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      original_year_imgs : list of 6 ee.Image (un-grouped), each containing `band` (predicted_label).\n",
    "      corrected_img      : ee.Image that contains grouped corrected bands y1c..y6c\n",
    "                           and doubletPattern/hasDoublet (as in your pipeline).\n",
    "      crop_intensity_imgs: optional list of 6 ee.Image, each with `band` in {8,9,10,11}.\n",
    "                           Used only where corrected class is crop (8) but original year is not crop.\n",
    "\n",
    "    Output:\n",
    "      ee.Image with bands y1f..y6f (final un-grouped labels).\n",
    "    \"\"\"\n",
    "    if len(original_year_imgs) != 6:\n",
    "        raise ValueError(\"Provide exactly 6 original yearly images.\")\n",
    "    if crop_intensity_imgs is not None and len(crop_intensity_imgs) != 6:\n",
    "        raise ValueError(\"If provided, crop_intensity_imgs must have exactly 6 images.\")\n",
    "\n",
    "    # Doublet pattern flags (already matrix-filtered earlier)\n",
    "    pat = corrected_img.select('doubletPattern').toInt()\n",
    "    has = corrected_img.select('hasDoublet').eq(1)\n",
    "\n",
    "    p1 = has.And(pat.eq(1))  # A X Y A A *\n",
    "    p2 = has.And(pat.eq(2))  # A A X Y A A\n",
    "    p3 = has.And(pat.eq(3))  # * A A X Y A\n",
    "\n",
    "    # For each year t, mark if that year is X or Y (only matters if we need to \"recreate\" water subclass)\n",
    "    # Pattern 1 affects y2 (X) and y3 (Y)\n",
    "    # Pattern 2 affects y3 (X) and y4 (Y)\n",
    "    # Pattern 3 affects y4 (X) and y5 (Y)\n",
    "    isX = {\n",
    "        1: ee.Image(0).eq(1),      # false\n",
    "        2: p1,\n",
    "        3: p2,\n",
    "        4: p3,\n",
    "        5: ee.Image(0).eq(1),\n",
    "        6: ee.Image(0).eq(1),\n",
    "    }\n",
    "    isY = {\n",
    "        1: ee.Image(0).eq(1),      # false\n",
    "        2: ee.Image(0).eq(1),\n",
    "        3: p1,\n",
    "        4: p2,\n",
    "        5: p3,\n",
    "        6: ee.Image(0).eq(1),\n",
    "    }\n",
    "\n",
    "    out_bands = []\n",
    "\n",
    "    for t in range(1, 7):\n",
    "        orig_t = ee.Image(original_year_imgs[t-1]).select([band]).toInt()     # original fine label\n",
    "        orig_grp_t = _group_from_orig(orig_t)                                 # grouped original\n",
    "        corr_grp_t = corrected_img.select(f'y{t}c').toInt()                   # grouped corrected\n",
    "\n",
    "        # Start with original by default\n",
    "        final_t = orig_t\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # (A) Non-water, non-crop classes: we can directly write grouped label\n",
    "        #     because they were not merged (built-up, tree, barren, scrub, plantation, background).\n",
    "        # ------------------------------------------------------------------\n",
    "        isWaterCorr = corr_grp_t.eq(2)\n",
    "        isCropCorr  = corr_grp_t.eq(8)\n",
    "\n",
    "        nonMerged = isWaterCorr.Or(isCropCorr).Not()\n",
    "        # If corrected differs from original grouped AND it's non-merged, write corr_grp directly\n",
    "        final_t = final_t.where(nonMerged.And(corr_grp_t.neq(orig_grp_t)), corr_grp_t)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # (B) Crop re-introduction:\n",
    "        #   If corrected says \"crop(8)\":\n",
    "        #     - If original already had a crop subclass (8/9/10/11), keep it.\n",
    "        #     - Else use crop_intensity_imgs[t-1] if provided; otherwise fallback to 8.\n",
    "        # ------------------------------------------------------------------\n",
    "        if crop_intensity_imgs is not None:\n",
    "            crop_pred_t = ee.Image(crop_intensity_imgs[t-1]).select([band]).toInt()\n",
    "        else:\n",
    "            crop_pred_t = ee.Image(8).toInt()\n",
    "\n",
    "        orig_is_crop = _is_in_list(orig_t, CROP_SET)\n",
    "\n",
    "        crop_fill = ee.Image(orig_t) \\\n",
    "            .where(orig_is_crop.Not(), crop_pred_t) \\\n",
    "            .toInt()\n",
    "\n",
    "        final_t = final_t.where(isCropCorr, crop_fill)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # (C) Water re-introduction:\n",
    "        #   If corrected says \"water(2)\":\n",
    "        #     - If original already had water subclass (2/3/4), keep it.\n",
    "        #     - Else:\n",
    "        #         * Singlet/other cases: use water class from one year before (t-1).\n",
    "        #         * Doublet cases:\n",
    "        #              - if this year is X -> use (t-1)\n",
    "        #              - if this year is Y -> use (t-2)\n",
    "        #       If chosen source isn't water, fall back to:\n",
    "        #           (1) other prior source (t-2), else\n",
    "        #           (2) 2 (generic water)\n",
    "        # ------------------------------------------------------------------\n",
    "        orig_is_water = _is_in_list(orig_t, WATER_SET)\n",
    "\n",
    "        # prior sources (as images); if out of range, use orig_t itself\n",
    "        prev1 = ee.Image(original_year_imgs[t-2]).select([band]).toInt() if t >= 2 else orig_t\n",
    "        prev2 = ee.Image(original_year_imgs[t-3]).select([band]).toInt() if t >= 3 else prev1\n",
    "\n",
    "        prev1w = _safe_water_source(prev1)\n",
    "        prev2w = _safe_water_source(prev2)\n",
    "\n",
    "        # choose source based on X/Y (doublet) or default singlet-like (t-1)\n",
    "        choose_prev2 = isY[t]  # Y -> (t-2)\n",
    "        choose_prev1 = isX[t].Or(choose_prev2.Not())  # X or non-doublet -> (t-1)\n",
    "\n",
    "        water_source = ee.Image(2).toInt()\n",
    "        water_source = water_source.where(choose_prev1, prev1w)\n",
    "        water_source = water_source.where(choose_prev2, prev2w)\n",
    "\n",
    "        # If original already water subclass, keep it; else use chosen source\n",
    "        water_fill = ee.Image(orig_t).where(orig_is_water.Not(), water_source).toInt()\n",
    "\n",
    "        final_t = final_t.where(isWaterCorr, water_fill)\n",
    "\n",
    "        out_bands.append(final_t.rename(f'y{t}f'))\n",
    "\n",
    "    return ee.Image.cat(out_bands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c07814d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crop_freq_imgs, crop_freq_date_ranges = get_six_year_cropping_frequency_rasters(\n",
    "    roi_boundary=roi_boundary,\n",
    "    start_year=2017,\n",
    "    num_years=6\n",
    ")\n",
    "\n",
    "final_img = reinstate_merged_classes_6yr(\n",
    "    original_year_imgs=images,\n",
    "    corrected_img=corrected,\n",
    "    crop_intensity_imgs=crop_freq_imgs  # later you will pass your 6 yearly crop-intensity rasters here\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdec7629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Map.addLayer(final_img.select('y1f'), vis_params_lulc, 'y1 final (un-grouped)')\n",
    "#Map.addLayer(final_img.select('y2f'), vis_params_lulc, 'y2 final (un-grouped)')\n",
    "#Map.addLayer(final_img.select('y3f'), vis_params_lulc, 'y3 final (un-grouped)')\n",
    "#Map.addLayer(final_img.select('y4f'), vis_params_lulc, 'y4 final (un-grouped)')\n",
    "#Map.addLayer(final_img.select('y5f'), vis_params_lulc, 'y5 final (un-grouped)')\n",
    "#Map.addLayer(final_img.select('y6f'), vis_params_lulc, 'y6 final (un-grouped)')\n",
    "#Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "894e7aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started export: projects/raman-461708/assets/AEZ_19_2017-07-01_2018-06-30_temporal_corrected\n",
      "Started export: projects/raman-461708/assets/AEZ_19_2018-07-01_2019-06-30_temporal_corrected\n",
      "Started export: projects/raman-461708/assets/AEZ_19_2019-07-01_2020-06-30_temporal_corrected\n",
      "Started export: projects/raman-461708/assets/AEZ_19_2020-07-01_2021-06-30_temporal_corrected\n",
      "Started export: projects/raman-461708/assets/AEZ_19_2021-07-01_2022-06-30_temporal_corrected\n",
      "Started export: projects/raman-461708/assets/AEZ_19_2022-07-01_2023-06-30_temporal_corrected\n"
     ]
    }
   ],
   "source": [
    "def export_temporal_corrected_assets(\n",
    "    imgs,                 # list of ee.Image (length = num_years)\n",
    "    aez,                  # int (AEZ number)\n",
    "    start_year,           # int (e.g., 2017)\n",
    "    project='raman-461708',\n",
    "    region_fc=\"users/mtpictd/agro_eco_regions\",  # same as your ROI source\n",
    "    scale=10,\n",
    "    maxPixels=1e13\n",
    "):\n",
    "    # ROI geometry for the AEZ (keeps exports tight)\n",
    "    roi_geom = ee.FeatureCollection(region_fc) \\\n",
    "        .filter(ee.Filter.eq(\"ae_regcode\", aez)) \\\n",
    "        .geometry()\n",
    "\n",
    "    tasks = []\n",
    "    for i, img in enumerate(imgs):\n",
    "        y1 = start_year + i\n",
    "        y2 = y1 + 1\n",
    "\n",
    "        # Same date naming you used while loading\n",
    "        date_tag = f\"{y1}-07-01_{y2}-06-30\"\n",
    "\n",
    "        # Asset ID with requested extension\n",
    "        asset_id = f\"projects/{project}/assets/AEZ_{aez}_{date_tag}_temporal_corrected\"\n",
    "\n",
    "        # Task description (must be short-ish and unique)\n",
    "        desc = f\"AEZ_{aez}_{y1}_{y2}_temporal_corrected\"\n",
    "\n",
    "        task = ee.batch.Export.image.toAsset(\n",
    "            image=ee.Image(img).clip(roi_geom),\n",
    "            description=desc,\n",
    "            assetId=asset_id,\n",
    "            region=roi_geom,\n",
    "            scale=scale,\n",
    "            maxPixels=maxPixels\n",
    "        )\n",
    "        task.start()\n",
    "        tasks.append(task)\n",
    "\n",
    "        print(f\"Started export: {asset_id}\")\n",
    "\n",
    "    return tasks\n",
    "\n",
    "tasks = export_temporal_corrected_assets(\n",
    "     imgs=[final_img.select('y'+str(i)+'f') for i in [1,2,3,4,5,6]],\n",
    "     aez=aez,\n",
    "     start_year=start_year,\n",
    "     project='raman-461708',\n",
    "     scale=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324eb8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
