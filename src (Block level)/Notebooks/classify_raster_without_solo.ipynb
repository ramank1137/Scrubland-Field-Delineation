{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBg2jArDvSv3"
   },
   "source": [
    "## Authenticate to Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GXSXdKfivbFF"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "ee.Authenticate() #Uncomment this whenever needed, once done usually not needed for 1-2 days\n",
    "ee.Initialize(project='ee-raman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_collection(asset_id):\n",
    "    \"\"\"Check if an asset exists, and load it as a FeatureCollection if it does.\n",
    "    Otherwise, return an empty FeatureCollection.\n",
    "    \n",
    "    Args:\n",
    "        asset_id (str): The Earth Engine asset ID.\n",
    "        \n",
    "    Returns:\n",
    "        ee.FeatureCollection: The loaded FeatureCollection or an empty one.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get asset information to check existence\n",
    "        ee.data.getAsset(asset_id)\n",
    "        print(f\"Asset '{asset_id}' exists. Loading FeatureCollection.\")\n",
    "        return ee.FeatureCollection(asset_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Asset '{asset_id}' does not exist. Returning empty FeatureCollection.\")\n",
    "        return ee.FeatureCollection([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Function to convert latitude to pixel Y at a given zoom level\n",
    "def lat_to_pixel_y(lat, zoom):\n",
    "    sin_lat = math.sin(math.radians(lat))\n",
    "    pixel_y = ((0.5 - math.log((1 + sin_lat) / (1 - sin_lat)) / (4 * math.pi)) * (2 ** (zoom + 8)))\n",
    "    return pixel_y\n",
    "\n",
    "# Function to convert longitude to pixel X at a given zoom level\n",
    "def lon_to_pixel_x(lon, zoom):\n",
    "    pixel_x = ((lon + 180) / 360) * (2 ** (zoom + 8))\n",
    "    return pixel_x\n",
    "\n",
    "# Function to convert pixel X to longitude\n",
    "def pixel_x_to_lon(pixel_x, zoom):\n",
    "    lon = (pixel_x / (2 ** (zoom + 8))) * 360 - 180\n",
    "    return lon\n",
    "\n",
    "# Function to convert pixel Y to latitude\n",
    "def pixel_y_to_lat(pixel_y, zoom):\n",
    "    n = math.pi - 2 * math.pi * pixel_y / (2 ** (zoom + 8))\n",
    "    lat = math.degrees(math.atan(math.sinh(n)))\n",
    "    return lat\n",
    "\n",
    "def lat_lon_from_pixel(lat, lon, zoom, scale):\n",
    "    \"\"\"\n",
    "    Given a starting latitude and longitude, calculate the latitude and longitude\n",
    "    of the opposite corner of a 256x256 image at a given zoom level.\n",
    "    \"\"\"\n",
    "    pixel_x = lon_to_pixel_x(lon, zoom)\n",
    "    pixel_y = lat_to_pixel_y(lat, zoom)\n",
    "    \n",
    "    new_lon = pixel_x_to_lon(pixel_x + 256*scale, zoom)\n",
    "    new_lat = pixel_y_to_lat(pixel_y + 256*scale, zoom)\n",
    "\n",
    "    return new_lat, new_lon\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Helper function for dividing an roi into blocks\n",
    "\n",
    "\"\"\"\n",
    "def get_n_boxes(lat, lon, n, zoom, scale):\n",
    "    diagonal_lat_lon = [(lat, lon),]\n",
    "    for i in range(n):\n",
    "        new_lat_lon = lat_lon_from_pixel(lat, lon, zoom, scale)\n",
    "        diagonal_lat_lon.append(new_lat_lon)\n",
    "        lat, lon = new_lat_lon\n",
    "    lats = [i[0] for i in diagonal_lat_lon]\n",
    "    longs = [i[1] for i in diagonal_lat_lon]\n",
    "    return list(product(lats, longs))\n",
    "\n",
    "def get_points(roi, directory):\n",
    "    points_file = Path(directory + \"/status.csv\")\n",
    "    if points_file.is_file():\n",
    "        df = pd.read_csv(directory + \"/status.csv\", index_col=False)\n",
    "        df[\"points\"] = df['points'].apply(ast.literal_eval)\n",
    "        return df\n",
    "    zoom = 17\n",
    "    scale = 16\n",
    "    bounds = roi.bounds().coordinates().get(0).getInfo()\n",
    "    lons = sorted([i[0] for i in bounds])\n",
    "    lats = sorted([i[1] for i in bounds])\n",
    "    starting_point = lats[-1], lons[0]\n",
    "    min_, max_ = (\n",
    "        [lon_to_pixel_x(lons[0], zoom), lat_to_pixel_y(lats[0], zoom) ],\n",
    "        [lon_to_pixel_x(lons[-1], zoom), lat_to_pixel_y(lats[-1], zoom)]\n",
    "        )\n",
    "    iterations = math.ceil(max(abs(min_[0] -  max_[0]), abs(min_[1] - max_[1]))/256/16)\n",
    "    points = get_n_boxes(starting_point[0], starting_point[1], iterations, zoom, scale)\n",
    "    intersect_list = []\n",
    "    print(len(points))\n",
    "    index = 0\n",
    "    for point in points:\n",
    "        top_left = point\n",
    "        bottom_right = lat_lon_from_pixel(top_left[0], top_left[1], zoom, scale)\n",
    "        rectangle = ee.Geometry.Rectangle([(top_left[1], top_left[0]), (bottom_right[1], bottom_right[0])])\n",
    "        print(top_left, bottom_right)\n",
    "        intersects = roi.geometry().intersects(rectangle, ee.ErrorMargin(1)).getInfo()\n",
    "        if intersects:\n",
    "            intersect_list.append((index, (top_left,bottom_right)))\n",
    "            index+=1\n",
    "        print(intersects)\n",
    "    df = pd.DataFrame(intersect_list, columns=[\"index\", \"points\"])\n",
    "    df[\"overall_status\"] = False\n",
    "    df[\"download_status\"] = False\n",
    "    df[\"model_status\"] = False\n",
    "    df[\"segmentation_status\"] = False\n",
    "    df[\"postprocessing_status\"] = False\n",
    "    df[\"plantation_status\"] = False\n",
    "    df.to_csv(directory + \"/status.csv\", index=False)\n",
    "    return df\n",
    "\n",
    "roi_boundary = ee.FeatureCollection(\"users/mtpictd/india_block_boundaries\").filter(ee.Filter.eq(\"block\", \"Bheramgarh\"))\n",
    "directory = \"Area_bheramgarh\"\n",
    "roi_boundary = ee.FeatureCollection(\"users/mtpictd/india_block_boundaries\").filter(ee.Filter.eq(\"block\", \"Jamkhed\"))\n",
    "directory = \"Area_jamkhed\"\n",
    "roi_boundary = ee.FeatureCollection(\"users/mtpictd/india_block_boundaries\").filter(ee.Filter.eq(\"block\", \"Peddapally\"))\n",
    "directory = \"Area_Peddapally\"\n",
    "\n",
    "blocks_df = get_points(roi_boundary, directory)\n",
    "points = list(blocks_df[\"points\"])\n",
    "\n",
    "roi_boundary = ee.FeatureCollection([ee.Feature(ee.Geometry.Rectangle([top_left[1], bottom_right[0], bottom_right[1], top_left[0]])) for top_left, bottom_right in points])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset 'projects/ee-raman/assets/Area_Peddapally_boundaries' exists. Loading FeatureCollection.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mapping = {\n",
    "    \"farm\": 1,\n",
    "    \"plantation\": 2,\n",
    "    \"scrubland\": 3,\n",
    "    \"rest\": 0\n",
    "}\n",
    "reversed_mapping = {v: k for k, v in mapping.items()}\n",
    "reversed_ee_mapping = ee.Dictionary(reversed_mapping)\n",
    "\n",
    "easy_farm = [\n",
    "    ee.Filter.gte(\"rect\", 0.67),\n",
    "    ee.Filter.gt(\"size\", 500),\n",
    "    ee.Filter.lt(\"size\", 2000),\n",
    "    ee.Filter.lt(\"ent\", 1)\n",
    "    ]\n",
    "easy_scurbland = [\n",
    "    ee.Filter.gte(\"size\", 60000),\n",
    "    ee.Filter.gt(\"red\", 0.9)\n",
    "    ]\n",
    "easy_plantation = [\n",
    "    ee.Filter.lt(\"area\", 20000),\n",
    "    ee.Filter.gt(\"area\", 1000)\n",
    "]\n",
    "\n",
    "\n",
    "all = get_feature_collection(\"projects/ee-raman/assets/\" + directory + \"_boundaries\")\n",
    "farm = all.filter(ee.Filter.And(*easy_farm))\n",
    "scrubland = all.filter(ee.Filter.And(easy_scurbland))\n",
    "plantation = all.filter(ee.Filter.eq(\"class\", \"plantation\")).map(lambda x: x.set(\"area\", x.geometry().area())).filter(ee.Filter.And(easy_plantation))\n",
    "\n",
    "farm_buffer = farm.map(lambda x: x.buffer(10))\n",
    "farm_image = ee.Image(0)\n",
    "farm_mask = farm_image.clip(farm_buffer).mask()\n",
    "farm_vectors = farm_mask.toInt().reduceToVectors(\n",
    "    geometry=roi_boundary,\n",
    "    scale=10,  # Change based on your resolution\n",
    "    geometryType='polygon',\n",
    "    labelProperty='zone',\n",
    "    reducer=ee.Reducer.countEvery()\n",
    ")\n",
    "farm_vectors = farm_vectors.filter(ee.Filter.eq('zone', 1)).map(lambda x: x.set(\"count\", farm.filterBounds(x.geometry()).size())).filter(ee.Filter.gt('count', 3))\n",
    "#farm = farm.filterBounds(farm_vectors)\n",
    "\n",
    "label_image = ee.Image(0).rename(\"label\")\n",
    "farm_mask = label_image.clip(farm).mask()\n",
    "scrubland_mask = label_image.clip(scrubland).mask()\n",
    "plantation_mask = label_image.clip(plantation).mask()\n",
    "\n",
    "label_image = label_image.where(farm_mask, mapping[\"farm\"]).where(scrubland_mask, mapping[\"scrubland\"]).where(plantation_mask, mapping[\"plantation\"])\n",
    "ts_data = ee.Image(\"projects/ee-raman/assets/ts_data_\" + directory)\n",
    "\n",
    "# Classes to sample (exclude background = 0)\n",
    "class_values = [(1,20000), (2,20000), (3,20000)]\n",
    "\n",
    "# Empty list to store samples\n",
    "samples_list = []\n",
    "\n",
    "for class_val, points in class_values:\n",
    "    # Create a mask for the class\n",
    "    class_mask = label_image.eq(class_val)\n",
    "    \n",
    "    # Mask the ts_image to only include pixels of this class\n",
    "    masked_ts = ts_data.updateMask(class_mask)\n",
    "    \n",
    "    # Sample uniformly from the masked image\n",
    "    class_samples = masked_ts.addBands(label_image.rename('class')) \\\n",
    "        .stratifiedSample(\n",
    "            numPoints=points,  # adjust as needed\n",
    "            classBand='class',\n",
    "            classValues=[class_val],\n",
    "            classPoints=[points],  # adjust per class\n",
    "            scale=10,\n",
    "            region=ts_data.geometry(),\n",
    "            seed=42,\n",
    "            geometries=True\n",
    "        )\n",
    "    \n",
    "    samples_list.append(class_samples)\n",
    "\n",
    "all_samples = samples_list[0].merge(samples_list[1]).merge(samples_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ee.Classifier.smileRandomForest(50).train(\n",
    "    features=all_samples,\n",
    "    classProperty='class',\n",
    "    inputProperties=ts_data.bandNames()\n",
    ")\n",
    "classified = ts_data.classify(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_mode_label(feature):\n",
    "    class_values = classified.reduceRegion(\n",
    "        reducer=ee.Reducer.mode(),\n",
    "        geometry=feature.geometry(),\n",
    "        scale=30,  # Adjust scale as per resolution\n",
    "        bestEffort=True\n",
    "    )\n",
    "    return feature.set('class', class_values.get('classification'))\n",
    "\n",
    "# Apply function to test features\n",
    "all_labels = all.map(assign_mode_label).filter(ee.Filter.notNull(['class']))\n",
    "all_labels = all_labels.map(lambda x: x.set('class', reversed_ee_mapping.get(ee.Number(x.get(\"class\")).int())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ee.batch.Export.table.toAsset(\n",
    "    collection=all_labels,\n",
    "    description='Classification',\n",
    "    assetId=\"projects/ee-raman/assets/\" + directory + \"_boundaries_refined\"\n",
    ")\n",
    "\n",
    "# Start the task\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f23d3fabe04a82a2afd3c2855057a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[0, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=SearchDataGUI(childrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geemap\n",
    "\n",
    "\n",
    "\n",
    "final_lulc_img = ee.Image(\"projects/ee-raman/assets/Area_Peddapally_v4\")\n",
    "#final_lulc_img_corrected = ee.Image(\"projects/ee-raman/assets/\" + filename_prefix + \"_corrected_slide\")\n",
    "#all = get_feature_collection(\"projects/ee-raman/assets/all_\" + suffix)\n",
    "#farm = all.filter(ee.Filter.eq(\"class\", \"farm\"))\n",
    "#scrubland = all.filter(ee.Filter.eq(\"class\", \"scrubland\"))\n",
    "#plantation = all.filter(ee.Filter.eq(\"class\", \"plantation\"))\n",
    "\n",
    "m = geemap.Map()\n",
    "m.centerObject(roi_boundary)\n",
    "\n",
    "\n",
    "url = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}'\n",
    "m.layout.height = '1000px'\n",
    "m.add_tile_layer(url, name=\"Google Map\", attribution=\"Google\")\n",
    "#m.add_basemap(, )\n",
    "m.addLayerControl()\n",
    "#m.addLayer(fields_boundary, {}, 'Fields')\n",
    "\n",
    "palette = [\n",
    "    '303000', '000000', '000000', '000000', '000000', 'f75cff', \n",
    "    '991695', 'e6ab2c', '3bef34', '2baa25', 'e6ef34', 'a1a524', 'eea15e'\n",
    "]\n",
    "\n",
    "palette_corrected = [\n",
    "    '303000', '000000', '000000', '000000', '000000', 'f75cff', \n",
    "    '991695', 'e6ab2c', '3bef34', '2baa25', 'e6ef34', 'a1a524', 'eea15e', '29554E'\n",
    "]\n",
    "\n",
    "vis_params = {\n",
    "    'min': 0,\n",
    "    'max': 12,\n",
    "    'palette': palette\n",
    "}\n",
    "\n",
    "vis_params_corrected = {\n",
    "    'min': 0,\n",
    "    'max': 13,\n",
    "    'palette': palette_corrected\n",
    "}\n",
    "\n",
    "labels = \"\"\"0. Background\n",
    "1. Built-up\n",
    "2. Water (Kharif)\n",
    "3. Water (Kharif + Rabi)\n",
    "4. Water (Kharif + Rabi + Zaid)\n",
    "5. Croplands\n",
    "6. Tree/Forest\n",
    "7. Barren Land\n",
    "8. Single Kharif (Light blue)\n",
    "9. Single Non-Kharif\n",
    "10. Double (Dark-Blue)\n",
    "11. Triple\n",
    "12. Shrub_Scrub\n",
    "13. Plantation\"\"\"\n",
    "labels = [i.split(\". \")[-1] for i in labels.split(\"\\n\")]\n",
    "\n",
    "palette_ = ['3bef34', '991695', '0000FF']\n",
    "vis_params_ = {\n",
    "    'min': 1,\n",
    "    'max': 3,\n",
    "    'palette': palette_\n",
    "}\n",
    "\n",
    "\n",
    "m.addLayer(final_lulc_img.select(\"predicted_label\"), vis_params, 'LULC')\n",
    "#m.addLayer(final_lulc_img_corrected.select(\"predicted_label\"), vis_params_corrected, 'LULC_corrected')\n",
    "#m.addLayer(classified, vis_params_, 'predictions')\n",
    "\n",
    "m.add_legend(keys=labels, colors=palette_corrected, position=\"bottomleft\")\n",
    "#m.addLayer(classified.select(\"classification\"), vis_params_, \"rest_with_labels\" )\n",
    "m.addLayer(farm_vectors, {}, 'farm_vectors')\n",
    "m.addLayer(farm, {}, 'farm')\n",
    "\n",
    "m.addLayer(scrubland, {}, 'scrubland')\n",
    "m.addLayer(all, {}, 'all')\n",
    "m.addLayer(plantation.map(lambda x: x.set(\"area\", x.geometry().area())).filter(ee.Filter.lt(\"area\", 20000)).filter(ee.Filter.gt(\"area\", 1000)), {}, 'plantation')\n",
    "#m.addLayer(rest, {}, 'rest')\n",
    "#m.addLayer(rest_all.filter(ee.Filter.eq(\"predicted_class\", 0)), {}, 'predicted_farm')\n",
    "#m.addLayer(rest_all.filter(ee.Filter.eq(\"predicted_class\", 1)), {}, 'predicted_scrubland')\n",
    "#m.addLayer(rest_all.filter(ee.Filter.eq(\"predicted_class\", 2)), {}, 'predicted_plantation')\n",
    "#m.addLayer(aatif_plantation, {}, 'aatif_plantation')\n",
    "\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Area_bheramgarh\"\n",
    "directory = \"Area_jamkhed\"\n",
    "directory = \"Area_peddapally\"\n",
    "\n",
    "suffix = directory.split(\"_\")[-1]\n",
    "mapping = {\n",
    "    \"farm\": 1,\n",
    "    \"plantation\": 2,\n",
    "    \"scrubland\": 3,\n",
    "    \"rest\": 0\n",
    "}\n",
    "reversed_mapping = {v: k for k, v in mapping.items()}\n",
    "reversed_ee_mapping = ee.Dictionary(reversed_mapping)\n",
    "\n",
    "def get_class_and_mapping(vectors, vector_name):\n",
    "    vector_of_class = vectors.filter(ee.Filter.eq('class', vector_name))\n",
    "    vector_of_class_with_map = vector_of_class.map(lambda f: f.set('class', mapping[vector_name]))\n",
    "    return vector_of_class, vector_of_class_with_map\n",
    "\n",
    "all = get_feature_collection(\"projects/ee-raman/assets/\" + directory + \"_boundaries\")\n",
    "farm, farm_with_map = get_class_and_mapping(all, \"farm\")\n",
    "scrubland, scrubland_with_map = get_class_and_mapping(all, \"scrubland\")\n",
    "plantation, plantation_with_map = get_class_and_mapping(all, \"plantation\")\n",
    "rest, rest_with_map = get_class_and_mapping(all, \"rest\")\n",
    "\n",
    "plantation = plantation.map(lambda x: x.set(\"area\", x.geometry().area())).filter(ee.Filter.lt(\"area\", 20000)).filter(ee.Filter.gt(\"area\", 1000))\n",
    "\n",
    "label_image = ee.Image(0).rename(\"label\")\n",
    "farm_mask = label_image.clip(farm).mask()\n",
    "scrubland_mask = label_image.clip(scrubland).mask()\n",
    "plantation_mask = label_image.clip(plantation).mask()\n",
    "\n",
    "label_image = label_image.where(farm_mask, mapping[\"farm\"]).where(scrubland_mask, mapping[\"scrubland\"]).where(plantation_mask, mapping[\"plantation\"])\n",
    "ts_data = ee.Image(\"projects/ee-raman/assets/ts_data_\" + directory)\n",
    "\n",
    "# Classes to sample (exclude background = 0)\n",
    "class_values = [(1,20000), (2,20000), (3,20000)]\n",
    "\n",
    "# Empty list to store samples\n",
    "samples_list = []\n",
    "\n",
    "for class_val, points in class_values:\n",
    "    # Create a mask for the class\n",
    "    class_mask = label_image.eq(class_val)\n",
    "    \n",
    "    # Mask the ts_image to only include pixels of this class\n",
    "    masked_ts = ts_data.updateMask(class_mask)\n",
    "    \n",
    "    # Sample uniformly from the masked image\n",
    "    class_samples = masked_ts.addBands(label_image.rename('class')) \\\n",
    "        .stratifiedSample(\n",
    "            numPoints=points,  # adjust as needed\n",
    "            classBand='class',\n",
    "            classValues=[class_val],\n",
    "            classPoints=[points],  # adjust per class\n",
    "            scale=10,\n",
    "            region=ts_data.geometry(),\n",
    "            seed=42,\n",
    "            geometries=True\n",
    "        )\n",
    "    \n",
    "    samples_list.append(class_samples)\n",
    "\n",
    "all_samples = samples_list[0].merge(samples_list[1]).merge(samples_list[2])\n",
    "\n",
    "#training_features = farm_with_map.merge(scrubland_with_map).merge(plantation_with_map)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
