{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7digTEkiZde"
   },
   "source": [
    "# SET CODING ENVIRONMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUH7mzH2jAnM"
   },
   "source": [
    "## Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pb6YaMr9jLPK"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import ee\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import folium\n",
    "from folium import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBg2jArDvSv3"
   },
   "source": [
    "## Authenticate to Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GXSXdKfivbFF"
   },
   "outputs": [],
   "source": [
    "ee.Authenticate() #Uncomment this whenever needed, once done usually not needed for 1-2 days\n",
    "ee.Initialize(project='ee-raman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hy5lznlZjlV3"
   },
   "source": [
    "# FUNCTION DEFINITIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_from_collection(collec, ind):\n",
    "    \"\"\"\n",
    "    Sometimes directly getting ith feature form collection doesn't work\n",
    "    This hack works all the time. Converting collection to list and getting\n",
    "    ith element and re-casting it as feature.\n",
    "    \"\"\"\n",
    "    return ee.Feature(collec.toList(collec.size().getInfo()).get(ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plTjnOW5uXu_"
   },
   "source": [
    "## Common Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OazSndJbuZ4o"
   },
   "outputs": [],
   "source": [
    "def displayMap(roi_boundary, image):\n",
    "  centroid = roi_boundary.geometry().centroid()\n",
    "  coordinates = centroid.coordinates()\n",
    "  centerLat = coordinates.get(1).getInfo()\n",
    "  centerLon = coordinates.get(0).getInfo()\n",
    "  mapObj = folium.Map(width='100%', height='80%', location=[centerLat, centerLon], zoom_start=50)\n",
    "\n",
    "  # Sattelite image visual parameters\n",
    "  vis_params = {\n",
    "    'min': 0,\n",
    "    'max': 12,\n",
    "    'palette': ['#000000',  # 0 Black- background\n",
    "              '#ff0000',   # 1 Red- builtup\n",
    "              '#74ccf4', # 2 Light Blue- kharif water\n",
    "              '#1ca3ec', # 3 Blue- kharif and rabi water\n",
    "              '#0f5e9c', # 4 Dark Blue- kharif and rabi and zaid water\n",
    "              '#f1c232', # 5 Yellow- croplands\n",
    "              '#38761d', # 6 Dark Green- Tree/Forests\n",
    "              '#A9A9A9', # 7 Gray- barren lands\n",
    "              '#f1c232', # 8 Yellow- Single Kharif Cropping\n",
    "              '#f59d22', # 9 Mustard- Single Non-Kharif Cropping\n",
    "              '#e68600', # 10 Orange- Double Cropping\n",
    "              '#b3561d', # 11 Brown- Triple Cropping\n",
    "              '#c39797' # 12 Mauve- Shrubs_Scrubs\n",
    "            ]\n",
    "    }\n",
    "\n",
    "  map_id_dict = ee.Image(image).getMapId(vis_params)\n",
    "\n",
    "  folium.TileLayer(\n",
    "          tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "          attr='Esri',\n",
    "          name='Esri Satellite',\n",
    "          overlay=True,\n",
    "          control=True\n",
    "      ).add_to(mapObj)\n",
    "\n",
    "  folium.raster_layers.TileLayer(\n",
    "                  tiles = map_id_dict['tile_fetcher'].url_format,\n",
    "                  attr = 'Google Earth Engine',\n",
    "                  name = 'Sentinel 2 image',\n",
    "                  overlay = True,\n",
    "                  control = True\n",
    "                  ).add_to(mapObj)\n",
    "\n",
    "  mapObj.add_child(folium.LayerControl())\n",
    "  display(mapObj)\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask clouds based on the QA60 band of Sentinel SR data.\n",
    "param {ee.Image} image Input Sentinel SR image\n",
    "return {ee.Image} Cloudmasked Sentinel-2 image\n",
    "'''\n",
    "def maskS2cloud(image):\n",
    "  qa = image.select('QA60')\n",
    "  #Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "  cloudBitMask = 1 << 10\n",
    "  cirrusBitMask = 1 << 11\n",
    "  #Both flags should be set to zero, indicating clear conditions.\n",
    "  mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "  return image.updateMask(mask).divide(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRPh2Zb1mNWN"
   },
   "source": [
    "## Cropping Frequency Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NFJUUM48mudS"
   },
   "outputs": [],
   "source": [
    "chastainBandNames = ['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2']\n",
    "\n",
    "# Regression model parameters from Table-4. MSI TOA reflectance as a function of OLI TOA reflectance.\n",
    "msiOLISlopes = [1.0946,1.0043,1.0524,0.8954,1.0049,1.0002]\n",
    "msiOLIIntercepts = [-0.0107,0.0026,-0.0015,0.0033,0.0065,0.0046]\n",
    "\n",
    "# Regression model parameters from Table-5. MSI TOA reflectance as a function of ETM+ TOA reflectance.\n",
    "msiETMSlopes = [1.10601,0.99091,1.05681,1.0045,1.03611,1.04011]\n",
    "msiETMIntercepts = [-0.0139,0.00411,-0.0024,-0.0076,0.00411,0.00861]\n",
    "\n",
    "# Regression model parameters from Table-6. OLI TOA reflectance as a function of ETM+ TOA reflectance.\n",
    "oliETMSlopes =[1.03501,1.00921,1.01991,1.14061,1.04351,1.05271];\n",
    "oliETMIntercepts = [-0.0055,-0.0008,-0.0021,-0.0163,-0.0045,0.00261]\n",
    "\n",
    "# Construct dictionary to handle all pairwise combos\n",
    "chastainCoeffDict = { 'MSI_OLI':[msiOLISlopes,msiOLIIntercepts,1], # check what the third item corresponds to\n",
    "                      'MSI_ETM':[msiETMSlopes,msiETMIntercepts,1],\n",
    "                      'OLI_ETM':[oliETMSlopes,oliETMIntercepts,1],\n",
    "                      'OLI_MSI':[msiOLISlopes,msiOLIIntercepts,0],\n",
    "                      'ETM_MSI':[msiETMSlopes,msiETMIntercepts,0],\n",
    "                      'ETM_OLI':[oliETMSlopes,oliETMIntercepts,0]\n",
    "                    }\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask cloudy pixels in Landsat-7\n",
    "'''\n",
    "def maskL7cloud(image):\n",
    "  qa = image.select('QA_PIXEL')\n",
    "  mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "  return image.updateMask(mask).select(['B1', 'B2', 'B3' , 'B4' , 'B5' , 'B7']).rename('BLUE', 'GREEN', 'RED' , 'NIR' , 'SWIR1' , 'SWIR2')\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask cloudy pixels in Landsat-8\n",
    "'''\n",
    "def maskL8cloud(image):\n",
    "  qa = image.select('QA_PIXEL')\n",
    "  mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "  return image.updateMask(mask).select(['B2', 'B3', 'B4' , 'B5' , 'B6' , 'B7']).rename('BLUE', 'GREEN', 'RED' , 'NIR' , 'SWIR1' , 'SWIR2')\n",
    "\n",
    "\n",
    "'''\n",
    "Function to mask clouds using the quality band of Sentinel-2 TOA\n",
    "'''\n",
    "def maskS2cloudTOA(image):\n",
    "  qa = image.select('QA60')\n",
    "  # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "  cloudBitMask = 1 << 10\n",
    "  cirrusBitMask = 1 << 11\n",
    "  # Both flags should be set to zero, indicating clear conditions.\n",
    "  mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0));\n",
    "  return image.updateMask(mask).select(['B2', 'B3', 'B4', 'B8',  'B11', 'B12']).rename(['BLUE', 'GREEN', 'RED', 'NIR', 'SWIR1', 'SWIR2'])\n",
    "\n",
    "\n",
    "'''\n",
    "Get Landsat and Sentinel image collections\n",
    "'''\n",
    "def Get_L7_L8_S2_ImageCollections(inputStartDate, inputEndDate, roi_boundary):\n",
    "  # ------ Landsat 7 TOA\n",
    "  L7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_TOA') \\\n",
    "          .filterDate(inputStartDate, inputEndDate) \\\n",
    "          .filterBounds(roi_boundary) \\\n",
    "          .map(maskL7cloud)\n",
    "  # print('\\n Original Landsat 7 TOA dataset: \\n',L7.limit(1).getInfo())\n",
    "  # print('Number of images in Landsat 7 TOA dataset: \\t',L7.size().getInfo())\n",
    "\n",
    "  # ------ Landsat 8 TOA\n",
    "  L8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA') \\\n",
    "          .filterDate(inputStartDate, inputEndDate) \\\n",
    "          .filterBounds(roi_boundary) \\\n",
    "          .map(maskL8cloud)\n",
    "  # print('\\n Original Landsat 8 TOA dataset: \\n', L8.limit(1).getInfo())\n",
    "  # print('Number of images in Landsat 8 TOA dataset: \\t',L8.size().getInfo())\n",
    "\n",
    "  # ------ Sentinel-2 TOA\n",
    "  S2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
    "          .filterDate(inputStartDate, inputEndDate) \\\n",
    "          .filterBounds(roi_boundary)  \\\n",
    "          .map(maskS2cloudTOA)\n",
    "  # print('\\n Original Sentinel-2 TOA dataset: \\n',S2.limit(1).getInfo())\n",
    "  # print('Number of images in Sentinel 2 TOA dataset: \\t',S2.size().getInfo())\n",
    "\n",
    "  return L7, L8, S2\n",
    "\n",
    "\n",
    "'''\n",
    "Function to apply model in one direction\n",
    "'''\n",
    "def dir0Regression(img,slopes,intercepts):\n",
    "  return img.select(chastainBandNames).multiply(slopes).add(intercepts)\n",
    "\n",
    "\n",
    "'''\n",
    "Applying the model in the opposite direction\n",
    "'''\n",
    "def dir1Regression(img,slopes,intercepts):\n",
    "  return img.select(chastainBandNames).subtract(intercepts).divide(slopes)\n",
    "\n",
    "\n",
    "'''\n",
    "Function to correct one sensor to another\n",
    "'''\n",
    "def harmonizationChastain(img, fromSensor,toSensor):\n",
    "  # Get the model for the given from and to sensor\n",
    "  comboKey = fromSensor.upper() + '_' + toSensor.upper()\n",
    "  coeffList = chastainCoeffDict[comboKey]\n",
    "  slopes = coeffList[0]\n",
    "  intercepts = coeffList[1]\n",
    "  direction = ee.Number(coeffList[2])\n",
    "\n",
    "  # Apply the model in the respective direction\n",
    "  out = ee.Algorithms.If(direction.eq(0),dir0Regression(img,slopes,intercepts),dir1Regression(img,slopes,intercepts))\n",
    "  return ee.Image(out).copyProperties(img).copyProperties(img,['system:time_start'])\n",
    "\n",
    "\n",
    "'''\n",
    "Calibrate Landsat-8 (OLI) and Sentinel-2 (MSI) to Landsat-7 (ETM+)\n",
    "'''\n",
    "def Harmonize_L7_L8_S2(L7, L8, S2):\n",
    "  # harmonization\n",
    "  harmonized_L8 = L8.map( lambda img: harmonizationChastain(img, 'OLI','ETM') )\n",
    "  harmonized_S2 = S2.map( lambda img: harmonizationChastain(img, 'MSI','ETM') )\n",
    "\n",
    "  # Merge harmonized landsat-8 and sentinel-2 to landsat-7 image collection\n",
    "  harmonized_LandsatSentinel_ic = ee.ImageCollection(L7.merge(harmonized_L8).merge(harmonized_S2))\n",
    "  # print(harmonized_LandsatSentinel_ic.size().getInfo())\n",
    "  return harmonized_LandsatSentinel_ic\n",
    "\n",
    "\n",
    "'''\n",
    "Add NDVI band to harmonized image collection\n",
    "'''\n",
    "def addNDVI(image):\n",
    "  return image.addBands(image.normalizedDifference(['NIR', 'RED']).rename('NDVI')).float()\n",
    "\n",
    "\n",
    "'''\n",
    "Function definitions to get NDVI values at each 16-day composites\n",
    "'''\n",
    "def Get_NDVI_image_datewise(harmonized_LS_ic):\n",
    "  def get_NDVI_datewise(date):\n",
    "    return harmonized_LS_ic.select(['NDVI']) \\\n",
    "                            .filterDate(ee.Date(date), ee.Date(date).advance(16, 'day')) \\\n",
    "                            .median() \\\n",
    "                            .set('system:time_start',ee.Date(date).millis())\n",
    "  return get_NDVI_datewise\n",
    "\n",
    "def Get_LS_16Day_NDVI_TimeSeries(inputStartDate, inputEndDate, harmonized_LS_ic):\n",
    "  startDate = datetime.strptime(inputStartDate,\"%Y-%m-%d\")\n",
    "  endDate = datetime.strptime(inputEndDate,\"%Y-%m-%d\")\n",
    "\n",
    "  date_list = pd.date_range(start=startDate, end=endDate, freq='16D').tolist()\n",
    "  date_list = ee.List( [datetime.strftime(curr_date,\"%Y-%m-%d\") for curr_date in date_list] )\n",
    "\n",
    "  LSC =  ee.ImageCollection.fromImages(date_list.map(Get_NDVI_image_datewise(harmonized_LS_ic)))\n",
    "\n",
    "  return LSC\n",
    "\n",
    "\n",
    "'''\n",
    "Pair available LSC and modis values for each time stamp.\n",
    "'''\n",
    "def pairLSModis(lsRenameBands):\n",
    "  def pair(feature):\n",
    "    date = ee.Date( feature.get('system:time_start') )\n",
    "    startDateT = date.advance(-8,'day')\n",
    "    endDateT = date.advance(8,'day')\n",
    "\n",
    "    # ------ MODIS VI ( We can add EVI to the band list later )\n",
    "    modis = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
    "              .filterDate(startDateT, endDateT) \\\n",
    "              .select(['NDVI','SummaryQA']) \\\n",
    "              .filterBounds(roi_boundary) \\\n",
    "              .median() \\\n",
    "              .rename(['NDVI_modis', 'SummaryQA_modis'])\n",
    "\n",
    "    return feature.rename(lsRenameBands).addBands(modis)\n",
    "  return pair\n",
    "\n",
    "\n",
    "'''\n",
    "Function to get Pearson Correlation Coffecient to perform GapFilling\n",
    "'''\n",
    "def get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, bandList):\n",
    "  corr = LSC_modis_paired_ic.filterBounds(roi_boundary) \\\n",
    "                            .select(bandList).toArray() \\\n",
    "                            .arrayReduce( reducer = ee.Reducer.pearsonsCorrelation(), axes=[0], fieldAxis=1 ) \\\n",
    "                            .arrayProject([1]).arrayFlatten([['c', 'p']])\n",
    "  return corr\n",
    "\n",
    "\n",
    "'''Use print(...) to write to this console.\n",
    "Fill gaps in LSC timeseries using modis data\n",
    "'''\n",
    "def gapfillLSM(LSC_modis_regression_model, LSC_bandName, modis_bandName):\n",
    "  def peformGapfilling(image):\n",
    "    offset = LSC_modis_regression_model.select('offset')\n",
    "    scale = LSC_modis_regression_model.select('scale')\n",
    "    nodata = -1\n",
    "\n",
    "    lsc_image = image.select(LSC_bandName)\n",
    "    modisfit = image.select(modis_bandName).multiply(scale).add(offset)\n",
    "\n",
    "    mask = lsc_image.mask()#update mask needs an input (no default input from the API document)\n",
    "    gapfill = lsc_image.unmask(nodata)\n",
    "    gapfill = gapfill.where(mask.Not(), modisfit)\n",
    "\n",
    "    '''\n",
    "    in SummaryQA,\n",
    "    0: Good data, use with confidence\n",
    "    1: Marginal data, useful but look at detailed QA for more information\n",
    "    2: Pixel covered with snow/ice\n",
    "    3: Pixel is cloudy\n",
    "    '''\n",
    "    qc_m = image.select('SummaryQA_modis').unmask(3)  # missing value is grouped as cloud\n",
    "    w_m  = modisfit.mask().rename('w_m').where(qc_m.eq(0), 0.8)  # default is 0.8\n",
    "    w_m = w_m.where(qc_m.eq(1), 0.5)   # Marginal\n",
    "    w_m = w_m.where(qc_m.gte(2), 0.2) # snow/ice or cloudy\n",
    "\n",
    "    # make sure these modis values are read where there is missing data from LandSat, Sentinel\n",
    "    w_l = gapfill.mask() # default is 1\n",
    "    w_l = w_l.where(mask.Not(), w_m)\n",
    "\n",
    "    return gapfill.addBands(w_l).rename(['gapfilled_'+LSC_bandName,'SummaryQA']) #have NDVI from modis and a summary of clarity for each\n",
    "\n",
    "  return peformGapfilling\n",
    "\n",
    "\n",
    "'''\n",
    "Function to combine LSC with Modis data\n",
    "'''\n",
    "def Combine_LS_Modis(LSC):\n",
    "  lsRenameBands = ee.Image(LSC.first()).bandNames().map( lambda band: ee.String(band).cat('_lsc') )\n",
    "  LSC_modis_paired_ic = LSC.map( pairLSModis(lsRenameBands) )\n",
    "\n",
    "  # Output contains scale, offset i.e. two bands\n",
    "  LSC_modis_regression_model_NDVI = LSC_modis_paired_ic.select(['NDVI_modis', 'NDVI_lsc']) \\\n",
    "                                                        .reduce(ee.Reducer.linearFit())\n",
    "\n",
    "  corr_NDVI = get_Pearson_Correlation_Coefficients(LSC_modis_paired_ic, roi_boundary, ['NDVI_modis', 'NDVI_lsc'])\n",
    "  LSMC_NDVI = LSC_modis_paired_ic.map(gapfillLSM(LSC_modis_regression_model_NDVI, 'NDVI_lsc', 'NDVI_modis'))\n",
    "\n",
    "  return LSMC_NDVI\n",
    "\n",
    "\n",
    "'''\n",
    "Mask out low quality pixels\n",
    "'''\n",
    "def mask_low_QA(lsmc_image):\n",
    "  low_qa = lsmc_image.select('SummaryQA').neq(0.2)\n",
    "  return lsmc_image.updateMask(low_qa).copyProperties(lsmc_image, ['system:time_start'])\n",
    "\n",
    "\n",
    "'''\n",
    "Add image timestamp to each image in time series\n",
    "'''\n",
    "def add_timestamp(image):\n",
    "  timeImage = image.metadata('system:time_start').rename('timestamp')\n",
    "  timeImageMasked = timeImage.updateMask(image.mask().select(0))\n",
    "  return image.addBands(timeImageMasked)\n",
    "\n",
    "\n",
    "'''\n",
    "Perform linear interpolation on missing values\n",
    "'''\n",
    "def performInterpolation(image):\n",
    "  image = ee.Image(image)\n",
    "  beforeImages = ee.List(image.get('before'))\n",
    "  beforeMosaic = ee.ImageCollection.fromImages(beforeImages).mosaic()\n",
    "  afterImages = ee.List(image.get('after'))\n",
    "  afterMosaic = ee.ImageCollection.fromImages(afterImages).mosaic()\n",
    "\n",
    "  # Interpolation formula\n",
    "  # y = y1 + (y2-y1)*((t – t1) / (t2 – t1))\n",
    "  # y = interpolated image\n",
    "  # y1 = before image\n",
    "  # y2 = after image\n",
    "  # t = interpolation timestamp\n",
    "  # t1 = before image timestamp\n",
    "  # t2 = after image timestamp\n",
    "\n",
    "  t1 = beforeMosaic.select('timestamp').rename('t1')\n",
    "  t2 = afterMosaic.select('timestamp').rename('t2')\n",
    "  t = image.metadata('system:time_start').rename('t')\n",
    "  timeImage = ee.Image.cat([t1, t2, t])\n",
    "  timeRatio = timeImage.expression('(t - t1) / (t2 - t1)', {\n",
    "                  't': timeImage.select('t'),\n",
    "                  't1': timeImage.select('t1'),\n",
    "                  't2': timeImage.select('t2'),\n",
    "              })\n",
    "\n",
    "  interpolated = beforeMosaic.add((afterMosaic.subtract(beforeMosaic).multiply(timeRatio)))\n",
    "  result = image.unmask(interpolated)\n",
    "  fill_value = ee.ImageCollection([beforeMosaic, afterMosaic]).mosaic()\n",
    "  result = result.unmask(fill_value)\n",
    "\n",
    "  return result.copyProperties(image, ['system:time_start'])\n",
    "\n",
    "\n",
    "def interpolate_timeseries(S1_TS):\n",
    "  lsmc_masked = S1_TS.map(mask_low_QA)\n",
    "  filtered = lsmc_masked.map(add_timestamp)\n",
    "\n",
    "  # Time window in which we are willing to look forward and backward for unmasked pixel in time series\n",
    "  timeWindow = 120\n",
    "\n",
    "  # Define a maxDifference filter to find all images within the specified days. Convert days to milliseconds.\n",
    "  millis = ee.Number(timeWindow).multiply(1000*60*60*24)\n",
    "  # Filter says that pick only those timestamps which lie between the 2 timestamps not more than millis difference apart\n",
    "  maxDiffFilter = ee.Filter.maxDifference(\n",
    "                              difference = millis,\n",
    "                              leftField = 'system:time_start',\n",
    "                              rightField = 'system:time_start',\n",
    "                            )\n",
    "\n",
    "  # Filter to find all images after a given image. Compare the image's timstamp against other images.\n",
    "  # Images ahead of target image should have higher timestamp.\n",
    "  lessEqFilter = ee.Filter.lessThanOrEquals(\n",
    "                            leftField = 'system:time_start',\n",
    "                            rightField = 'system:time_start'\n",
    "                          )\n",
    "\n",
    "  # Similarly define this filter to find all images before a given image\n",
    "  greaterEqFilter = ee.Filter.greaterThanOrEquals(\n",
    "                            leftField = 'system:time_start',\n",
    "                            rightField = 'system:time_start'\n",
    "                          )\n",
    "\n",
    "  # Apply first join to find all images that are after the target image but within the timeWindow\n",
    "  filter1 = ee.Filter.And( maxDiffFilter, lessEqFilter )\n",
    "  join1 = ee.Join.saveAll(\n",
    "                  matchesKey = 'after',\n",
    "                  ordering = 'system:time_start',\n",
    "                  ascending = False\n",
    "          )\n",
    "  join1Result = join1.apply(\n",
    "                  primary = filtered,\n",
    "                  secondary = filtered,\n",
    "                  condition = filter1\n",
    "                )\n",
    "\n",
    "  # Apply first join to find all images that are after the target image but within the timeWindow\n",
    "  filter2 = ee.Filter.And( maxDiffFilter, greaterEqFilter )\n",
    "  join2 = ee.Join.saveAll(\n",
    "                  matchesKey = 'before',\n",
    "                  ordering = 'system:time_start',\n",
    "                  ascending = True\n",
    "          )\n",
    "  join2Result = join2.apply(\n",
    "                  primary = join1Result,\n",
    "                  secondary = join1Result,\n",
    "                  condition = filter2\n",
    "                )\n",
    "\n",
    "  interpolated_S1_TS = ee.ImageCollection(join2Result.map(performInterpolation))\n",
    "\n",
    "  return interpolated_S1_TS\n",
    "\n",
    "\n",
    "'''\n",
    "Function Definition to get Padded NDVI LSMC timeseries image for a given ROI\n",
    "'''\n",
    "def Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary):\n",
    "  L7, L8, S2 = Get_L7_L8_S2_ImageCollections(startDate, endDate, roi_boundary)\n",
    "\n",
    "  harmonized_LS_ic = Harmonize_L7_L8_S2(L7, L8, S2)\n",
    "  harmonized_LS_ic = harmonized_LS_ic.map(addNDVI)\n",
    "  LSC = Get_LS_16Day_NDVI_TimeSeries(startDate, endDate, harmonized_LS_ic)\n",
    "  LSMC_NDVI = Combine_LS_Modis(LSC)\n",
    "  Interpolated_LSMC_NDVI = interpolate_timeseries(LSMC_NDVI)\n",
    "  final_LSMC_NDVI_TS = Interpolated_LSMC_NDVI.select(['gapfilled_NDVI_lsc']).toBands()\n",
    "  final_LSMC_NDVI_TS = final_LSMC_NDVI_TS.clip(roi_boundary)\n",
    "  return final_LSMC_NDVI_TS\n",
    "\n",
    "def get_cropping_frequency(roi_boundary, startDate, endDate):\n",
    "  final_LSMC_NDVI_TS =  Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary)\n",
    "  return final_LSMC_NDVI_TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zLWDWcKm4AH"
   },
   "source": [
    "# MAIN FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYIr6onzgE1x"
   },
   "source": [
    "## Take user input on ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of the Rectangle is  23.070494296156163\n"
     ]
    }
   ],
   "source": [
    "top_left = [10.62060477, 77.87217496]  # Replace lon1 and lat1 with actual values\n",
    "bottom_right = [10.57740888, 77.91612074]  # Replace lon2 and lat2 with actual values\n",
    "\n",
    "# Create a rectangle geometry using the defined corners\n",
    "rectangle = ee.Geometry.Rectangle([top_left[1], bottom_right[0], bottom_right[1], top_left[0]])\n",
    "print(\"Area of the Rectangle is \", rectangle.area().getInfo()/1e6)\n",
    "# Create a feature collection with the rectangle as a boundary\n",
    "roi_boundary = ee.FeatureCollection([ee.Feature(rectangle)])\n",
    "directory = 'Area_testing_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of the Rectangle is  41.89448898377194\n"
     ]
    }
   ],
   "source": [
    "top_left = [20.56149133, 73.56330458]  # Replace lon1 and lat1 with actual values\n",
    "bottom_right = [20.47917109, 73.60725362]  # Replace lon2 and lat2 with actual values\n",
    "\n",
    "# Create a rectangle geometry using the defined corners\n",
    "rectangle = ee.Geometry.Rectangle([top_left[1], bottom_right[0], bottom_right[1], top_left[0]])\n",
    "print(\"Area of the Rectangle is \", rectangle.area().getInfo()/1e6)\n",
    "# Create a feature collection with the rectangle as a boundary\n",
    "roi_boundary = ee.FeatureCollection([ee.Feature(rectangle)])\n",
    "directory = 'Area_surgana'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of the Rectangle is  9.437397485806445\n"
     ]
    }
   ],
   "source": [
    "top_left = [19.26903317, 80.86453702]  # Replace lon1 and lat1 with actual values\n",
    "bottom_right = [19.24167092, 80.89408520]  # Replace lon2 and lat2 with actual values \n",
    "\n",
    "# Create a rectangle geometry using the defined corners\n",
    "rectangle = ee.Geometry.Rectangle([top_left[1], bottom_right[0], bottom_right[1], top_left[0]])\n",
    "print(\"Area of the Rectangle is \", rectangle.area().getInfo()/1e6)\n",
    "# Create a feature collection with the rectangle as a boundary\n",
    "roi_boundary = ee.FeatureCollection([ee.Feature(rectangle)])\n",
    "directory = 'Area_forested'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of the Rectangle is  9.437397485806445\n"
     ]
    }
   ],
   "source": [
    "top_left = [19.26903317, 80.86453702]  # Replace lon1 and lat1 with actual values\n",
    "bottom_right = [19.24167092, 80.89408520]  # Replace lon2 and lat2 with actual values  \n",
    "# Create a rectangle geometry using the defined corners\n",
    "rectangle = ee.Geometry.Rectangle([top_left[1], bottom_right[0], bottom_right[1], top_left[0]])\n",
    "print(\"Area of the Rectangle is \", rectangle.area().getInfo()/1e6)\n",
    "# Create a feature collection with the rectangle as a boundary\n",
    "roi_boundary = ee.FeatureCollection([ee.Feature(rectangle)])\n",
    "\n",
    "directory = 'Area_plantation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_boundary = ee.FeatureCollection(\"users/mtpictd/india_block_boundaries\").filter(ee.Filter.eq(\"block\", \"Bheramgarh\"))\n",
    "directory = \"Area_bheramgarh\"\n",
    "roi_boundary = ee.FeatureCollection(\"users/mtpictd/india_block_boundaries\").filter(ee.Filter.eq(\"block\", \"Jamkhed\"))\n",
    "directory = \"Area_jamkhed\"\n",
    "roi = ee.FeatureCollection(\"users/mtpictd/india_block_boundaries\").filter(ee.Filter.eq(\"block\", \"Peddapally\"))\n",
    "directory = \"Area_Peddapally\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Function to convert latitude to pixel Y at a given zoom level\n",
    "def lat_to_pixel_y(lat, zoom):\n",
    "    sin_lat = math.sin(math.radians(lat))\n",
    "    pixel_y = ((0.5 - math.log((1 + sin_lat) / (1 - sin_lat)) / (4 * math.pi)) * (2 ** (zoom + 8)))\n",
    "    return pixel_y\n",
    "\n",
    "# Function to convert longitude to pixel X at a given zoom level\n",
    "def lon_to_pixel_x(lon, zoom):\n",
    "    pixel_x = ((lon + 180) / 360) * (2 ** (zoom + 8))\n",
    "    return pixel_x\n",
    "\n",
    "# Function to convert pixel X to longitude\n",
    "def pixel_x_to_lon(pixel_x, zoom):\n",
    "    lon = (pixel_x / (2 ** (zoom + 8))) * 360 - 180\n",
    "    return lon\n",
    "\n",
    "# Function to convert pixel Y to latitude\n",
    "def pixel_y_to_lat(pixel_y, zoom):\n",
    "    n = math.pi - 2 * math.pi * pixel_y / (2 ** (zoom + 8))\n",
    "    lat = math.degrees(math.atan(math.sinh(n)))\n",
    "    return lat\n",
    "\n",
    "def lat_lon_from_pixel(lat, lon, zoom, scale):\n",
    "    \"\"\"\n",
    "    Given a starting latitude and longitude, calculate the latitude and longitude\n",
    "    of the opposite corner of a 256x256 image at a given zoom level.\n",
    "    \"\"\"\n",
    "    pixel_x = lon_to_pixel_x(lon, zoom)\n",
    "    pixel_y = lat_to_pixel_y(lat, zoom)\n",
    "    \n",
    "    new_lon = pixel_x_to_lon(pixel_x + 256*scale, zoom)\n",
    "    new_lat = pixel_y_to_lat(pixel_y + 256*scale, zoom)\n",
    "\n",
    "    return new_lat, new_lon\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Helper function for dividing an roi into blocks\n",
    "\n",
    "\"\"\"\n",
    "def get_n_boxes(lat, lon, n, zoom, scale):\n",
    "    diagonal_lat_lon = [(lat, lon),]\n",
    "    for i in range(n):\n",
    "        new_lat_lon = lat_lon_from_pixel(lat, lon, zoom, scale)\n",
    "        diagonal_lat_lon.append(new_lat_lon)\n",
    "        lat, lon = new_lat_lon\n",
    "    lats = [i[0] for i in diagonal_lat_lon]\n",
    "    longs = [i[1] for i in diagonal_lat_lon]\n",
    "    return list(product(lats, longs))\n",
    "\n",
    "def get_points(roi, directory):\n",
    "    points_file = Path(directory + \"/status.csv\")\n",
    "    if points_file.is_file():\n",
    "        df = pd.read_csv(directory + \"/status.csv\", index_col=False)\n",
    "        df[\"points\"] = df['points'].apply(ast.literal_eval)\n",
    "        return df\n",
    "    zoom = 17\n",
    "    scale = 16\n",
    "    bounds = roi.bounds().coordinates().get(0).getInfo()\n",
    "    lons = sorted([i[0] for i in bounds])\n",
    "    lats = sorted([i[1] for i in bounds])\n",
    "    starting_point = lats[-1], lons[0]\n",
    "    min_, max_ = (\n",
    "        [lon_to_pixel_x(lons[0], zoom), lat_to_pixel_y(lats[0], zoom) ],\n",
    "        [lon_to_pixel_x(lons[-1], zoom), lat_to_pixel_y(lats[-1], zoom)]\n",
    "        )\n",
    "    iterations = math.ceil(max(abs(min_[0] -  max_[0]), abs(min_[1] - max_[1]))/256/16)\n",
    "    points = get_n_boxes(starting_point[0], starting_point[1], iterations, zoom, scale)\n",
    "    intersect_list = []\n",
    "    print(len(points))\n",
    "    index = 0\n",
    "    for point in points:\n",
    "        top_left = point\n",
    "        bottom_right = lat_lon_from_pixel(top_left[0], top_left[1], zoom, scale)\n",
    "        rectangle = ee.Geometry.Rectangle([(top_left[1], top_left[0]), (bottom_right[1], bottom_right[0])])\n",
    "        print(top_left, bottom_right)\n",
    "        intersects = roi.geometry().intersects(rectangle, ee.ErrorMargin(1)).getInfo()\n",
    "        if intersects:\n",
    "            intersect_list.append((index, (top_left,bottom_right)))\n",
    "            index+=1\n",
    "        print(intersects)\n",
    "    df = pd.DataFrame(intersect_list, columns=[\"index\", \"points\"])\n",
    "    df[\"overall_status\"] = False\n",
    "    df[\"download_status\"] = False\n",
    "    df[\"model_status\"] = False\n",
    "    df[\"segmentation_status\"] = False\n",
    "    df[\"postprocessing_status\"] = False\n",
    "    df[\"plantation_status\"] = False\n",
    "    df.to_csv(directory + \"/status.csv\", index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "blocks_df = get_points(roi_boundary, directory)\n",
    "points = list(blocks_df[\"points\"])\n",
    "\n",
    "roi_boundary = ee.FeatureCollection([ee.Feature(ee.Geometry.Rectangle([top_left[1], bottom_right[0], bottom_right[1], top_left[0]])) for top_left, bottom_right in points])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize roi on maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNFhupdZubPN"
   },
   "source": [
    "## LULC execution for years 2017 onwards with temporal correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lif5-R6xNiec",
    "outputId": "e96d3cb6-6e38-42d9-c01b-8f35cb288d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EXECUTING LULC PREDICTION FOR  2023-07-01  TO  2024-06-30 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "startDate = '2023-07-01'\n",
    "endDate = '2024-07-01'\n",
    "\n",
    "scale = 10\n",
    "\n",
    "loopStart = startDate\n",
    "loopEnd = (datetime.strptime(endDate,\"%Y-%m-%d\")).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "while loopStart != loopEnd:\n",
    "    currStartDate = datetime.strptime(loopStart,\"%Y-%m-%d\")\n",
    "    currEndDate = (currStartDate+relativedelta(years=1)-timedelta(days=1))\n",
    "\n",
    "    loopStart = (currStartDate+relativedelta(years=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    currStartDate = currStartDate.strftime(\"%Y-%m-%d\")\n",
    "    currEndDate = currEndDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    print(\"\\n EXECUTING LULC PREDICTION FOR \",currStartDate,\" TO \",currEndDate,\"\\n\")\n",
    "\n",
    "    curr_filename = directory + '_' + currStartDate + \"_\" + currEndDate\n",
    "\n",
    "    if datetime.strptime(currStartDate,\"%Y-%m-%d\").year < 2017:\n",
    "        print(\"To generate LULC output of year \",datetime.strptime(currStartDate,\"%Y-%m-%d\").year,\" , go to cell-LULC execution for years before 2017\")\n",
    "        continue\n",
    "    ts_data = Get_Padded_NDVI_TS_Image(startDate, endDate, roi_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = ts_data.select(ts_data.bandNames().getInfo()).rename([\"_\".join(i.split(\"_\")[1:]) + \"_\" + i.split(\"_\")[0] for i in ts_data.bandNames().getInfo()])\n",
    "task = ee.batch.Export.image.toAsset(\n",
    "    image=ts_data.clip(roi_boundary.geometry()),\n",
    "    description='Time Series' + directory,\n",
    "    assetId='projects/ee-raman/assets/temp12_' + directory.split(\"_\")[-1],\n",
    "    #pyramidingPolicy = {'predicted_label': 'mode'},\n",
    "    scale = scale,\n",
    "    maxPixels = 1e13,\n",
    "    crs = 'EPSG:4326'\n",
    ")\n",
    "task.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
